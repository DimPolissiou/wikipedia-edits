{"title_page": "Globalize (JavaScript library)", "text_new": "{{Infobox software\n| name                   = Globalize\n| logo                   = [[File:Globalize logo.svg|frameless]]\n| author                 = Rafael Xavier de Souza\n| developer              = [[jQuery Foundation]]\n| released               = {{Start date and age|2015|04|23}}\n| latest release version = 1.4.2 ({{Start date and age|2019|03|07}})\n| latest release date    = \n| programming language   = [[JavaScript]]\n| platform               = See [[#Browser support|Browser support]]\n| genre                  = [[JavaScript library]]\n| license                = [[MIT License]]<ref name=\"jqorg-license\">{{cite web\n | url = https://jquery.org/license/\n | title = License - jQuery Project\n | accessdate = 2016-01-30\n | publisher = jQuery Foundation\n}}</ref>\n| website                = {{URL|github.com/globalizejs/globalize}}\n}}\n'''Globalize''' is a [[cross-platform]] [[JavaScript library]] for [[internationalization and localization]] that uses the Unicode [[Common Locale Data Repository]] (CLDR).\n\n==Overview==\nGlobalize provides number formatting and parsing, date and time formatting and parsing, currency formatting, unit formatting, message formatting (ICU message format pattern), and plural support.\n\nDesign Goals:\n* Leverages the Unicode CLDR data and follows its UTS#35 specification.\n* Keeps code separate from i18n content. Doesn't host or embed any locale data in the library. Empowers developers to control the loading mechanism of their choice.\n* Allows developers to load as much or as little data as they need. Avoids duplicating data if using multiple i18n libraries that leverage CLDR.\n* Keeps code modular. Allows developers to load the i18n functionalities they need.\n* Runs in browsers and [[Node.js]], consistently across all of them.\n* Makes [[globalization]] as easy to use as [[jQuery]].\n\nGlobalize is based on the Unicode Consortium's [[Common Locale Data Repository]] (CLDR), the largest and most extensive standard repository of locale data available. CLDR is constantly updated and is used by many large applications and operating systems, to always have access to the most accurate and up-to-date locale data.\n\n==Usage==\nSince Globalize doesn't bundle any localization data, it has to be first initialized using some CLDR content:\n\n<syntaxhighlight lang=\"javascript\">\nvar Globalize = require( \"globalize\" );\nGlobalize.load( require( \"cldr-data\" ).entireSupplemental() );\nGlobalize.load( require( \"cldr-data\" ).entireMainFor( \"en\", \"es\" ) );\n\nGlobalize(\"en\").formatDate(new Date());\n// > \"11/27/2015\"\n\nGlobalize(\"es\").formatDate(new Date());\n// > \"27/11/2015\"\n</syntaxhighlight>\n\n==History==\nGlobalize was first announced in October 2010 by [[John Resig]]<ref>[http://blog.jquery.com/2010/10/04/new-official-jquery-plugins-provide-templating-data-linking-and-globalization/ Announcement of jQuery Globalization on jQuery Blog]</ref> and originally developed by David Reed, sponsored by [[Microsoft]], under the name jQuery Globalization plugin,<ref>[https://github.com/globalizejs/globalize/commit/3fc4b83d15a3337d5d9e70efebb36a4a8af0f861 Initial commit of jQuery Globalization on GitHub]</ref> built on top of an export of the .net locale database.<ref>[https://github.com/globalizejs/globalize/tree/3fc4b83d15a3337d5d9e70efebb36a4a8af0f861/generator The source files for the generator on GitHub]</ref> From there the dependency on jQuery was removed<ref>[https://github.com/globalizejs/globalize/commit/252f8ad0f668dbc63c7c43deef160acc9b3c9746 GitHub commit that starts a non-jQuery dependent version of the library]</ref> and the project renamed to Globalize.<ref>[https://github.com/globalizejs/globalize/commit/5cdac721d5ac49e708dc690fc15d60c7dc526bac Final GitHub commit to rename the repo from jquery-global to Globalize]</ref> In a much larger effort, the project was entirely rewritten on top of Unicode's CLDR, making use of its comprehensive and accurate coverage of all kinds of localization data.<ref>[http://blog.jquery.com/2015/04/23/announcing-globalize-1-0/ Announcement of Globalize 1.0]</ref>\n\n==References==\n{{Reflist|30em}}\n\n{{Web frameworks}}\n{{Authority control}}\n\n[[Category:Free software programmed in JavaScript]]\n[[Category:JavaScript libraries]]\n[[Category:Software using the MIT license]]\n", "text_old": "{{Infobox software\n| name                   = Globalize\n| logo                   = [[File:Globalize logo.svg|frameless]]\n| author                 = Rafael Xavier de Souza\n| developer              = jQuery Foundation\n| released               = {{start date and age|2015|04|23}}\n| latest release version = 1.4.2 ({{start date and age|2019|03|07}})\n| latest release date    = \n| programming language   = [[JavaScript]]\n| platform               = See [[#Browser support|Browser support]]\n| genre                  = [[JavaScript library]]\n| license                = [[MIT License|MIT]]<ref name=\"jqorg-license\">{{cite web\n | url = https://jquery.org/license/\n | title = License - jQuery Project\n | accessdate = 2016-01-30\n | publisher = jQuery Foundation\n}}</ref>\n| website                = {{URL|github.com/globalizejs/globalize}}\n}}\n'''Globalize''' is a [[cross-platform]] [[JavaScript library]] for [[internationalization and localization]] that uses the Unicode [[Common Locale Data Repository]] (CLDR).\n\n==Overview==\n\nGlobalize provides number formatting and parsing, date and time formatting and parsing, currency formatting, unit formatting, message formatting (ICU message format pattern), and plural support.\n\nDesign Goals:\n* Leverages the Unicode CLDR data and follows its UTS#35 specification.\n* Keeps code separate from i18n content. Doesn't host or embed any locale data in the library. Empowers developers to control the loading mechanism of their choice.\n* Allows developers to load as much or as little data as they need. Avoids duplicating data if using multiple i18n libraries that leverage CLDR.\n* Keeps code modular. Allows developers to load the i18n functionalities they need.\n* Runs in browsers and [[Node.js]], consistently across all of them.\n* Makes [[globalization]] as easy to use as [[jQuery]].\n\nGlobalize is based on the Unicode Consortium's [[Common Locale Data Repository]] (CLDR), the largest and most extensive standard repository of locale data available. CLDR is constantly updated and is used by many large applications and operating systems, to always have access to the most accurate and up-to-date locale data.\n\n==Usage==\n\nSince Globalize doesn't bundle any localization data, it has to be first initialized using some CLDR content:\n\n<syntaxhighlight lang=\"javascript\">\nvar Globalize = require( \"globalize\" );\nGlobalize.load( require( \"cldr-data\" ).entireSupplemental() );\nGlobalize.load( require( \"cldr-data\" ).entireMainFor( \"en\", \"es\" ) );\n\nGlobalize(\"en\").formatDate(new Date());\n// > \"11/27/2015\"\n\nGlobalize(\"es\").formatDate(new Date());\n// > \"27/11/2015\"\n</syntaxhighlight>\n\n==History==\nGlobalize was first announced in October 2010 by [[John Resig]]<ref>[http://blog.jquery.com/2010/10/04/new-official-jquery-plugins-provide-templating-data-linking-and-globalization/ Announcement of jQuery Globalization on jQuery Blog]</ref> and originally developed by David Reed, sponsored by Microsoft, under the name jQuery Globalization plugin,<ref>[https://github.com/globalizejs/globalize/commit/3fc4b83d15a3337d5d9e70efebb36a4a8af0f861 Initial commit of jQuery Globalization on GitHub]</ref> built on top of an export of the .net locale database.<ref>[https://github.com/globalizejs/globalize/tree/3fc4b83d15a3337d5d9e70efebb36a4a8af0f861/generator The source files for the generator on GitHub]</ref> From there the dependency on jQuery was removed<ref>[https://github.com/globalizejs/globalize/commit/252f8ad0f668dbc63c7c43deef160acc9b3c9746 GitHub commit that starts a non-jQuery dependent version of the library]</ref> and the project renamed to Globalize.<ref>[https://github.com/globalizejs/globalize/commit/5cdac721d5ac49e708dc690fc15d60c7dc526bac Final GitHub commit to rename the repo from jquery-global to Globalize]</ref> In a much larger effort, the project was entirely rewritten on top of Unicode's CLDR, making use of its comprehensive and accurate coverage of all kinds of localization data.<ref>[http://blog.jquery.com/2015/04/23/announcing-globalize-1-0/ Announcement of Globalize 1.0]</ref>\n\n==References==\n{{Reflist|30em}}\n\n{{Web frameworks}}\n{{Authority control}}\n\n[[Category:Free software programmed in JavaScript]]\n[[Category:JavaScript libraries]]\n[[Category:Software using the MIT license]]\n", "name_user": "Ghettoblaster", "label": "safe", "comment": "", "url_page": "//en.wikipedia.org/wiki/Globalize_(JavaScript_library)"}
{"title_page": "NEC V60", "text_new": "{{Copy edit|date=March 2020}}\n{{Infobox CPU\n| name           = NEC V60 / V70 / V80 / AFPP\n| image          = NEC V60 die.jpg\n| image_size     =\n| caption        = Die shot of NEC V60 microprocessor<br/>Name \"V60 D70616\" in bottom center\n| manuf1         = [[NEC Corporation|NEC]]\n| produced-start = V60: 1986<br/>V70: 1987<br/>V80: 1989<br/>AFPP: 1989\n| produced-end   = \n| slowest        = V60: 16&nbsp;MHz<br/>V70: 20/25&nbsp;MHz<br/>V80: 25/33&nbsp;MHz<br/>AFPP: 20\n| slow-unit      =&nbsp;MHz\n| size-from      = V60: 1.5/1.2 \u03bcm<br/>V70: 1.5/1.2 \u03bcm<br/>V80: 0.8 \u03bcm<br/>AFPP: 1.2 \u03bcm\n| transistors    = V60: 375K<br/>V70: 385K<br/>V80: 980K<br/>AFPP: 433K\n| arch           = NEC V60-V80<ref name=\"V60-Prog-Ref-Man\"/>\n| microarch      = \"V60/V70\", \"V80\"\n| instructions   = V60/V70:&nbsp;119<br/>V80:&nbsp;123\n| extensions     = V80: atomic\n| l1cache        = V80: 1K/1K\n| data-width     = V60: 16 (int. 32)<br/>V70: 32<br/>V80: 32\n| address-width  = V60: 24 (int. 32)<br/>V70: 32<br/>V80: 32\n| virtual-width  = 32 Linear<ref name=\"V60-Prog-Ref-Man\"/>\n| predecessor    = [[NEC V20|V20-V50]]\n| successor      = [[V850|V800&nbsp;Series]]\n| co-processor   = AFPP&nbsp;(\u03bcPD72691)\n| application    = [[Embedded system|Embedded]],<br/>[[Minicomputer]],<br/>[[Game arcade]]\n| pack1          = V60:&nbsp;68&#8209;pin&nbsp;[[Pin grid array|PGA]]<br/>V60:&nbsp;120&#8209;pin&nbsp;[[Quad Flat Package|QFP]]\n| pack2          = V70:&nbsp;132&#8209;pin&nbsp;[[Pin grid array|PGA]]\n| pack3          = V70:&nbsp;208&#8209;pin&nbsp;[[Quad Flat Package|QFP]]\n| pack4          = V80:&nbsp;280&#8209;pin&nbsp;[[Pin grid array|PGA]]\n| pack5          = AFPP:&nbsp;68&#8209;pin&nbsp;[[Pin grid array|PGA]]\n| pcode1         = \u03bcPD70616R&#8209;16\n| pcode2         = \u03bcPD70615GD&#8209;16\n| pcode3         = \u03bcPD70632R&#8209;20\n| pcode4         = \u03bcPD70632R&#8209;25\n| pcode5         = \u03bcPD70632GD&#8209;20\n| pcode6         = \u03bcPD70832R&#8209;25\n| pcode7         = \u03bcPD70832R&#8209;33\n| pcode8         = \u03bcPD72691R&#8209;20\n}}\n\n'''NEC V60'''<ref name=\"V60-Prog-Ref-Man\"/><ref name=\"maruzen\"/> is a [[Complex instruction set computer|CISC]] [[microprocessor]] once manufactured by [[NEC Corporation|NEC]] starting in 1986. It has an [[memory management unit|MMU]], and [[real-time operating system|RTOS]] support both for [[Unix]]-based user-application-oriented systems<ref name=\"RX-UX-832\"/> and for [[Industrial TRON|I&#8209;TRON]] based hardware-control-oriented [[embedded system]]s. This article also describes '''[[NEC V70|V70]]''' and '''[[NEC V80|V80]]''' because these have the same [[instruction set architecture|ISA]] as the V60.<ref name=\"overview\"/> In addition, dedicated co-[[Floating-Point Processor|FPP]],<ref name=\"coproc\"/>\nmulti-cpu [[lockstep (computing)|lockstep]] [[fault-tolerant computer system|fault-tolerant mechanism]] named [[Redundancy (engineering)|FRM]], [[development tool]]s including [[Ada (programming language)|Ada]] certified system [[#MV&#8209;4000|MV&#8209;4000]], and [[in-circuit emulator|ICE]] are described. At last, their successor<ref name=\"IEIEC-1995\"/> the [[Renesas V850|V800&nbsp;Series]] product families are briefly introduced.\n\nThe V60/V70/V80's applications covered a wide area, including: [[circuit switching]] [[telephone exchange]]s, [[minicomputer]]s, [[aerospace engineering|aerospace]] [[guidance system]]s,<ref name=\"akatsuki\"/> [[word processor]]s, [[Industrial Computers|industrial computer]]s, and various [[game arcade]]s.\n\n== {{anchor}}Introduction ==\n\nNEC V60<ref name=\"maruzen\"/><ref name=\"V60-Prog-Ref-Man\"/> is a [[Complex instruction set computer|CISC]]<ref name=\"pj\"/> processor once manufactured by [[NEC]] started in 1986.<ref name=\"SIG-ARC-043\"/> It is the first 32-bit [[microprocessor|general-purpose microprocessor]] commercially available in Japan.<ref name=\"trend\"/>\n\nBased on a relatively traditional design at that moment,<ref name=\"MIPS-1984\"/><ref name=\"RISC-II\"/><ref name=\"R2000\"/><ref name=\"First-SPARC\"/><ref name=\"i860\"/> indeed it was a radical divorcing from NEC's previous 16-bit V\u2013Series; the [[NEC V20|V20-V50]].<ref name=\"V20-V50-progman\"/> Those were based on the [[Intel 8086]] model.<ref name=\"pj\"/> But V60 still retained the ability to emulate V20/V30.<ref name=\"V60-Prog-Ref-Man\"/>{{rp|\u00a710}}\nAccording to NEC's documentation, this [[Computer architecture|computer architectural]] change was made due to the increasing demands for, and the diversity of, [[high-level programming language]]s. Such trend called for a processor both with performance; doubling the bus's width to 32 bits, and with flexibility; having large numbers of general-purpose registers.<ref name=\"maruzen\"/><ref name=\"V60-Prog-Ref-Man\"/> These were a part of common features of [[Reduced instruction set computer|''Reduced Instruction Set Computer'']].<ref name=\"Computer-Architecture-4thEd\"/> This transition from [[Complex instruction set computer|CISC]] to [[Reduced instruction set computer|RISC]] brought much benefits to the emerging markets \u2014 at that moment.\n\nBut today, both of two [[Silicon Valley]] born [[Reduced instruction set computer|RISC]]s are pressed, instead [[x86|Intel's x86]] has been main stream for these decades. The reason is, though [[x86]] has [[Complex instruction set computer|CISC]] [[Instruction set architecture|ISA]], [[Intel 80486|80486]] internally adopts [[RISC]] features.<ref name=\"i486-ICCD89\"/><ref name=\"i486-Micro-1990\"/>\nAccording to [[Pat Gelsinger]]'s word, binary backward compatibility for the legacy software assets is much important than ISA change.<ref name=\"CNET-2007\"/>\n\n== {{anchor|V60|D70616|\u03bcPD70616|.mu.PD70616}}Overview ==\n\n=== Instruction set ===\n\nThe V60 (\u03bcPD70616) /.mu.PD70616/, however, staid in [[Complex instruction set computer|CISC]] features.<ref name=\"Wade, 1996\"/> Its manual describes them as [[Mainframe computer|mainframe-computer]]-based fully [[orthogonal instruction set]], in other words, ''Complex Instruction Set Computer'', which comprises; non-uniform length instructions, memory-to-memory operations including string manipulation, and fairly complex operand addressing schemes.<ref name=\"V60-Prog-Ref-Man\"/><ref name=\"maruzen\"/><ref name=\"Computer-Architecture-4thEd\"/>\n\n=== Family ===\n\nThe V60 has 32 bits internal buses although it has externally narrower 16 bits data and 24 bits address buses. In addition, V60 has 32 of 32-bit general-purpose registers.<ref name=\"V60-Prog-Ref-Man\"/>{{rp|\u00a71}}\nIts basic [[Computer architecture|architecture]] is inherited to the following models. The V70 (\u03bcPD70632) has 32 bits external buses, released in 1987. Launched in 1989, the V80 (\u03bcPD70832)<ref name=\"overview\"/> is the culmination of the series; having on-chip caches, having a branch predictor, and less reliance on [[microcode]] for complex operations.<ref name=\"micro1990\"/>\n\n=== Software ===\n\nThe [[operating system]]s, developed for the V60-V80 series, are generally oriented toward [[Real-time operating system|real-time operation]]s. Several OSs were ported on them, including real-time Unix and real-time I\u2011TRON.<ref name=\"rtos1997\"/><ref name=\"32b-itron\"/>\n\nBecause the V60/V70 has been used for various Japanese [[game arcade]]s, their ''[[instruction set architecture]]'' is still surviving as the [[Emulator#CPU simulator|CPU simulator]], called [[MAME|MAME, ''Multiple Arcade Machine Emulator'']], for this niche.<ref name=\"v60-cemu\"/> The latest [[open-source software|open-source]] [[source code|code]] is available from [[GitHub]] [[Repository (version control)|repository]] ([https://github.com/mamedev/mame/ <mamedev/mame>][https://github.com/mamedev/mame/tree/master/src/devices/cpu/v60/ </src/devices/cpu/v60/>]).\n\n=== FRM ===\n\nAll three processors has the synchronous multiple modular [[lockstep (computing)|''lockstep'' mechanism]] named FRM (Functional Redundancy Monitoring), which enables [[fault-tolerant computer system]]s. It requires plural of devices of the same model, then one of them becomes the \"master mode,\" while the other devices listen to the master device in the \"checker mode.\" If two or more devices arise different result via their \"fault output\" pins simultaneously, the majority voting decision can be made by external circuits. In addition, recovery method, either with ''roll-back'' by \"retry\" or with ''roll-forward'' by \"exception\" for the instruction which is detected mismatch, can be selected via an external pin.<ref name=\"IEEE-MICRO-FRM\"/><ref name=\"compcon1988\"/><ref name=\"V60-Prog-Ref-Man\"/>{{rp|\u00a711}}<ref name=\"overview\"/><ref name=\"SIG-ARC-069\"/><ref name=\"V60-Datasheet\"/>{{rp|\u00a73-229, 266}}\n{| class=\"wikitable\"\n|-\n! Pin Name !! I/O !! Function\n|-\n| BMODE (FRM) || Input || Select the normal bus (master) mode or FRM operating (checker) mode\n|-\n| {{overline|BLOCK}} ({{overline|MSMAT}}) || Output || Master output requesting bus lock, i.e. freezing bus operation<br/>Checker output indicating a mismatch has been detected\n|-\n| BFREZ || Input || Assertion for freezing bus operation\n|-\n| RT/{{overline|EP}} || Input || Selecting input for \"roll-back by retry\" or \"roll-forward by exception\"\n|}\n\n== {{anchor|\u03bcPD70615|.mu.PD70615|D70615|PS98-145-HMW}}V60 ==\nThe work on V60 processor began in 1982 under the leadership of Yoichi Yano.<ref name=\"dev-story\"/> About 250 engineers participated and the V60 (\u03bcPD70616) debuted in February 1986.<ref name=\"Meth\u00e91991\"/> It had a six-stage pipeline, built-in memory management unit and floating-point arithmetic. It was manufactured in 1.5&nbsp;[[\u03bcm]] on a two-layer aluminum metal CMOS process using 375,000 transistors on a {{nowrap|13.9 \u00d7 13.8 mm<sup>2</sup>}} die.<ref name=\"SIG-ARC-043\"/><ref name=\"dataquest-1986\"/> It operated at 5&nbsp;V and was initially packaged in a 68-pin [[pin grid array|PGA]].<ref name=\"dataquest-1987\"/> The first version ran at 16&nbsp;MHz and attained 3.5 [[Instructions per second#MIPS|MIPS]].<ref name=\"dataquest-1986\"/> Its sample price at launch was set to \u00a5100,000 ($588.23). It entered full-scale production in August 1986.<ref name=\"dataquest-1986\"/>\n\n[[File:VR_Virtua_Racing.jpg|thumb|Sega ''[[Virtua Racing]]'' based on [[List of Sega arcade system boards#Sega Model 1|''Sega Model 1'']]<br/> ([http://www.retroclinic.com/leopardcats/vrtwin/vrtwin.htm External Link])]]\n[[Sega]] employed this processor for the most of its arcade game sets in the 1990s; both the [[List of Sega arcade system boards#Sega System 32|Sega System 32]] and the [[List of Sega arcade system boards#Sega Model 1|Sega Model 1]] architectures used V60 for their main CPU. (The latter one used lower-cost variant  \u03bcPD70615 /.mu.PD70615/,<ref name=\"mamedev-model1\"/> which doesn't implement V20/V30 emulation and FRM.<ref name=\"cat95\"/>\n) The V60 was also used for the main CPU in the ''SSV'' arcade architecture\u2014so named because it was developed together by [[SETA Corporation|''Seta'']], [[Sammy Corporation|''Sammy'']], and [[Visco Corporation|''Visco'']].<ref name=\"mamedev-ssv\"/> Sega originally considered using a 16&nbsp;MHz V60 as the basis for its [[Sega Saturn]] console, but after receiving the word, that the [[PlayStation (console)|PlayStation]] employed a [[MIPS architecture|MIPS]] [[R3000|R3000A]] at 33.8&nbsp;MHz processor, instead chose the dual-[[SuperH|SH-2]] design for the eventual production model.<ref name=\"ric-tan\"/>\n\nIn 1988, NEC released a kit called PS98-145-HMW<ref name=\"ps98-145-hmw\"/> for [[Unix]] enthusiasts. The kit contained a V60 processor board that could be plugged into selected models of the [[PC-9800 series|PC-9800]] computer series and a '15 8\"-floppy disks distribution' of their [[UNIX System V]] port, the [[PC-UX|PC-UX/V]] [[UNIX System&nbsp;V#SVR2|Rel 2.0 (V60)]]. The suggested retail price for this kit was 450,000 Yen.<ref name=\"ps98-145-hmw\"/> NEC group companies themselves intensively employed V60 processor. Their [[telephone exchange|telephone circuit switcher]] (exchanger), which was one of the first intended target, used V60. In 1991, they expanded [[word processor]] products line, named [[:ja:\u6587\u8c6a|\"Bungou Mini\" (\u6587\u8c6a\u30df\u30cb in Japanese)]] series ''5SX'', ''7SX'', and ''7SD'', with a V60 for fast [[Computer font#Outline fonts|outline font]] processing, while the main system processor was a 16&nbsp;MHz [[NEC V20#Variants and successors|NEC V33]].<ref>{{YouTube|2kTVKjOWu3I|''Bungou Mini 5RX''}} with [[Computer font#Outline fonts|\"high speed outline font smoothing\"]] TV CM</ref><ref name=\"ipsj-bungo\"/> In addition, V60 has [[microcode]] variants for NEC's [[minicomputer]] ''MS-4100'' Series, which was the fastest one in Japan at that moment.<ref name=\"nec-tecj-ms4100\"/><ref name=\"ispj-ms4100\"/><ref name=\"nij-ms4100\"/>\n\n== {{anchor|\u03bcPD70632|.mu.PD70632|D70632}}V70 ==\n[[File:UPD70632GD-20 V70 01.JPG|thumb|V70 (\u03bcPD70632GD-20) in [[Quad Flat Package|QFP]] packaging, mounted on [[Jaleco]] ''[[:ja:\u30e1\u30ac\u30b7\u30b9\u30c6\u30e032|Mega System32]]'' [[Printed wiring board|PWB]] ]]\nThe V70 (\u03bcPD70632) /.mu.PD70632/ improved on V60 by widening external buses to 32 bits, then both internal and external buses became 32 bits width. It was also manufactured in a 1.5&nbsp;\u03bcm with two-metal layer process. Its {{nowrap|14.35 \u00d7 14.24 mm<sup>2</sup>}} die had 385,000 transistors and was packaged in a 132-pin ceramic [[Pin grid array|PGA]]. Its [[Memory management unit|MMU]] had support for [[demand paging]]. Its floating-point unit claimed [[IEEE 754]] compliance.<ref name=\"SIG-ARC-069\"/> The 20&nbsp;MHz version attained a peak performance of 6.6 MIPS and was priced at launch in August 1987 at \u00a5100,000 ($719.42). Initial production capacity was 20,000 units monthly.<ref name=\"dataquest-1987-2\"/> A later report describes it as [[Semiconductor device fabrication|fabricated]] in 1.2-micrometer CMOS and {{nowrap|12.23 \u00d7 12.32 mm<sup>2</sup>}} die.<ref name=\"overview\"/> The V70 had a two-cycle non-pipeline (T1-T2) external bus system, whereas that of the V60 operated at 3 or 4 cycles (T1-T3/T4).<ref name=\"overview\"/><ref name=\"maruzen\"/> Of course, the internal units were pipelined.\n\nV70 was used by [[Sega]] in its [[List of Sega arcade system boards#System Multi 32 specifications|''System Multi 32'']] design\n<ref name=\"mamedev1\"/> and by [[Jaleco]] in its [[:ja:\u30e1\u30ac\u30b7\u30b9\u30c6\u30e032|''Mega System 32'']] design. (See the top photo of the V70, which is mounted on the latter system's [[printed circuit board]].)<ref name=\"mamedev-mc32\"/>\n\n[[File:H-IIA F17 launching AKATSUKI.jpg|thumb|Liftoff of H&#8209;IIA Flight&nbsp;17, one of payload is [[Akatsuki (spacecraft)|Akatsuki; Venus Climate Orbiter]] ]]\nThe \"[[aerospace engineering|aerospace]]-spec\" ([[JAXA]] <sup>formerly [[National Space Development Agency of Japan|NASDA]]</sup> qualified EEE grade) variant of V70, running with [[RX616]], was embedded in the main control module called ''[[Guidance, navigation, and control|Guidance Control]] Computer'' by [[JAXA]] into the ''[[H-IIA|H&#8209;IIA]]'' [[carrier rocket]]s, and satellites such as [[Akatsuki (spacecraft)|''Akatsuki'' (Venus Climate Orbiter)]] and [[Kibo (ISS module)|''Kibo'' (ISS module)]].<ref name=\"akatsuki\"/><ref name=\"JAXA-Kibo\"/><ref name=\"Kibo-EDEE\"/> It had been used until their replacement in 2013 flight 22 with the 64-bit [[microprocessor]] ''HR5000'', which is based on [[MIPS architecture#MIPS32/MIPS64|MIPS64-5Kf architecture]],<ref name=\"MIPS64-5Kf-DS\"/> [[Semiconductor device fabrication|fabricated]] by HIREC.<ref name=\"nectech-jaxagcc\"/><ref name=\"jaxa-eee-parts\"/><ref name=\"HIREC-HR5000\"/> The ''[[H-IIA|H&#8209;IIA]]'' type ''[[launch vehicle]]s'' deployed domestically in Japan, although JAXA called for [[satellite]]s as its [[payload]] from the foreign countries. As is described in ''JAXA's LSI (MPU/ASIC) roadmap'', this V70 variant is \"32bit MPU (''H32/V70'')\" which development term, probably including QT phase, was \"from the middle of 1980s to early 1990s.\" In addition, the ''HR5000'' is \"64bit MPU (25MHz),\" which development is completed around 2011. Then V70 was retired.<ref name=\"jaxa-roadmap\"/>{{rp|9}}<ref name=\"jaxa-status-2013\"/>\n\n\"Space Environment Data Acquisition\" for the V70 was done by ''Kibo''-ISS exposed facility.\n{| class=\"wikitable\"\n|-\n! Item !! Part No. !! SEE (Single Event Effect)<br/>Monitored Item\n! Result <ref name=\"Kibo-SEE\"/>\n|-\n| V70-MPU || [[National Space Development Agency of Japan|NASDA]]<br/>38510/92101xz || [[Single event upset|SEU (Single Event Upset)]]<br/>[[Latch-up|SEL (Single Event Latch-up)]] || Not observed<br/>(\u20142010/9/30)\n|}\n\n== {{anchor|\u03bcPD70832|.mu.PD70832|D70832}}V80 ==\nThe V80 (\u03bcPD70832) /.mu.PD70832/<ref name=\"overview\"/> was launched in the spring of 1989. By incorporating on-chip caches and a [[branch predictor]], it was declared NEC's [[Intel 486|486]] by ''[[Computer Business Review]]''.<ref name=\"CBR-1\"/><ref name=\"CBR-2\"/> The performance of V80 was two to four times than that of V70, depending on application. For example, compared with V70, the V80 had a 32-bit hardware multiplier to reduce integer multiplication cycles to 9 from 23. (For more detailed differences, see hardware architecture section below.) The V80 was manufactured in 0.8-micrometer CMOS process with a die area of {{nowrap|14.49 \u00d7 15.47 mm<sup>2</sup>}} consisting of 980,000 transistors. It was packaged in a 280-pin [[Pin grid array|PGA]], and operated at 25 and 33&nbsp;MHz with claimed peak performance of 12.5 and 16.5 MIPS, respectively. V80 had separated 1&nbsp;KB on-die cache both for instructions and for data, and had 64-entry [[branch predictor]]; the performance gain, attributed to the latter, was about 5%. The launch prices of V80 were cited as equivalent to $1200 for the 33&nbsp;MHz model and $960 for the 25&nbsp;MHz model. Supposedly a 45&nbsp;MHz model was scheduled for 1990,<ref name=\"CBR-2\"/> but did not materialize.\n\nThe V80, associated with \u03bcPD72691 co-FPP and \u03bcPD71101 simple [[peripheral]] chips, was used for [[Industrial PC|industrial computer]] with the [[RX-UX832]] real-time UNIX and a [[X Window System|X11-R4]] based window system.<ref name=\"Meiden-Jiho-Jul92\"/><ref name=\"Meiden-Jiho-May93\"/>\n\n== {{anchor|\u03bcPD72691|.mu.PD72691|D72691|AFPP}}AFPP (co&#8209;FPP) ==\n\nThe AFPP (\u03bcPD72691) /.mu.PD72691/ is a co-processor for floating point arithmetic operations.<ref name=\"Majithi, 1987\"/> The name stands for Advanced Floating Point Processor as is described in NEC's data sheet. The V60/V70/V80 themselves can perform floating point arithmetic, but they are very slow because of microcode operations without dedicated hardware. In 1989, to compensate V60/V70/V80 for their fairly weak floating point performance, NEC launched the 80-bit floating point co-processor; for 32-bit [[Single-precision floating-point format|single precision]], for 64-bit [[Double-precision floating-point format|double precision]], and for 80-bit [[extended precision]] [[IEEE 754]] format operations.<ref name=\"coproc\"/><ref name=\"overview\"/> This chip claimed 6.7 [[MFLOPS]] in the vector-[[matrix multiplication]], operating at 20&nbsp;MHz. It was [[Semiconductor device fabrication|fabricated]] in 1.2-micrometer double-metal layer CMOS process containing 433,000 transistors on an {{nowrap|11.6 \u00d7 14.9 mm<sup>2</sup>}} die.<ref name=\"coproc\"/> It was packaged in a 68-pin [[Pin grid array|PGA]]. This co-processor connected to V80 via the dedicated bus. But in case of connecting to V60 and V70, it shared their main buses, which scenario diminished their peak performance.<ref name=\"overview\"/>\n\n== {{anchor|arch}}Hardware Architecture ==\nV60/V70/V80 shared the basic architecture. They had thirty-two 32-bit [[general-purpose register]]s, although the last three of them were commonly used as [[stack pointer]], [[frame pointer]], and [[argument pointer]], those were well matched with [[High-level programming language|high level language]] [[compiler]]s' [[calling convention]]s.<ref name=\"SIG-ARC-069\"/><ref name=\"GCC-Internal\"/> The V60 and V70 had a 119-instruction set,<ref name=\"SIG-ARC-069\"/> slightly extended to 123 instructions for the V80. The instructions have [[Complex instruction set computing|non-uniform length]] between one and 22 bytes,<ref name=\"V60-Prog-Ref-Man\"/> and they take two operands, both of which can be memory locations.<ref name=\"overview\"/> After studying the V60's reference manual, [[Paul Vixie]] described it as \"a very [[VAX]]-ish arch, with a V20/V30 emulation mode (which, if you recall, means it can run Intel 8086/8088 software)\".<ref name=\"google-groups\"/>\n\nV60-V80 had a built-in [[Memory management unit|MMU]]<ref name=\"SIG-ARC-043\"/><ref name=\"Majithi, 1987\"/> that divide the 4 GB [[Virtual memory|virtual address space]] into in four 1-GB sections, each section further divided in 1,024 1-MB areas, each area composed of 256 4-KB pages. On the V60/V70 four registers (ATBR0 to ATBR3) store section pointers on the processor, but the area tables entries (ATE) and [[Memory management unit#Page table entries|page tables entries (PTE)]] are stored into off-chip RAM. The V80 merged the ATE and ATBR registers, which are both on-chip with only the [[Memory management unit#Page table entries|PTE]] entries stored into external RAM, allowing for a faster execution of [[Translation lookaside buffer|TLB]] misses by eliminating one memory read.<ref name=\"overview\"/>\n\nThe TLBs on the V60/70 are 16-entry [[CPU cache#Associativity|fully associative]] with replacement done by [[microcode]]. The V80 in contrast has a 64-entry 2-way [[set associative]] [[Translation lookaside buffer|TLB]] with replacement done in hardware. [[Translation lookaside buffer|TLB]] replacement took 58 cycles in the V70 and also disrupted the pipelined execution of other instructions. On the V80 a TLB replacement took only 6/11 cycles depending if the page was in the same area or not; pipeline disruption no longer occurred in V80 because of the separate TLB replacement hardware unit which operated in parallel to the rest of the processor.<ref name=\"overview\"/>\n\nAll three processors used the same protection mechanism with 4 execution levels (set via a [[program status word]]), with [[ring 0]] being the privileged level that could access a special set of privileged registers on the processors.<ref name=\"overview\"/>\n\nAll three models supported a triple-mode redundancy configuration with three CPUs used in a [[byzantine fault tolerance]] scheme with bus freeze, instruction retry, and chip replacement signals.<ref name=\"overview\"/><ref name=\"compcon1988\"/> The V80 also added parity signals to its data and address buses.<ref name=\"overview\"/>\n\nString operations were implemented in [[microcode]] in the V60/V70, but aided by hardware Data Control Unit in the V80, running at full bus speed. This made string operations about five times faster in the V80.<ref name=\"overview\"/>\n\nAll floating point operations are largely implemented in microcode across the family and thus and are fairly slow. On the V60/V70 the 32-bit floating point operations took 120/116/137 cycles for addition/multiplication/division, while the corresponding 64-bit floating point operations took 178/270/590 cycles. The V80 had some limited hardware assist for parts of the floating point operations, e.g. decomposition into sign, exponent and mantissa, thus its floating point unit was claimed up to 3 times as effective as the one of the V70, with 32-bit operations taking 36/44/74 cycles while 64-bit floating point operations taking 75/110/533 cycles on the V80 (again, for addition/multiplication/division).<ref name=\"overview\"/>\n\n== {{anchor|PC-UX/V Rel 2.0 (V60)|Real-time UNIX RX-UX 832|RX-UX 832|RX-UX832|MUSTARD|RX616|NEC RX116|RX116|}}Operating Systems ==\n\n=== Unix (non-real-time and real-time) ===\n\nNEC ported several variants of [[Unix]] to its V60/V70/V80 processors for user-application-oriented systems, including real-time ones. The first flavor of NEC's [[UNIX System V]] port for V60 was called [[PC-UX/V]] [[UNIX System&nbsp;V#SVR2|Rel 2.0]] (V60).<ref name=\"PC-UX-R2-V60\"/> (also refer to [[#External links|external link]] photos below, much interesting) NEC also developed a variant for V60/V70/V80 with a focus on real-time operation called Real-time UNIX RX-UX 832.<ref name=\"RX-UX-832\"/> It has double layered kernel structure, and all the kernel call of Unix issues task to the real-time kernel. The multiprocessor version of RX-UX 832 was also developed, and was named MUSTARD (A Multiprocessor Unix for Embedded Real-Time Systems).<ref name=\"Suzuki1992\"/> The MUSTARD-powered computer prototype used eight V70 processors. It utilizes FRM function, and can configure and change the structure of master and checker upon request.<ref name=\"8-V70-Proc\"/>\n([https://books.google.co.jp/books?id=Hyn9Cqf8PZsC&pg=PA195#v=onepage&q&f=false Google Books])\n\n=== I&#8209;TRON (real-time) ===\n\nFor hardware-control-oriented [[embedded systems]], the [[Industrial TRON|I&#8209;TRON]] based real-time operating system, named RX616, was implemented by NEC for the V60/V70.<ref name=\"IEEE-MICRO-FRM\"/><ref name=\"rtos1997\"/> The 32-bit RX616 was a continuous fork from the 16-bit [[NEC RX116|RX116]], which was for the [[NEC V20|V20-V50]].<ref name=\"dataquest-1987-2\"/><ref name=\"32b-itron\"/>\n\n=== FlexOS (real-time) ===\n\nIn 1987, [[Digital Research|Digital Research, Inc.]] had also announced that they were planning on porting [[FlexOS]] to the V60 and V70.<ref name=\"FLEXOS\"/>\n\n=== CP/M and DOS (legacy 16-bit) ===\n\nThe V60 could also run [[CP/M]] and [[DOS]] programs (ported from the V20-V50 series) using V20/V30 emulation mode.<ref name=\"dataquest-1986\"/> According to a 1991 article in [[InfoWorld]], [[Digital Research]] was working on a version of [[Concurrent DOS]] for the V60 at some point, but this was never released as the V60/V70 processors were not imported in the US for use in PC clones.<ref name=\"Inc.1991\"/>\n\n== {{anchor|compiler|cross-compiler}}Development Tools ==\n\n=== {{anchor|PKG70616|MetaWare|MetaWare, Inc.|High C/C++}}C/C++ cross compilers ===\n\nRegarding the [[development tool]] kit and [[Integrated development environment|IDE]], NEC had its own C compiler the PKG70616; \"Software Generation tool package for V60/V70.\"<ref name=\"cat-fr\"/> In addition, GHS ([[Green Hills Software]]) made its native mode C compiler (MULTI), and [[MetaWare, Inc.]]<ref name=\"metaware\"/> (currently [[Synopsys]], via [[Synopsys#ARC International|ARC International]]) made one for V20/V30 emulation mode, i.e. 8086 model, called High C/C++.<ref name=\"high-c\"/><ref name=\"i486-Micro-1990\"/>{{rp|acknowledgement}}\n[[Cygnus Solutions]] (currently [[Red Hat]]) also ported [[GNU Compiler Collection|GCC]] in a part of [[EGCS]] fork,<ref name=\"egcs\"/> but it seems not to be public.<ref name=\"by-cygnus-1\"/><ref name=\"by-cygnus-2\"/>\n\nAs of 2018, the machine directory ''necv70'' is still kept alive in the [[newlib]] C language libraries (libc.a and libm.a) by [[RedHat]].<ref name=\"newlib\"/> Its home page is [https://sourceware.org/newlib/ https://sourceware.org/newlib/]. Recent maintenance seems to be done on [https://sourceware.org/git/gitweb.cgi?p=newlib-cygwin.git;a=history;f=newlib/libc/machine/necv70;hb=HEAD <2016-12-23>]. The latest source code is available from its [[git]] [[Repository (version control)|repository]] [https://sourceware.org/git/gitweb.cgi?p=newlib-cygwin.git;a=tree;f=newlib/libc/machine/necv70 <newlib/libc/machine/necv70>]. The assembler source code [https://sourceware.org/git/gitweb.cgi?p=newlib-cygwin.git;a=blob;f=newlib/libc/machine/necv70/setjmp.S <setjump.S>] is truly the mnemonic of V70.\n\n=== {{anchor|MV4000|MV&#8209;4000}}MV-4100 Ada 83 certified system ===\n\nThe [[Ada (programming language)|Ada 83]] certified ''platform system'' was named MV\u20114000, sometimes notified as MV4000. This certification was done with \"the target\" system, that utilized ''Real-time UNIX RX-UX 832'' OS running on the [[VMEbus]] (IEEE 1014) based system, a V70 processor board plugged in.  \"The host\" of the [[cross compiler]] was the ''NEC Engineering Work Station [[:ja:EWS4800|EWS 4800]]''. Its \"host os\" ''[[EWS-UX|EWS-US/V]]'' was also [[UNIX System&nbsp;V]] based.<ref name=\"ada83cpl\"/><ref name=\"MV&#8209;4000\"/><ref name=\"ews-4800\"/>\n\nThe certification status is issued as the [https://books.google.com/books?id=M3F-lhug50cC&pg=PA198&dq=MV4000+V70 ADA YEAR BOOK]. The status of MV\u20114000 (notified as MV4000) can be found such as 1994, and 1995 revision.\n\nAda 83 validation status by AETECH, Inc.<ref name=\"ada83cpl\"/>\n<br/>\nNOTE: In accordance with the [http://archive.adaic.com/compilers/val-proc/1222val.html Ada Validation Procedures (Version 5.0)], certificates will no longer be issued for Ada 83 compilers. Testing may be performed by an Ada Conformity Assessment Laboratory (ACAL) for specific procurement requirements, and the ACAA will issue a letter affirming such testing, but no certificates will be issued. All validation certificates ever issued for testing under Version 1.11 of the ACVC test suite expired on 31 March 1998.\n{| class=\"wikitable\"\n|-\n! System Name !! Certificate Number !! Compiler Type !! HOST Machine !! HOST OS !! TARGET Machine !! TARGET OS\n|-\n| NEC Ada Compiler System for EWS-UX/V to V70/RX-UX832, Version 1.0 || 910918S1.11217 || Base || NEC EWS4800/60 || EWS-UX/V R8.1 || NEC MV4000 || RX-UX832 V1.6\n|-\n| NEC Ada Compiler System for EWS-UX/V(Release 4.0) to V70/RX-UX832 Version Release 4.1 (4.6.4) || 910918S1.11217 ||  Derived || EWS4800 Superstation RISC Series || EWS-UX/V(R4.0) R6.2 || NEC MV4000 || RX-UX832 V1.63\n|}\n\n{| class=\"wikitable\"\n|-\n! MV\u20114000 Features <ref name=\"MV&#8209;4000\"/>\n|-\n| System bus: IEEE1014 D1.2/IEC821 Rev C.1 (8-slot)\n|-\n| Expansion bus: IEC822 Rev C or V70 cache bus (6-slot)\n|-\n| Built-in 100M byte (formatted) 3.5-inch SCSI hard disk\n|-\n| Built-in 1M-byte 3.5-inch floppy disk drive 1\n|-\n| Expansion SCSI (1 ch)\n|-\n| EMI evaluation: VCCI - 1 kind\n|}\n\n=== Evaluation board kits ===\n\nNEC released some of plug-in type evaluation board kits for V60/V70.\n{| class=\"wikitable\"\n|-\n! Parts No. !! Descriptions !! Remarks\n|-\n| EBIBM-7061UNX || V60 coprocessor slave board with Unix for [[IBM Personal Computer XT|PC-XT]]/[[IBM Personal Computer/AT|AT]] || w/ [[PC-UX]]/V Rel 2.0 (V60)\n|-\n| PS98-145-HMW || V60 coprocessor slave board with Unix for [[PC-9800 series|NEC PC-9801]] || w/ [[PC-UX]]/V Rel 2.0 (V60)\n|-\n| EBIBM-70616SBC || V60 single board computer for [[Multibus#Multibus I|Multibus I]] ||\n|-\n| A part of MV-4000 || V70 single board computer for [[VMEbus]] || [[Ada 83]] certified\n|-\n|}\n\n== {{anchor|hw-emulator|ICE}}In-Circuit Emulator ==\n\n=== On-chip software debug support ===\n\nNEC had its own full (non-ROM and non-JTAG) probe-based ''[[in-circuit emulator]]''; the IE-V60 because V60/V70 themselves had emulator-chip capabilities. NEC described it as \"user friendly software debug function.\"  In fact, they have various trapping exceptions, such as data read (or write) to the user specified address, and 2 break-points simultaneously. <sup>Section 9</sup>\n<ref name=\"V60-Prog-Ref-Man\"/>\n\n=== External bus status pins ===\n\nExternal bus system also indicates its bus status with 3 bits of status pins, such as the first [[instruction fetch]] after branch, continuous [[instruction fetch]], [[Translation lookaside buffer|TLB]] [[data access]], single [[data access]], [[Sequential access|sequential data access]]. <sup>Section 6.1, p.&nbsp;114</sup>\n<ref name=\"maruzen\"/>\n\n{| class=\"wikitable\"\n|-\n! ST[2:0] !! Description\n|-\n| 111 || [[Instruction fetch]]\n|-\n| 011 || [[Instruction fetch]] after branch\n|-\n| 101 || [[Translation lookaside buffer|\"TLB\"]] [[data access]]\n|-\n| 100 || \"System base (interrupt & exception vector) table\" [[data access]]\n|-\n| 011 || Single [[data access]]\n|-\n| 010 || Short-path data access (Skipped address by read-after-write)\n|-\n| 001 || [[Sequential access|Sequential data access]]\n|-\n|}\n\n=== Debugging with V80 ===\n\nThese software and hardware debugging functions were also built on the V80, but it did not have [[In-circuit emulation|in-circuit emulator]]. Probably because it succeeded much fruits from V60/V70, such as [[Real-time operating system|real-time]] [[UNIX System&nbsp;V|UNIX]] RX-UX 832 and [[Real-time operating system|real-time]] [[Industrial TRON|I&#8209;TRON]] RX616. Think, if once [[Unix]] boots up, who needs [[In-circuit emulation|in-circuit emulator]] both for developing [[device driver]] and for developing [[application software]]. What developer need is a [[C (programming language)|C]] [[compiler]], self as well as [[Cross compiler|cross]], and the [[Debugger#Debugger front-ends|screen debugger]], working with the target device, such as [[GNU Debugger#Graphical user interface|GDB-Tk]].\n\n=== IE-V60 ===\n\nThe IE-V60 was the first ''in-circuit emulator'' for V60 manufactured by NEC. It also had PROM programmer function. <sup>Section 9.4, p.&nbsp;205</sup><ref name=\"maruzen\"/>\n\n=== {{anchor|HP 64758}}HP 64758 ===\n\n[[Hewlett Packard]] (currently [[Keysight]]) offered a probing-pod-based ''[[In-circuit emulation]]'' hardware for the V70, built on their ''[[HP 64700]]'' Series systems,<ref name=\"HP-Vseries\"/><ref name=\"HP64700\"/> successor of ''[[HP 64000]]'' Series (detailed description is available within Wikipedia, with graphical image), more precisely the HP 64758<ref name=\"HP64758G\"/><ref name=\"HP-discon\"/> emulated the V70.<ref name=\"HP-Vseries\"/> It enables trace function like a [[logic analyzer]]. This [[Electronic test equipment|test equipment]] also displays [[Disassembler|disassembled instruction]] level [[source code]] automatically; with trace data display; ''without'' any [[object file]].<ref name=\"HP-Vseries\"/> And displays [[high-level language]] [[source code]] if user provide the [[source code]] and the [[object file]], which is [[compile]]d with [[DWARF]] information. Interface for V60 (10339G) is also listed in the catalog.<ref name=\"HP-discon\"/> But long probing-pod cable required \"special grade qualified\" devices, i.e. high speed grade V70.\n\nHP 64758: Main units, sub-nits, and hosted interface\n{| class=\"wikitable\"\n|-\n! Product !! Description\n|-\n| 64758A || V70 20&nbsp;MHz Emulator 512KB of Emul. mem.\n|-\n| 64758AX || One-Time-Update \n|-\n| 64758B || V70 20MHZ Emulator 1MB of Emulation mem.\n|-\n| 64758G || V70 20&nbsp;MHz emulation subsystem 512KB\n|-\n| 64758H || V70 20&nbsp;MHz emulation subsystem 1MB\n|-\n| 64758S || V70(uPD70632) Hosted User Interface\n|}\n\nSoftware options\n{| class=\"wikitable\"\n|-\n! Product !! Description\n|-\n| 64879L || V70 Assembler/Linker Single User License\n|-\n| 64879M || V70 Assembler/Linker Media & Manuals\n|-\n| 64879U || V70 Assembler/Linker Multi-user license\n|}\n\nHardware options\n{| class=\"wikitable\"\n|-\n! Product !! Description\n|-\n| B3068B || V70 Graphical Hosted User Interface\n|-\n| 10339G || NEC V60 INTERFACE\n|-\n| E2407A || NEC V70 INTERFACE\n|}\n\n== {{anchor|fading}}Fading and Successors ==\n\n=== Strategic failure of the V80 [[microarchitecture]] ===\n\nIn its development phase, the V80 was thought as the same performance chip as the [[Intel 80486]].<ref name=\"V80-rumor\"/> But, as the result, they became much different features. The internal execution for each instruction of the V80 needed at least 2 cycles, while that of i486 was 1. The internal pipeline of the V80 seemed [[Pipeline (computing)#Buffered, asynchronous pipelines|buffered A-synchronous]], but that of i486 was [[Pipeline (computing)#Buffered, synchronous pipelines|synchronous]]. In other words, the internal [[microarchitecture]] of V80 was [[Complex instruction set computer|CISC]], but that of i486 was [[Reduced instruction set computer|RISC]]. Both of their [[Instruction set architecture|ISA]] had long non-uniform [[Complex instruction set computer|CISC]] instructions, so i486 adopted wider 128-bit internal [[cache memory]], while that of V80 was 32-bit width. This difference can be seen on their die photos.<ref name=\"overview\"/><ref name=\"i486-Micro-1990\"/><ref name=\"micro1990\"/><ref name=\"i486-ICCD89\"/>\nThis strategic failure was fatal from the performance point of view, but NEC did not change its design. NEC might be able to throw away its [[Physical design (electronics)|physical design]], and to reconsider in [[register-transfer level]] as soon as possible, but it did not.\n\n=== Fading ===\nThe V60-V80 architecture did not enjoy much commercial success.<ref name=\"Meth\u00e91991\"/>\n\nThe V60, V70, and V80 were listed in 1989 and 1990 NEC catalogs in their [[Pin grid array|PGA]] packaging.<ref name=\"cat89\"/><ref name=\"cat90\"/> A NEC catalog from 1995 still listed the V60 and V70 (not only in their [[Pin grid array|PGA]] version but also in a [[Quad Flat Package|QFP]] packaging, and also included a low-cost variant of the V60 named \u03bcPD70615, which eliminated V20/V30 emulation and FRM function), alongside their assorted chipset, but the V80 is not offered in this catalog.<ref name=\"cat95\"/> The 1999 edition of the same catalog no longer has any V60-V80 products.<ref name=\"cat99\"/>\n\n=== {{anchor|NEC V810|NEC V820|NEC V830|\u03bcPD70732|\u03bcPD70742}}The V800&nbsp;Series ===\n\nIn 1992, NEC launched new model, the V800&nbsp;Series 32-bit [[microcontroller]], but it does not have [[Memory management unit|MMU (Memory Management Unit)]].<ref name=\"1992-ARC-06\"/> Those were much different from CISC, but [[Reduced instruction set computer|RISC]]-based architecture, inspired by the [[Intel i960]], [[MIPS architecture]], and other [[Reduced instruction set computer|RISC]] processor instructions, such as JARL (Jump and Register Link), and [[load/store architecture]].\n\nAt this moment, all the huge software assets of the V60/V70, like real-time Unix, were lost and never returned to their successors. The scenario Intel circumvents.\n\nThe V800&nbsp;Series had 3 product line variants, the V810&nbsp;Family, the V830&nbsp;Family, and the [[V850|V850&nbsp;Family]].<ref name=\"EDN\"/><ref name=\"IEIEC-1995\"/><ref name=\"IEEE-1998\"/>\n\nV820 (\u03bcPD70742) was a simple variant of V810 (\u03bcPD70732) with peripherals. The [[:ja:\u30b7\u30d0\u30f3\u30e0\u30b7|#4]] seems to be skipped (see page 58 <ref name=\"cat95\"/>), probably because of Japanese [[tetraphobia]].  One [[Japanese pronunciation]] of \"4\" means \"death.\" So the successors well avoid the [[Deathwatch beetle|Death-watch]]; Shi-ban (#4; Shi-ban) ''[[Software bug|Bug]]'' ({{nihongo2|[[:ja:\u30b7\u30d0\u30f3\u30e0\u30b7|\u6b7b\u756a\u866b]]}}, precisely ''[[deathwatch beetle]]''). As of 2005, it was already the [[V850]] era, and the [[V850]]&nbsp;Family has been enjoying great success.<ref name=\"cat05\"/> As of 2018, it is called Renesas V850&nbsp;Family and RH850&nbsp;Family with V850/V850E1/V850E2 and V850E2/V850E3 CPU cores, respectively. Those CPU cores have extended [[Instruction set architecture|ISA]] of original V810 CPU core;<ref name=\"V810-GCC\"/> running with V850 compiler.<ref name=\"GHS-V850\"/>\n\n== {{anchor|sw-emulator|ISS|MEME}}Emulator (CPU Simulator) Software ==\n\n=== MAME ===\n\nBecause the V60/V70 had been used for many Japanese [[game arcade]]s, their [[instruction set architecture]] has still survived as [[Emulator#CPU simulator|CPU simulator]] for this niche market. It is called [[MAME|MAME (''Multiple Arcade Machine Emulator'')]], which emulates multiple old [[game arcade]]s for enthusiasts.<ref name=\"v60-cemu\"/> It is a kind of an [[instruction set simulator]], not for developers but for users.\n\nNowadays, it has been kept providing by the [http://www.mamedev.org/ ''MAME development team'']. The latest [[open-source software|open-source]] [[source code|code]], written in [[C++]], is available from [[GitHub]] [[Repository (version control)|repository]] ([https://github.com/mamedev/mame/ <mamedev/mame>][https://github.com/mamedev/mame/tree/master/src/devices/cpu/v60/ </src/devices/cpu/v60/>]). The ''[[operation code]]s'' in the file [https://github.com/mamedev/mame/blob/master/src/devices/cpu/v60/optable.hxx optable.hxx] are exactly the same as those of V60.<ref name=\"V60-Prog-Ref-Man\"/>\n\n== See also ==\n* [[NEC V20]]\n* [[V850]]\n* [[R4200]]\n\n== References ==\n\n{{reflist|colwidth=30em\uff5crefs=\n\n<!----------------->\n<!----- BOOKS ----->\n<!----------------->\n\n<!----- BOOKS, AUTHOR=NEC ----->\n\n<ref name=\"V60-Prog-Ref-Man\">\n{{cite book|author1=NEC|title=\u03bcPD70616 Programmer's Reference Manual|date=November 1986|publisher=The Internet Archive, a 501(c)(3) non-profit|edition=PRELIMINARY|url=https://archive.org/details/NEC_V60pgmRef|quote=<br/>EPUB, KINDLE, PDF, PDF w/text, FULL TEXT, etc, are available}}\n</ref>\n\n<ref name=\"V60-Datasheet\">\n{{cite book|title=1987 Microcomputer Data Book: Vol. 2|date=August 1986|publisher=NEC|pages=3-229\u20133-232|url=http://bitsavers.org/components/nec/_dataBooks/1987_Microcomputer_Products_Vol_2.pdf}}\n</ref>\n\n<ref name=\"V20-V50-progman\">\n{{cite book|author1=NEC|title=16-BIT V SERIES; INSTRUCTIONS|date=June 1997|publisher=The Internet Archive, a 501(c)(3) non-profit|edition=5|url=https://archive.org/details/bitsavers_necdatabooBITVSeriesJun97_693718|quote=<br/>EPUB, KINDLE, PDF, FULL TEXT, etc, are available.}}\n</ref>\n\n<ref name=\"Computer-Architecture-4thEd\">\n{{cite book|last1=Hennessy: Stanford University|first1=John L|last2=Patterson: University of California at Berkeley|first2=David A.|title=Computer Architecture: A Quantitative Approach|date=2007|publisher=MORGAN KAUFMANN PUBLISHERA|url=https://archive.org/details/2007ComputerArchitectureAQuantitativeApproach|isbn=978-0-12-370490-0|edition=Fourth|quote=<br/>Open Access: EPUB, KINDLE, PDF, FULL TEXT, etc, are available.}}\n</ref>\n\n<!----- BOOKS, JAPANESE ----->\n\n<ref name=\"maruzen\">\n{{Cite book |last=Kani |first=Dr. Kenji |date=April 1987 |trans-title=V-Series Microcomputer 2|title=V\u30b7\u30ea\u30fc\u30ba\u30de\u30a4\u30af\u30ed\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf 2|publisher=Maruzen | isbn=978-4621031575 |language=japanese|quote=<br/>\u672c\u66f8\u306f\u65e5\u672c\u96fb\u6c17(\u682a)\u304c\u3001\u308f\u304c\u56fd\u3067\u306f\u3058\u3081\u3066\u958b\u767a\u3057\u305f32\u30d3\u30c3\u30c8\u30de\u30a4\u30af\u30ed\u30d7\u30ed\u30bb\u30c3\u30b5V60\u306b\u3064\u3044\u3066\u89e3\u8aac\u3057\u305f\u3082\u306e\u3067\u3042\u308b\u3002[This book explains the V60, Japanese first developed 32-bit microprocessor by NEC.]}}\n</ref>\n\n<!----- BOOKS, AUTHOR NOT NEC ----->\n\n<ref name=\"Meth\u00e91991\">\n{{cite book|author=David T. Meth\u00e9|title=Technological Competition in Global Industries: Marketing and Planning Strategies for American Industry|url=https://books.google.com/books?id=_wHx9wlDVlcC&pg=PA128|year=1991|publisher=Greenwood Publishing Group|isbn=978-0-89930-480-9|page=128}}\n</ref>\n\n<!------------------->\n<!----- JOURNAL ----->\n<!------------------->\n\n<!----- JOURNAL, AUTHOR==NEC ----->\n\n<ref name=\"isscc1986\">\n{{cite journal|last1=Yano|first1=Y|last2=Iwasaki|first2=J|last3=Sato|first3=Y|last4=Iwata|first4=T|last5=Nakagawa|first5=K|last6=Ueda|first6=M|title=A 32b CMOS VLSI microprocessor with on-chip virtual memory management|journal=Solid-State Circuits Conference. Digest of Technical Papers. 1986 IEEE International|volume=XXIX|date=Feb 1986|pages=36\u201337|doi=10.1109/ISSCC.1986.1156924|publisher=IEEE|quote=<br/>The execution unit (EXU) is a microprogrammed 32b data path processor which has thirty-two 32b general-purpose registers, sixteen 32b scratch-pad registers, a 64b barrel shifter, a 32b arithmetic logic unit (ALU); and a couple of control registers. Three data-buses that are running}}<br/>\n{{cite journal|title=ditto|url=https://www.researchgate.net/publication/3994148|publisher=Research Gate|url-access=registration}}\n</ref>\n\n<ref name=\"acm86\">\n{{cite journal|last1=Kaneko|first1=H|last2=Miki|first2=Y|last3=Koya|first3=K|last4=Araki|first4=M|title=A 32-bit CMOS microprocessor with six-stage pipeline structure|journal=Proceedings of 1986 ACM Fall Joint Computer Conference|date=November 1986|pages=1000\u20131007|publisher=IEEE Computer Society Press|quote=<br/>Abstract<br/>32-bit microprocessors are the key devices which carry high data processing capability, that was obtained by earlier general purpose computer systems and mini-computer systems, in much lower cost. Earlier 32-bit microprocessors were limited to adopt excellent architecture and design using appropriate hardware by number of devices could be fabricated on a chip. Complex functions such as Virtual Memory management and \u2026\n}}<br/>\n{{cite journal|title=ditto|publisher=ACM|url-access=subscription|url=https://scholar.google.com/scholar?q=%22A+32-Bit+CMOS+Microprocessor+with+Six-Stage+Pipeline+Structure%22}}\n</ref>\n<ref name=\"IEEE-MICRO-FRM\">\n{{Cite journal | doi = 10.1109/40.527 | title = Implementation of the V60/V70 and its FRM function| journal = IEEE Micro| volume = 8| issue = 2| pages = 22\u201336| date =April 1988| last1 = Kimura | first1 = S.| last2 = Komoto | first2 = Y.| last3 = Yano | first3 = Y.|quote=<br/>Abstract:<br/>A description is given of the V60/V70, the first commercially based, general-purpose 32-bit microprocessor in Japan. Its functions include on-chip floating-point operations, a high-level-language-oriented architecture, software debugging support, and support functions to promote a high level of system reliability. Because high reliability is so important, the V60/V70 contains functional redundancy monitoring (FRM) support functions. The discussion covers the overall design considerations, architecture, implementation, hazard detection and control, and FRM functions. The V60/V70 uses a TRON real-time operating system specification.}}\n</ref>\n\n<ref name=\"compcon1988\">\n{{Cite book | doi = 10.1109/CMPCON.1988.4824 | isbn = 0-8186-0828-5 | title = V60/V70 microprocessor and its systems support functions | publisher = Digest of Papers. COMPCON Spring 88 Thirty-Third IEEE Computer Society International Conference | pages = [https://archive.org/details/compconspring8830000ieee/page/36 36\u201342] | date = Spring 1988 | last1 = Yano | first1 = Y. | last2 = Koumoto | first2 = Y. | last3 = Sato | first3 = Y. | quote = <br/>Abstract:<br/>Two advanced 32-bit microprocessors, the V60 and V70 ( mu PD70616 and mu PD70632, respectively), and their support functions for operating systems and high-reliability systems are described. Three operating system functions, namely, the virtual memory support functions, context-switch functions, and asynchronous trap functions are examined. A basic mechanism for high-reliability-system implementation, called FRM (functional redundancy monitoring), is discussed. FRM allows a system to be designed in which multiple V60s (or V70s) form a configuration in which one processor in the system acts as a master while the others act as monitors. An FRM board that uses three V60s in its redundant core is introduced. | url = https://archive.org/details/compconspring8830000ieee/page/36 }}\n</ref>\n\n<ref name=\"micro1990\">\n{{cite journal|last1=Kaneko|first1=Hiroaki|last2=Suzuki|first2=Nariko|last3=Wabuka|first3=Hhiroaki|last4=Maemura|first4=Koji|title=Realizing the V80 and its system support functions|journal=IEEE Micro|date=April 1990|volume=10|issue=2|pages=56\u201369|doi=10.1109/40.52947|issn=0272-1732|quote=<br/>Abstract:<br/>An overview is given of the architecture of an overall design considerations for the 11-unit, 32-b V80 microprocessor, which includes two 1-kB cache memories and a branch prediction mechanism that is a new feature for microprocessors. The V80's pipeline processing and system support functions for multiprocessor and high-reliability systems are discussed. Using V80 support functions, multiprocessor and high-reliability systems were realized without any performance drop. Cache memories and a branch prediction mechanism were used to improve pipeline processing. Various hardware facilities replaced the usual microprogram to ensure high performance.}}\n<br/>{{Cite journal|title=ditto|journal=IEEE Micro|volume=10|issue=2|pages=56\u201369|publisher=ACM|url-access=subscription|url=https://dl.acm.org/citation.cfm?id=623503|doi=10.1109/40.52947|date=March 1990|last1=Kaneko|first1=Hiraoki|last2=Suzuki|first2=Nariko|last3=Wabuka|first3=Hiroshi|last4=Maemura|first4=Koji}}</ref>\n\n<ref name=\"IEEE-MICRO-FRM\">\n{{Cite journal | doi = 10.1109/40.527 | title = Implementation of the V60/V70 and its FRM function| journal = IEEE Micro| volume = 8| issue = 2| pages = 22\u201336| date =April 1988| last1 = Kimura | first1 = S.| last2 = Komoto | first2 = Y.| last3 = Yano | first3 = Y.|quote=<br/>Abstract:<br/>A description is given of the V60/V70, the first commercially based, general-purpose 32-bit microprocessor in Japan. Its functions include on-chip floating-point operations, a high-level-language-oriented architecture, software debugging support, and support functions to promote a high level of system reliability. Because high reliability is so important, the V60/V70 contains functional redundancy monitoring (FRM) support functions. The discussion covers the overall design considerations, architecture, implementation, hazard detection and control, and FRM functions. The V60/V70 uses a TRON real-time operating system specification.}}\n</ref>\n\n<ref name=\"coproc\">\n{{Cite journal | doi = 10.1109/JSSC.1989.572608|issn=1558-173X| title = A 6.7-MFLOPS floating-point coprocessor with vector/matrix instructions| journal = IEEE Journal of Solid-State Circuits| volume = 24| issue = 5| pages = 1324\u20131330| date =Oct 1989| last1 = Nakayama | first1 = T.| last2 = Harigai | first2 = H.| last3 = Kojima | first3 = S.| last4 = Kaneko | first4 = H.| last5 = Igarashi | first5 = H.| last6 = Toba | first6 = T.| last7 = Yamagami | first7 = Y.| last8 = Yano | first8 = Y.|quote=<br/>Abstract:<br/>An 80-bit floating-point coprocessor which implements 24 vector/matrix instructions and 22 mathematical functions is described. This processor can execute floating-point addition/rounding and pipelined multiplication concurrently, under the control of horizontal-type microinstructions. The SRT division method and CORDIC trigonometrical algorithm are used for a favorable cost/performance implementation. The performance of 6.7 MFLOPS in the vector-matrix multiplication at 20&nbsp;MHz has been attained by the use of parallel operations. The vector/matrix instruction is about three times faster than conventional add and multiply instructions. The chip has been fabricated in 1.2- mu m double-metal layer CMOS process containing 433000 transistors on an 11.6*14.9-mm/sup 2/ die size.| bibcode=1989IJSSC..24.1324N }}\n</ref>\n\n<ref name=\"overview\">\n{{cite journal |last1=Komoto |first1=Yasuhiko |last2=Saito |first2=Tatsuya|last3=Mine|first3=Kazumasa |date=1990-08-25 |title=Overview of 32-bit V-Series Microprocessor |format=pdf | url= https://ipsj.ixsq.nii.ac.jp/ej/index.php?action=pages_view_main&active_action=repository_action_common_download&item_id=59745&item_no=1&attribute_id=1&file_no=1&page_id=13&block_id=8 |journal=Journal of Information Processing |volume=13 |issue=2 |pages=110\u2013122 |doi= |issn=1882-6652 |language=en|access-date=2018-01-08|quote=Open Access<br/>Abstract:<br />The advances in semiconductor manufacturing technology make it possible to integrate a floating-point unit and a memory management unit noto one microprocessor chip. They also permit the designers of a microprocessor to implement techniques used in the design of mainframe computers especially with regard to pipeline structures. The architecture of the V60 V70 and V80 was made possible by there advances. The V60 and V70 are NEC's first 32-bit microprocessors and include almost all the functions required by applied systems in a chip. The instruction set provides a high-level-language-oriented structure operating system sup-port functions and support functions for highly reliable systems. The V80 also employs the same architecture and achieves higher performance by means of cache memories and branch prediction mechanisms. The V80achieved a performance from two to four times higher than that of the V70.}}\n</ref>\n\n<!----- JOURNAL, SOFTWARE ----->\n\n<ref name=\"PC-UX-R2-V60\">\n{{cite journal|url=http://id.nii.ac.jp/1001/00113909/|format=pdf|publisher=Information Society of Japan|title=PORTING UNIX System&nbsp;V TO THE V60 SYSTEMS|journal=\u5168\u56fd\u5927\u4f1a\u8b1b\u6f14\u8ad6\u6587\u96c6|volume=\u7b2c33\u56de|issue=\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u304a\u3088\u3073\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2|pages=163\u2013164|language=Japanese|access-date=2018-01-07|date=October 1986|last1=\u96c5\u5247|first1=\u5bfa\u672c|last2=\u5065\u6cbb|first2=\u8d64\u7fbd|last3=\u826f\u5f66|first3=\u548c\u7530|last4=\u7531\u7d00\u5b50|first4=\u6c34\u6a4b|last5=\u6ecb|first5=\u5ddd\u53c8}}\n</ref>\n\n<ref name=\"RX-UX-832\">\n{{Cite journal | doi = 10.1016/0165-6074(89)90105-1| title = Real-time UNIX operating system: RX-UX 832| journal = Microprocessing and Microprogramming| volume = 27| issue = 1\u20135| pages = 533\u2013538| date = August 1989| last1 = Mizuhashi | first1 = Yukiko | last2 = Teramoto | first2 = Msanoro |quote= <br/>Abstract:<br/>This paper describes requirements for real-time UNIX operating systems, design concept and the implementation of RX-UX 832 real-time UNIX operating system for v60/v70 microprocessor which are NEC's 32-bit microprocessors. RX-UX 832 is implemented adopting the building block structure, composed of three modules, real-time kernel, file-server and Unix supervisor. To guarantee a real-time responsibility, several enhancements were introduced such as, fixed priority task scheduling scheme, contiguous block file system and fault tolerant functions.<br/>Thus, RX-UX 832 allows system designers to use standard Unix as its man-machine interface to build fault tolerant systems with sophisticated operability and provides high-quality software applications on the high performance microchips. }}\n</ref>\n\n<ref name=\"Suzuki1992\">\n{{cite book|author=Norihisa Suzuki|title=Shared Memory Multiprocessing|url=https://books.google.com/books?id=Hyn9Cqf8PZsC&pg=PA195|date=January 1992|publisher=MIT Press|isbn=978-0-262-19322-1|page=195}}\n</ref>\n\n<ref name=\"8-V70-Proc\">\n[http://www.dtic.mil/dtic/tr/fulltext/u2/a240438.pdf Office of Naval Research Asian Office, Scientific Information Bulletin, Vol 16, No. 3 July-September 1991], p. 3\n</ref>\n\n<ref name=\"Inc.1991\">\n{{cite journal|author=Brett Glass|title=Answer Line|url=https://books.google.com/books?id=VlAEAAAAMBAJ&pg=PA72|date=6 May 1991|journal=InfoWorld|page=72|issn=0199-6649}}\n</ref>\n\n<ref name=\"FLEXOS\">\n{{cite journal |title=Digital Research launches FlexOS 286 Real-Time Manufacturing Operating System |editor=CBR |journal=Computer Business Review |date=1987-01-15 |url=http://www.cbronline.com/news/digital_research_launches_flexos_286_real_time_manufacturing_operating_system |access-date=2018-09-15 |url-status=live |archive-url=https://archive.is/U9oeA |archive-date=2013-01-18}}</ref>\n<ref name=rtos1997>\n{{cite journal |last1=Shimojima |first1=Takehiko |last2=Teramoto |first2=Masanori|year=1987 |title=V60 real-time operating system |journal=Microprocessing and Microprogramming|volume=21 |issue=1\u20135 |pages=197\u2013204 |doi=10.1016/0165-6074(87)90038-X|issn=0165-6074|quote=<br/>Abstract:<br/>This paper describes the requirements for 32-bit microprocessor real-time operating systems, design objectives and the implementation of the V60/V70 Real-Time Operating System (RTOS) and its programming supports.}}\n</ref>\n\n<!----- JOURNAL, CAD ----->\n\n<ref name=\"cad\">\n{{cite journal|last1=Kurosawa|first1=A.|last2=Yamada|first2=K.|last3=Kishimoto|first3=A.|last4=Mori|first4=K.|last5=Nishiguchi|first5=N.|title=A Practical CAD System Application for Full Custom VLSI Microcomputer Chips|journal=IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems|date=May 1987|volume=6|issue=3|pages=364\u2013373|doi=10.1109/TCAD.1987.1270281|issn=1937-4151|quote=<br/>Abstract:<br/>This paper presents a practical CAD system application for layout and verification, resulting in producible full-cutom VLSI microcomputer chips. The CAD system supports three design methodologies--symbolic layout mixed with mask level layout, compaction as an optimizer, and fully automated verification. For the area optimization, the symbolic layout and compactor subsystem supports a flexible description of orthogonal layout patterns with arbitrary dimensions in a loose placement manner. The layout patterns include path data, polygonal data, and symbolic cells. For power and delay optimization, the compactor compacts layout data, decreasing both resistance and capacitance for wires and ion-implanted layers. This feature is pioneering the new generation compactor. Emphasis should be put on the fact that it can compact layout data to a format 10-15 percent smaller than that accomplished manually. The verification subsystem can detect all kinds of errors, more than 30 items. A novel feature of the electrical rule check is that it investigates complementary logic errors for CMOS circuits. The synergy of those three design methodologies has brought about several significant advantages. One is manpower reduction by more than half, in the most complicated design process for unique random logic. The other is a 1600-transistors compaction output, smaller by 365 mils/sup 2/ than that manually compacted. The circuit implementation on a chip works at more than a 15&nbsp;MHz clock rate. Another is the first silicon success. It has been accomplished in a full-custom VLSI microcomputer chip consisting of more than 100 000 transistors.}}\n</ref>\n\n<!----- JOURNAL, V800 ----->\n\n<ref name=\"1992-ARC-06\">\n{{cite journal|last1=Harigai|first1=Hisao|last2=Kusuda|first2=Masaori|last3=Kojima|first3=Shingo|last4=Moriyama|first4=Masatoshi|last5=Ienaga|first5=Takashi|last6=Yano|first6=Yoichi|title=\u4f4e\u6d88\u8cbb\u96fb\u529b\u30fb\u4f4e\u96fb\u5727\u52d5\u4f5c\u306e32\u30d3\u30c3\u30c8\u30de\u30a4\u30af\u30ed\u30d7\u30ed\u30bb\u30c3\u30b5V810|journal=SIG Technical Reports, Information Processing Society of Japan|date=1992-10-22|volume=1992|issue=82 (1992-ARC-096)|pages=41\u201348|url=https://ci.nii.ac.jp/naid/170000021173|trans-title=A low power consumption and low voltage operation 32-bit RISC Microprocessor|quote=<br/>Abstract:<br/>An advanced 32-bit RISC microprocessor for embedded control; V810 is introduced in this paper. The V810 has high performance and application specified functions. V810 dissipates less power than any other RISC chips. The V810 is the first 32-bit RISC microprocessor that operates at 2.2V.<br/>The V810 chip is fabricated by using 0.8\u03bcm CMOS double metal layer process technology to integrate 240,000 transistors on a 7.7\u00d77.7mm<sup>2</sup> die.}}\n</ref>\n\n<ref name=\"IEIEC-1995\">\n{{cite journal|last1=Suzuki|first1=Hiroaki|last2=Sakai|first2=Toshichika|last3=Harigai|first3=Hisao|last4=Yano|first4=Yoichi|title=A 0.9-V, 2.5&nbsp;MHz CMOS 32-bit Microprocessor|journal=IEICE TRANSACTIONS on Electronics|date=1995-04-25|volume=E78-C|issue=4|pages=389\u2013393|url-access=subscription|url=http://search.ieice.org/bin/summary.php?id=e78-c_4_389&category=C&year=1995&lang=E|accessdate=2018-01-09|issn=0916-8516|quote=<br/>Summary:<br/>A 32-bit RISC microprocessor \"V810\" that has 5-stage pipeline structure and a 1 Kbyte, direct-mapped instruction cache realizes 2.5&nbsp;MHz operation at 0.9 V with 2.0 mW power consumption. The supply voltage can be reduced to 0.75 V. To overcome narrow noise margin, all the signals are set to have rail-to-rail swing by pseudo-static circuit technique. The chip is fabricated by a 0.8 \u03bcm double metal-layer CMOS process technology to integrate 240,000 transistors on a 7.4 mm7.1 mm die.}}\n</ref>\n\n<ref name=\"IEEE-1998\">\n{{cite journal |last1=Suzuki |first1=K. |last2=Arai |first2=T. |last3=Nadehara|first3=K.| last4=Kuroda|first4=I.|year=1998 |title=V830R/AV: embedded multimedia superscalar RISC processor |url= |journal=IEEE Micro |volume=18 |issue=2 |pages=36\u201347 |issn=0272-1732|doi=10.1109/40.671401 |access-date=|quote=<br/>Abstract:<br/>The V830R/AV's real-time decoding of MPEG-2 video and audio data enables practical embedded-processor-based multimedia systems.}}\n</ref>\n\n<!----- JOURNAL, JAPANESE ----->\n\n<ref name=\"SIG-ARC-043\">\n{{cite journal|last1=Yamahata|first1=Hitoshi|last2=Suzuki|first2=Nariko|last3=Koumoto|first3=Yasuhiko|last4=Shiiba|first4=Tadaaki|title=\u30de\u30a4\u30af\u30ed\u30d7\u30ed\u30bb\u30c3\u30b5V60\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3|journal=SIG Technical Reports; Microcomputer 43-2|date=1987-02-06|volume=1987|issue=8(1986-ARC-043)|pages=1\u20138|url=https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_uri&item_id=24887&file_id=1&file_no=1|trans-title=Architecture of the microprocessor V60|publisher=Information Processing Society of Japan|language=ja|format=PDF|id=AN10096105|quote=<br/>This report will describe a single chip 32-bit CMOS VLSI microprocessor V60. It has been implemented by using a double metal-layer CMOS process technology with 1.5 um design rule to integrate 375,000 transistors. It integrates the virtual memory management unit for demand paging and the floating-point operations that conform to the IEEE-754 Floating-Point Standard. By using V20/V30 emulation mode, it can directly execute object programs of 16-bit CPU (V30). Instruction formats are suited to code-generation phase of compilers. 237 instructions are provided for high-level language and operating system. It can execute 3.5 MIPS (Million Instructions per Second) at 16-MHz operation with 16-bit data bus.}}\n</ref>\n\n<ref name=\"SIG-ARC-069\">\n{{cite journal|last1=Takahashi|first1=Toshiya|last2=Yano|first2=Yoichi|title=V60/V70\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3|journal=SIG Technical Reports|date=1988-01-21|volume=1988|issue=4(1987-ARC-069)|pages=57\u201364|url=https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_uri&item_id=24816&file_id=1&file_no=1|trans-title=The Architecture of V60/V70 Microprocessors|publisher=Information Processing Society of Japan|language=ja|format=PDF|id=AN10096105|quote=<br/>This report describes the architecture of V60/V70 32-bit microprocessors. The architecture integrates various features into a single silicon die, such as a rich set of general purpose registers, high level language oriented instruction set, floating-point data handling which is suitable for scientific applications, and the FRM (Functionality Redundancy Monitoring) operation mode which supports highly-reliable systems configuration. These features will be introduced.}}\n</ref>\n\n<ref name=\"dev-story\">\n{{Cite web|url=http://www.shmj.or.jp/dev_story/pdf/develop46.pdf|first1=Yoichi|last1=Yano|date=April 2012|publisher=Semiconductor History Museum of Japan|language=Japanese|access-date=2018-01-08|title=32\u30d3\u30c3\u30c8\u30fb\u30de\u30a4\u30b3\u30f3\u300cV60\u300d\u958b\u767a\u7269\u8a9e|trans-title=Development story of the 32-bit microcomputer V60}}<br/>\n{{Cite journal|format=pdf|url=http://www.ssis.or.jp/encore/encore2012.html#no75|journal=Bulletin \"Encore\"|date=April 2012|volume=75|pages=17\u201320|publisher=Society of Semiconductor Industry Specialists|title=ditto|language=Japanese|access-date=2018-01-08}}\n</ref>\n\n<ref name=\"32b-itron\">\n{{cite journal|last1=Monden|first1=Hiroshi|last2=Teramoto|first2=Takashi|last3=Koga|first3=Masanori|title=V60\u7528\u30a2\u30eb\u30bf\u30a4\u30e0OS\u306e\u691c\u8a0e\u3000\uff0d32\u30d3\u30c3\u30c8I&#8209;TRON\u306b\u5411\u3051\u3066\uff0d|journal=SIG (ARC) Technical Reports|date=1986-03-14|volume=1986|issue=19(1985-ARC-061)|pages=1\u20138|url=https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_action_common_download&item_id=24938&item_no=1&attribute_id=1&file_no=1|trans-title=Feasibility study of real-time OS for the V60 - toward for the 32-bit I&#8209;TRON -|publisher=Information Processing Society of Japan|language=Japanese|format=PDF|id=AN10096105|quote=Open Access}}</ref>\n\n<!----- JOURNAL, NEC-TECHNICAL ----->\n\n<ref name=\"nectech-jaxagcc\">\nHAYASHI, N. [http://www.nec.com/en/global/techrep/journal/g11/n01/pdf/110130.pdf Guidance Control Computer for Launch Vehicle], NEC Technical Journal, Vol. 6, No. 1/2001, pp. 145-148\n</ref>\n\n<ref name=\"nec-tecj-ms4100\">\n{{Cite journal|url=http://jglobal.jst.go.jp/en/public/20090422/200902041619492749|title=The outline of NEC super minicomputer MS4100 Series, NEC Technical Journal |journal=Nec\u6280\u5831 |volume=39 |issue=11 |pages=113\u2013124 |publisher=NEC Technical Journal, Vol.39 Iss.11 p.p.113-124, Nov. 1986|language=Japanese|year=1986 |last1=Takeo |first1=Sakurai |last2=Osamu |first2=Oizumi }}\n</ref>\n\n<!----- JOURNAL, Meidensha Corp ----->\n\n<ref name=\"Meiden-Jiho-Jul92\">\n{{cite journal|last1=OSAMU|first1=TSUJI|last2=SATORU|first2=KOMIYAMA|last3=TOSHIYUKI|first3=DOI|last4=TETSUYA|first4=IWAKI|title=\u60c5\u5831\u6a5f\u5668 \u5de5\u696d\u7528\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u03bcPORT\u2010III|journal=\u660e\u96fb\u6642\u5831 [Meiden Jiho]|date=July 1992|issue=225|pages=24\u201332|url=http://jglobal.jst.go.jp/en/public/20090422/200902079033599746|trans-title=Information-processing equipment.Industrial computer .MU.PORT-III.|language=ja|issn=0386-1570}}\n</ref>\n\n<ref name=\"Meiden-Jiho-May93\">\n{{cite journal|last1=HISAO|first1=SASAKI|last2=AKIRA|first2=SATO|last3=TOSHIO|first3=KARAKAMA|title=\u5de5\u696d\u7528\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u03bcPORT\u2010III\u3068\u9069\u7528\u4e8b\u4f8b|journal=\u660e\u96fb\u6642\u5831 [Meiden Jiho]|date=May 1993|issue=230|pages=41\u201344|url=http://jglobal.jst.go.jp/en/public/20090422/200902104337850113|trans-title=Applications of industrial computer .MU.PORT-III.|language=ja|issn=0386-1570}}\n</ref>\n\n<!----- JOURNAL, AUTHOR==OTHERS ----->\n\n<ref name=\"MIPS-1984\">\n{{cite journal|last1=Rowen|first1=C.|last2=Przbylski|first2=S.|authorlink3=Norman Jouppi|last3=Jouppi|first3=N.|last4=Gross|first4=T.|last5=Shott|first5=J.|last6=Hennessy|first6=J.|title=A pipelined 32b NMOS microprocessor|journal=1984 IEEE International Solid-State Circuits Conference. Digest of Technical Papers|date=1984|volume=XXVII|pages=180\u2013181|doi=10.1109/ISSCC.1984.1156607|quote=<br/>Stanford MIPS}}\n</ref>\n\n<ref name=\"RISC-II\">\n{{cite journal|last1=Sherburne|first1=R. W.|last2=Katevenis|first2=M. G. H.|last3=Patterson|first3=D. A.|last4=Sequin|first4=C. H.|title=A 32-bit NMOS microprocessor with a large register file|journal=IEEE Journal of Solid-State Circuits|date=1984|volume=19|issue=5|pages=682\u2013689|doi=10.1109/JSSC.1984.1052208|issn=0018-9200|quote=<br/>UCB RISC-II|bibcode=1984IJSSC..19..682S}}\n</ref>\n\n<ref name=\"R2000\">\n{{cite journal|last1=Riordan|first1=T.|last2=Grewal|first2=G. P.|last3=Hsu|first3=S.|last4=Kinsel|first4=J.|last5=Libby|first5=J.|last6=March|first6=R.|last7=Mills|first7=M.|last8=Ries|first8=P.|last9=Scofield|first9=R.|title=The MIPS M2000 system|journal=Proceedings 1988 IEEE International Conference on Computer Design: VLSI|date=1988|pages=366\u2013369|doi=10.1109/ICCD.1988.25724|quote=<br/>MIPS M2000 (R2000)|isbn=0-8186-0872-2}}\n</ref>\n\n<ref name=\"First-SPARC\">\n{{cite journal|last1=Namjoo|first1=M.|last2=Agrawal|first2=A.|last3=Jackson|first3=D. C.|last4=Quach|first4=L.|title=CMOS gate array implementation of the SPARC architecture|journal=Digest of Papers. COMPCON Spring 88 Thirty-Third IEEE Computer Society International Conference|date=1988|pages=[https://archive.org/details/compconspring8830000ieee/page/10 10\u201313]|doi=10.1109/CMPCON.1988.4818|url=https://archive.org/details/compconspring8830000ieee/page/10|quote=<br/>SPARC, 1st Gen.|isbn=0-8186-0828-5}}\n</ref>\n\n<ref name=\"i860\">\n{{cite journal|last1=Kohn|first1=L.|last2=Fu|first2=S. W.|title=A 1,000,000 transistor microprocessor|journal=IEEE International Solid-State Circuits Conference, 1989 ISSCC. Digest of Technical Papers|date=1989|pages=54\u201355|doi=10.1109/ISSCC.1989.48231|quote=<br/>Intel 860}}\n</ref>\n\n<ref name=\"i486-ICCD89\">\n{{cite journal|last1=Fu|first1=B.|last2=Saini|first2=A.|last3=Gelsinger|first3=P. P.|title=Performance and microarchitecture of the i486 processor|journal=Proceedings 1989 IEEE International Conference on Computer Design: VLSI in Computers and Processors|date=1989|pages=182\u2013187|doi=10.1109/ICCD.1989.63352|isbn=0-8186-1971-6|quote=<br/>Intel 80486<br/>Abstract:<br/>The i486 microprocessor includes a carefully tuned, five-stage pipeline with an integrated 8-kB cache. A variety of techniques previously associated only with RISC (reduced-instruction-set computer) processors are used to execute the average instruction in 1.8 clocks. This represents a 2.5* reduction from its predecessor, the 386 microprocessor. The pipeline and clock count comparisons are described in detail. In addition, an onchip floating-point unit is included which yields a 4* clock count reduction from the 387 numeric coprocessor. The microarchitecture enhancements and optimizations used to achieve this goal, most of which are non-silicon-intensive, are discussed. All instructions of the 386 microprocessor and the 387 numeric coprocessor are implemented in a completely compatible fashion.}}\n</ref>\n\n<ref name=\"i486-Micro-1990\">\n{{cite journal|last1=Crawford|first1=J.H.|title=The i486 CPU: executing instructions in one clock cycle|journal=IEEE Micro|date=February 1990|volume=10|issue=1|pages=27\u201336|doi=10.1109/40.46766|issn=0272-1732|citeseerx=10.1.1.126.4216}}\n</ref>\n\n<ref name=\"pj\">\n{{cite journal|last1=Hardenbergh |first1=Hal W | title=RISCs CISCs and Fabs|journal=Programmer's Journal|year=1988|publisher=Avant-Garde Creations|volume=6|issue=2|page=15|quote=<br/>So far we haven't mentioned two 32-bit CISC chips, the NEC V60/70 and the AT&T WE32 family. Unlike the NEC V20/25/30/50, the V60/70 is ''not'' based on the Intel architecture. NEC is targeting the V60/70 at embedded applications, ... }}\n[https://books.google.com/books?id=iX8qAAAAMAAJ&q=V60/70 Google Books]\n</ref>\n\n<ref name=\"trend\">\n{{cite journal |last1=Sakamura|first1=Ken|date=April 1988 |title=Recent Trends |url=http://www.computer.org/csdl/mags/mi/1988/02/m2010.pdf |journal=IEEE Micro |volume=8 |issue=2 |pages=10\u201311 |doi= |issn=0272-1732|pmc= |pmid= |access-date=2018-01-08 |quote=<br/>The V60/V70, NEC's proprietary CPU, is the first commercial-base, general-purpose, 32-bit microprocessor in Japan.}}\n</ref>\n\n<ref name=\"Wade, 1996\">\n{{cite journal|last1=Wade|first1=James|title=A Community-Level Analysis of Sources and Rates of Technological Variation in the Microprocessor Market|journal=Academy of Management Journal|date=1 October 1996|volume=39|issue=5|pages=1218\u20131244|doi=10.2307/256997|url=http://amj.aom.org/content/39/5/1218.short|language=en|issn=0001-4273|quote=<br/>7 The sponsors that did not use RISC technology were NEC, AT&T, and Followers of the TRON standard. All three of these microprocessors were specialized for users for whom performance was the highest priority. The Hitachi microprocessor followed the TRON standard, a high-performance CISC technology that, Japanese developers suggested, would be a viable alternative to RISC. The AT&T chip was portrayed as a chip suitable for building top-of-the-line, minicomputer-like computing systems. Similarly, NEC's V60 and V70 were patterned after one of NEC's 36-bit mainframe computers.|jstor=256997}}\n</ref>\n\n<ref name=\"Majithi, 1987\">\n{{cite journal|last1=Majithi|first1=Kenneth|title=The New Generation of Microprocessors|journal=IEEE Micro|date=1987|volume=7|issue=4|pages=4\u20135|doi=10.1109/MM.1987.304873|issn=0272-1732|quote=<br/>The Japanese have been equally aggressive in their new designs of high-performance microprocessors. NEC's V60 and V70 microprocessors use architectures that include not only the MMU but also an arithmetic floating-point unit on chip. Hitachi and Fujitsu have collaborated to produce a family of microprocessors adapted to the TRON operating system. These processors incorporate instruction pipelines as well as instruction and stack caches. However, unlike NEC, their FPU function is off chip.}}\n</ref>\n\n<!------------------->\n<!----- CATALOG ----->\n<!------------------->\n\n<ref name=\"cat-fr\">\n{{cite web|author1=NEC|title=Microprocessors and Peripherals Data Book|url=http://matthieu.benoit.free.fr/cross/data_sheets/NEC_Microprocessors-and-Peripherals_Data_Book.htm}}\n</ref>\n\n<ref name=\"cat89\">\n{{cite book|author1=NEC|title=Intelligent Peripheral Devices Data Book|url=https://archive.org/details/bitsavers_necdataBootPeripheralDevicesDataBook_33483764|publisher=The Internet Archive, a 501(c)(3) non-profit|page=18|date=June 1989}}\n</ref>\n\n<ref name=\"cat90\">\n{{cite book|author1=NEC|title=Single-Chip Microcontroller Data Book|url=https://archive.org/details/bitsavers_necdatabooMicrocontrollerDataBook_57118308|publisher=The Internet Archive, a 501(c)(3) non-profit|page=30|date=May 1990}}\n</ref>\n\n<ref name=\"cat95\">\n{{cite web|author1=NEC|title=SEMICONDUCTOR SELECTION GUIDE|edition=10th|date=Oct 1995|url=http://icbank.com/data/ICBShop/board/D72611GF.pdf}}\n</ref>\n\n<ref name=\"cat99\">\n{{cite web|author1=NEC|title=SEMICONDUCTORS SELECTION GUIDE|edition=17th|url=http://www.littlediode.com/datasheets/pdf/Datasheets-NEC/NEC-SHORTFORM.PDF|date=April 1999}}\n</ref>\n\n<ref name=\"cat05\">\n{{cite web|title=Microcontrollers and Development Tools Selection Guide|url=http://www1.futureelectronics.com/doc/RENESAS%20ELECTRONICS/NECMicrocontrollerGuide%5B1%5D.pdf|author=NEC|date=May 2005}}\n</ref>\n\n<!------------------------>\n<!----- WEB MATERIAL ----->\n<!------------------------>\n\n<!----- WEB, ACADEMIC ----->\n\n<ref name=ric-tan>\n{{cite web|url=http://www.stanford.edu/group/htgg/sts145papers/rtan_2001_2.pdf|author=Richard Tan|title=STS 145 Case Study Sega: The effect of corporate conflict on game design| quote=<br/>\"The Saturn originally ran on a NEC V60 chip at 16MHz. Compare this to the PlayStation CPU ([[MIPS architecture|MIPS]] R3000A 32bit [[Reduced instruction set computer|RISC]] chip) which runs are 33.8MHz, almost double the speed. According to one Sega staff member, when Nakayama first received design specifications for the PlayStation, he was \u2018the maddest I have ever seen him\u2019, calling up the entire R&D division to his office to shout at them. An effort was made to compensate by adding another CPU for dual operation; however, this solution made the system so hard to develop for that, according to Yu Suzuki himself, \u201conly 1 out of 100 programmers could use the Saturn to its full potential.\u201d\"}}\n</ref>\n\n<!----- WEB, NEC ----->\n\n<ref name=\"ps98-145-hmw\">\n{{Cite web|url=http://121ware.com/support/product/data/spec/sft/sw225d-1.html |title=Model Number: PS98-145-HMW, Item Name: PC-UX/V(Rel2.0)(V60) |publisher=NEC product sheet}}\n</ref>\n\n<!----- WEB, GHS ----->\n\n<ref name=\"GHS-V850\">\n{{cite web|title=V850 and RH850 Embedded Software Solutions|url=https://www.ghs.com/products/v850_development.html|website=www.ghs.com|publisher=Green Hills Software}}\n</ref>\n\n<!----- WEB, MIPS ----->\n\n<ref name=\"HIREC-HR5000\">\n{{cite web|last1=Voica|first1=Alex|title=Back to the future: 64-bit MIPS CPU explores the origins of the solar system \u2013 MIPS|url=https://www.mips.com/blog/back-to-the-future-64-bit-mips-cpu-explores-rare-asteroid/|website=www.mips.com|publisher=MIPS|language=en|date=2015-07-29}}\n</ref>\n\n<ref name=\"MIPS64-5Kf-DS\">\n{{cite book|title=MIPS64 5Kf Processor Core Datasheet|date=2005-01-31|publisher=MIPS Technologies Inc.|edition=01.04|url=http://wiki.prplfoundation.org/w/images/f/f1/MD00111-2B-4KEC-DTS-02.03.pdf|language=en}}\n</ref>\n\n<!----- WEB, MAME DEV ----->\n\n<ref name=\"v60-cemu\">\n{{cite web|url=http://mamedev.org/source/src/emu/cpu/v60/v60.c.html |title=MAME:/src/emu/cpu/v60/v60.c |publisher=Mamedev.org |date= |accessdate=2014-02-15 |archiveurl=https://web.archive.org/web/20140222070653/http://mamedev.org/source/src/emu/cpu/v60/v60.c.html |archivedate=2014-02-22 }}\n</ref>\n\n<ref name=\"mamedev1\">\n{{cite web|url=http://mamedev.org/source/src/mame/drivers/segas32.c.html |title=MAME:/src/mame/drivers/segas32.c |publisher=Mamedev.org |date= |accessdate=2014-02-15 |archiveurl=https://web.archive.org/web/20140403190647/http://mamedev.org/source/src/mame/drivers/segas32.c.html |archivedate=2014-04-03}}\n</ref>\n\n<ref name=\"mamedev-model1\">\n{{cite web|url=http://mamedev.org/source/src/mame/drivers/model1.c.html |title=MAME:/src/mame/drivers/model1.c |publisher=Mamedev.org |date= |accessdate=2014-02-15 |archiveurl=https://web.archive.org/web/20140403180645/http://mamedev.org/source/src/mame/drivers/model1.c.html |archivedate=2014-04-03}}\n</ref>\n\n<ref name=\"mamedev-ssv\">\n{{cite web|url=http://mamedev.org/source/src/mame/drivers/ssv.c.html |title=MAME:/src/mame/drivers/ssv.c |publisher=Mamedev.org |date= |accessdate=2014-02-15 |archiveurl=https://web.archive.org/web/20140403215238/http://mamedev.org/source/src/mame/drivers/ssv.c.html |archivedate=2014-04-03}}\n</ref>\n\n<ref name=\"mamedev-mc32\">\n{{cite web|url=http://mamedev.org/source/src/mame/drivers/ms32.c.html |title=MAME:/src/mame/drivers/ms32.c |publisher=Mamedev.org |date= |accessdate=2014-02-15 |archiveurl=https://web.archive.org/web/20140403182226/http://mamedev.org/source/src/mame/drivers/ms32.c.html |archivedate=2014-04-03}}\n</ref>\n\n<!----- WEB, PLANET VIRTUAL BOY ----->\n\n<ref name=\"V810-GCC\">\n{{cite web|title=A newer GCC compiler. \u00ab Virtual Boy Development Board \u00ab Forum \u00ab Planet Virtual Boy|url=http://www.planetvb.com/modules/newbb/viewtopic.php?topic_id=6456|website=www.planetvb.com|language=en}}\n</ref>\n\n<!----- WEB, DATAQUEST ----->\n\n<ref name=\"dataquest-1986\">\n[[Dataquest]], \"Japanese Semiconductor Industry Service\", 1st Quarter 1986, p. 18 (pdf p. 44 in [http://archive.computerhistory.org/resources/access/text/2013/04/102723432-05-01-acc.pdf this multi-volume archive])\n</ref>\n\n<ref name=\"dataquest-1987\">\n[[Dataquest]], \"Japanese Semiconductor Industry Service\", 1st Quarter 1987, p. 18 (pdf p. 182 in [http://archive.computerhistory.org/resources/access/text/2013/04/102723432-05-01-acc.pdf this multi-volume archive])</ref>\n\n<ref name=\"dataquest-1987-2\">\n[[Dataquest]], \"Japanese Semiconductor Industry Service\", 2nd Quarter 1987, p. 21 (pdf p. 223 in [http://archive.computerhistory.org/resources/access/text/2013/04/102723432-05-01-acc.pdf this multi-volume archive])</ref>\n\n<!----- WEB, COMPUTER BUSINESS REVIEW ----->\n\n<ref name=\"CBR-1\">\nNEC LAUNCHES V80 ANSWER TO INTEL's 80486 - Computer Business Review, 1989-03-15\nBalcklist:www.cbronline.com/news/nec_launches_v80_answer_to_intels_80486\n</ref>\n\n<ref name=\"CBR-2\">\nNEC MAY HAVE THE EDGE WITH ITS 930,000 TRANSISTOR V80 ANSWER TO INTEL'S 80486 - Computer Business Review, 1989-04-06\nBalcklist:www.cbronline.com/news/nec_may_have_the_edge_with_its_930000_transistor_v80_answer_to_intels_80486\n</ref>\n\n<!----- WEB, MUSEUM ----->\n\n<ref name=\"ipsj-bungo\">\n{{cite web|url=http://museum.ipsj.or.jp/en/computer/word/0058.html|publisher=museum.ipsj.or.jp|title=Bungo mini 5SX\uff0cBungo mini 7SX\uff0cBungo mini 7SD \u2013 Computer Museum |access-date=2017-04-22}}\n</ref>\n\n<ref name=\"ispj-ms4100\">\n{{Cite web |url=http://museum.ipsj.or.jp/en/computer/mini/0027.html |publisher=museum.ipsj.or.jp | title=MS-4100 Series - Computer Museum|language=en|access-date=2018-01-07}}\n</ref>\n\n<ref name=\"nij-ms4100\">\n{{Cite web|url=https://dbnst.nii.ac.jp/pro/detail/282|title=MS4100 Series|publisher=dbnst.nii.ac.jp|language=Japanese|access-date=2018-01-08}}\n</ref>\n\n<ref name=\"HP64700\">\n{{Cite web|url=http://www.hpmuseum.net/display_item.php?hw=1086|title=HP Computer Museum|language=en|access-date=2018-01-07}}\n</ref>\n\n<!----- WEB, JAXA ----->\n\n<ref name=\"JAXA-Kibo\">\n{{cite web|title=Kibo HANDBOOK|url=http://iss.jaxa.jp/kibo/library/fact/data/kibo-handbook_en.pdf|publisher=JAXA|page=101|date=September 2007}}\n</ref>\n\n<ref name=\"Kibo-EDEE\">\n{{cite web|title=Space Environment Data Acquisition equipment-Attached Payload (SEDA/AP)|url=http://iss.jaxa.jp/en/kiboexp/ef/seda-ap/|website=iss.jaxa.jp|publisher=JAXA|language=en|date=2007-03-30}}\n</ref>\n\n<ref name=\"jaxa-roadmap\">\n{{cite web|title=JAXA's LSI (MPU/ASIC) roadmap, p. 9; excl. front|url=https://eeepitnl.tksc.jaxa.jp/mews/en/21st/data/2-1.pdf |website=Development Status for JAXA Critical Parts, 2008|publisher=JAXA}}\n</ref>\n\n<ref name=\"jaxa-status-2013\">\n{{cite web|title=Development Status of JAXA EEE Parts |url=https://eeepitnl.tksc.jaxa.jp/mews/jp/26th/data/2_12_1.pdf  |website=Development Status for JAXA Critical Parts, 2008|publisher=JAXA}}\n</ref>\n\n<ref name=\"jaxa-eee-parts\">\n{{Cite web|url=https://eeepitnl.tksc.jaxa.jp/en/Critical_P/completed/index_e.html|title=Database of JAXA Qualified EEE Parts and Material: Critical Parts|publisher=JAXA|language=en|access-date=2018-01-07}}\n</ref>\n\n<ref name=\"Kibo-SEE\">\n{{cite web|title=\u56fd\u969b\u5b87\u5b99\u30b9\u30c6\u30fc\u30b7\u30e7\u30f3\u300c\u304d\u307c\u3046\u300d\u8239\u5916\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u642d\u8f09 \u5b87\u5b99\u74b0\u5883\u8a08\u6e2c\u30df\u30c3\u30b7\u30e7\u30f3\u88c5\u7f6e\uff08\uff33\uff25\uff24\uff21\uff0d\uff21\uff30\uff09|url=http://www.icrr.u-tokyo.ac.jp/~hmiya/5th_sympo/Goka_Chimon2010.pdf|pages=52\u201353|language=ja|trans-title=Space Environment Data Acquisition Equipment \u2013 Attached Payload (SEDA-AP) on the ISS - \u201cKibo\u201d Exposed Facility}}\n</ref>\n\n<!----- WEB, CODE ----->\n\n<ref name=\"GCC-Internal\">\n{{Cite web|url=https://gcc.gnu.org/onlinedocs/gccint/Frame-Registers.html|title=GNU Compiler Internals}}\n</ref>\n\n<ref name=\"by-cygnus-1\">\n{{cite mailing list |url=https://gcc.gnu.org/ml/gcc-patches/1999-02n/msg00703.html |title=Patch to replace CYGNUS LOCAL with EGCS LOCAL in config.sub |date=1999-02-25 |mailing-list=gcc-patches |last= |first= |author=[[Cygnus Solutions]] |authorlink= |language= |ref= |quote=<br/>Hi Guys,<br/>I would like to submit the following patch.  It renames all occurrences of CYGNUS LOCAL to EGCS LOCAL, which seems slightly more accurate! :-)<br/>Cheers<br/>Nick}}\n</ref>\n\n<ref name=\"by-cygnus-2\">\n{{cite mailing list |url=https://gcc.gnu.org/ml/gcc-patches/1999-02n/msg00704.html |title=Re: Patch to replace CYGNUS LOCAL with EGCS LOCAL in config.sub |date=1999-02-25 |accessdate= |mailing-list=gcc-patches |last= |first= |author=[[Cygnus Solutions]] |authorlink= |language= |ref= |quote=<br/>Seems like a misguided exercise to me.<br/>If the changes are truly Cygnus-specific, they should not be in Egcs. Otherwise, they should be merged into the config.sub master copy (whose maintainer, by the way, in Ben!).}}\n</ref>\n\n<ref name=\"egcs\">\n{{Cite web|url=https://opensource.apple.com/source/gcc/gcc-926/config.sub.auto.html|title=gcc/gcc-926/config.sub|author=Cygnus Solutions|publisher=Apple Inc.|access-date=2018-01-07}}</ref>\n\n<ref name=\"newlib\">\n{{cite web|url=http://www.embedded.com/design/prototyping-and-development/4024867/Embedding-with-GNU-Newlib |title=Embedding with GNU: Newlib |publisher=Embedded |date=2001-12-28 |access-date=2014-02-15}}\n</ref>\n\n<ref name=\"Inc.1991\">\n{{cite journal|author=Brett Glass|title=Answer Line|url=https://books.google.com/books?id=VlAEAAAAMBAJ&pg=PA72|date=6 May 1991|journal=InfoWorld|page=72|issn=0199-6649}}\n</ref>\n\n<ref name=\"ada83cpl\">\n{{cite web|url=http://archive.adaic.com/compilers/ada83cpl.html |title=Ada 83 Certified Processor List |publisher=Archive.adaic.com |date=1998-03-31 |accessdate=2014-02-15}}\n</ref>\n\n<ref name=\"MV&#8209;4000\">\n{{cite web|url=http://www.chipcatalog.com/NEC/MV&#8209;4000.htm |title=MV&#8209;4000 |publisher=Chipcatalog.com |date= |accessdate=2014-02-15}}\n</ref>\n\n<ref name=\"ews-4800\">\n[http://www006.upp.so-net.ne.jp/tati/docs/48summary.txt History-of-48series] (refers to the [[:ja:EWS4800|''EWS 4800'']] NEC computers)\n</ref>\n\n<!----- WEB, KEYSIGHT ----->\n\n<ref name=\"HP64758G\">\n{{Cite web|url=https://www.keysight.com/en/pd-64758G%3Aepsg%3Apro-pn-64758G/v70-20mhz-emulation-subsystem-512kb?lc=eng|title=64758G V70 20MHz emulation subsystem 512KB|publisher=Keysight|language=en|access-date=2018-01-08}}\n</ref>\n\n<ref name=\"HP-discon\">\n{{Cite web|url=https://www.keysight.com/upload/cmc_upload/All/Disco_Products_not_on_site.pdf|page=97|title=Agilent Test & Measurement Discontinued Products|publisher=Keysight|access-date=2018-01-08}}\n</ref>\n\n<ref name=\"HP-Vseries\">\n{{Cite web|url=http://literature.cdn.keysight.com/litweb/pdf/5091-2705E.pdf |title=HP Emulators and Development Solutions for NEC V Series Microprocessors|page=13|publisher=Keysight|language=en|access-date=2018-01-07}}\n</ref>\n\n<!----- WEB, GENERAL ----->\n\n<ref name=\"google-groups\">\n{{cite web|url=https://groups.google.com/d/msg/comp.arch/o99tLF7STeE/OjX1y09VggwJ|title=Google Groups \u2013 Some comments on the NEC V60/V70 |accessdate=2017-04-22}}\n</ref>\n\n<ref name=\"V80-rumor\">\n{{cite web|title=NEC V80|url=https://groups.google.com/forum/#!topic/comp.arch/NMTvNkMzef0|website=groups.google.com|publisher=Google Groups}}</ref>\n\n<ref name=\"akatsuki\">\n{{Cite web|url=http://www.cpushack.com/2015/12/11/akatsuki-dawn-rises-again-at-venus/|title=Akatsuki: Dawn rises again at Venus|language=en|access-date=2018-01-07}}\n</ref>\n\n<ref name=\"EDN\">\n{{cite web|url=http://www.edn.com/electronics-news/4347599/NEC-Wraps-ARM-into-Gate-Arrays-4347599|publisher=edn.com|title=NEC Wraps ARM into Gate Arrays &#124; EDN|accessdate=2017-04-22}}\n</ref>\n\n<ref name=\"metaware\">\n{{cite web|title=MetaWare, Inc.|url=https://www.crunchbase.com/organization/metaware-inc|publisher=crunchbase|quote=<br/>MetaWare, Inc.<br/>MetaWare, Inc. is a supplier of tools and technologies for software developers.<br/>Santa Cruz, California, United States<br/>MetaWare, Inc. is a privately held company operates as a supplier of tools and technologies for software developers.}}\n</ref>\n\n<ref name=\"high-c\">\n{{cite web|title=MetaWare High C/C++|url=http://www.edm2.com/index.php/MetaWare_High_C/C%2B%2B|publisher=EDM/2}}\n</ref>\n\n<ref name=\"CNET-2007\">\n{{cite web|title=Despite its aging design, the x86 is still in charge|url=https://www.cnet.com/news/despite-its-aging-design-the-x86-is-still-in-charge/|website=CNET|language=en}}\n</ref>\n\n}}\n\n== External links ==\n* [http://itpro.nikkeibp.co.jp/article/COLUMN/20051201/225552/?SS=imgview&FD=-791347235&ST=system Die photo of the V60; at Nikkei BP (in Japanese)]\n* [http://www.shmj.or.jp/shimura/ssis_shimura2_19.htm Die photo of the V60]; at Semiconductor History Museum of Japan (in Japanese)\n* [https://cn.freeimages.com/photo/silicon-chip-1564335 Die photo of the V60], mounted on [[Pin grid array|PGA]] package (much clear, in Chinese)\n* [https://cn.freeimages.com/photo/silicon-chip-with-die-1564477 Die photo of the V60] with [[Pin grid array|PGA]] packaging, removed ceramic cap (in Chinese)\n* [http://canoro.altervista.org/cpu/fotogallery2.php?idcpu=necd70616r-16mio Photo of the V60] in [[Pin grid array|PGA]] packaging w/ ceramic cap shield; glass shield\n* [https://www.cpucollection.ca/NecD70616R-16.jpg Photo of the V60] in [[Pin grid array|PGA]] packaging w/ metal cap shield; seam weld\n* [http://ozuma.o.oo7.jp/unix/ux-v/ Blog: PS98-145-HMW kit: \"PC-UX/V\" w/ 15 disks & \"V60 Sub board\"]  for [[NEC PC-9801]] slot (in Japanese)\n* [http://www.cpushack.com/2015/12/11/akatsuki-dawn-rises-again-at-venus/ Article: V70 in PGA packaging] and the [[H-IIA|H-IIA rocket]] (in English)\n* [http://www.retroclinic.com/leopardcats/vrtwin/vrtwin.htm Photo of NEC V60 CPU board] of the [[Virtua Racing|Sega Virtua Racing]] (in English)\n* [http://www.system16.com/hardware.php?id=709 Site: \"System 16\"] - [[List of Sega arcade system boards#Sega System 32|Sega System 32]] Hardware (in English)\n* [http://www.system16.com/hardware.php?id=712 Site: \"System 16\"] - [[List of Sega arcade system boards#Sega Model 1|Sega Model 1]] Hardware (in English)\n* [http://www.system16.com/hardware.php?id=710 Site: \"System 16\"] - [[List of Sega arcade system boards#System Multi 32 specifications|Sega System Multi 32]] Hardware (in English)\n* Original documents for the V60 (\u03bcPD70616) & V70 (\u03bcPD70632) is available from [http://mess.redump.net/datasheets/nec/ here].\n* Datasheets for the AFPP (\u03bcPD72691) is available from [http://www.datasheetarchive.com/uPD72691-datasheet.html here].\n* [https://www.renesas.com/en-us/products/microcontrollers-microprocessors/v850.html Renesas V850 Family web site]\n* [https://www.renesas.com/en-us/products/microcontrollers-microprocessors/rh850.html Renesas RH850 Family web site]\n\n<!-- * [https://www.cpu-world.com/forum/viewtopic.php?t=19572 Photos of the V60 and V70 in their packaging] -->\n\n[[Category:NEC microprocessors|V60|V70|V80|AFPP|NEC V60|NEC V70|NEC V80|NEC AFPP]]\n[[Category:Microprocessors|NEC V60]]\n[[Category:Coprocessors|NEC AFPP|NEC \u03bcPD72691]]\n[[Category:Video game hardware|NEC V60]]\n[[Category:32-bit microprocessors]]\n", "text_old": "{{Copy edit|date=March 2020}}\n{{Infobox CPU\n| name           = NEC V60 / V70 / V80 / AFPP\n| image          = NEC V60 die.jpg\n| image_size     =\n| caption        = Die shot of NEC V60 microprocessor<br/>Name \"V60 D70616\" in bottom center\n| manuf1         = [[NEC Corporation|NEC]]\n| produced-start = V60: 1986<br/>V70: 1987<br/>V80: 1989<br/>AFPP: 1989\n| produced-end   = \n| slowest        = V60: 16&nbsp;MHz<br/>V70: 20/25&nbsp;MHz<br/>V80: 25/33&nbsp;MHz<br/>AFPP: 20\n| slow-unit      =&nbsp;MHz\n| size-from      = V60: 1.5/1.2 \u03bcm<br/>V70: 1.5/1.2 \u03bcm<br/>V80: 0.8 \u03bcm<br/>AFPP: 1.2 \u03bcm\n| transistors    = V60: 375K<br/>V70: 385K<br/>V80: 980K<br/>AFPP: 433K\n| arch           = NEC V60-V80<ref name=\"V60-Prog-Ref-Man\"/>\n| microarch      = \"V60/V70\", \"V80\"\n| instructions   = V60/V70:&nbsp;119<br/>V80:&nbsp;123\n| extensions     = V80: atomic\n| l1cache        = V80: 1K/1K\n| data-width     = V60: 16 (int. 32)<br/>V70: 32<br/>V80: 32\n| address-width  = V60: 24 (int. 32)<br/>V70: 32<br/>V80: 32\n| virtual-width  = 32 Linear<ref name=\"V60-Prog-Ref-Man\"/>\n| predecessor    = [[NEC V20|V20-V50]]\n| successor      = [[V850|V800&nbsp;Series]]\n| co-processor   = AFPP&nbsp;(\u03bcPD72691)\n| application    = [[Embedded system|Embedded]],<br/>[[Minicomputer]],<br/>[[Game arcade]]\n| pack1          = V60:&nbsp;68&#8209;pin&nbsp;[[Pin grid array|PGA]]<br/>V60:&nbsp;120&#8209;pin&nbsp;[[Quad Flat Package|QFP]]\n| pack2          = V70:&nbsp;132&#8209;pin&nbsp;[[Pin grid array|PGA]]\n| pack3          = V70:&nbsp;208&#8209;pin&nbsp;[[Quad Flat Package|QFP]]\n| pack4          = V80:&nbsp;280&#8209;pin&nbsp;[[Pin grid array|PGA]]\n| pack5          = AFPP:&nbsp;68&#8209;pin&nbsp;[[Pin grid array|PGA]]\n| pcode1         = \u03bcPD70616R&#8209;16\n| pcode2         = \u03bcPD70615GD&#8209;16\n| pcode3         = \u03bcPD70632R&#8209;20\n| pcode4         = \u03bcPD70632R&#8209;25\n| pcode5         = \u03bcPD70632GD&#8209;20\n| pcode6         = \u03bcPD70832R&#8209;25\n| pcode7         = \u03bcPD70832R&#8209;33\n| pcode8         = \u03bcPD72691R&#8209;20\n}}\n\n'''NEC V60'''<ref name=\"V60-Prog-Ref-Man\"/><ref name=\"maruzen\"/> is a [[Complex instruction set computer|CISC]] [[microprocessor]] once manufactured by [[NEC Corporation|NEC]] started in 1986. It has [[memory management unit|MMU]], and [[real-time operating system|RTOS]] supports both for [[Unix]]-based user-application-oriented systems<ref name=\"RX-UX-832\"/> and for [[Industrial TRON|I&#8209;TRON]] based hardware-control-oriented [[embedded system]]s. This article also describes '''[[NEC V70|V70]]''' and '''[[NEC V80|V80]]''' because these have the same [[instruction set architecture|ISA]] as V60.<ref name=\"overview\"/> In addition, dedicated co-[[Floating-Point Processor|FPP]],<ref name=\"coproc\"/>\nmulti-cpu [[lockstep (computing)|lockstep]] [[fault-tolerant computer system|fault-tolerant mechanism]] named [[Redundancy (engineering)|FRM]], [[development tool]]s including [[Ada (programming language)|Ada]] certified system [[#MV&#8209;4000|MV&#8209;4000]], and [[in-circuit emulator|ICE]] are described. At last, their successor<ref name=\"IEIEC-1995\"/> the [[Renesas V850|V800&nbsp;Series]] product families are briefly introduced.\n\nV60/V70/V80's application covered much wide area, including: [[circuit switching]] [[telephone exchange]]s, [[minicomputer]]s, [[aerospace engineering|aerospace]] [[guidance system]]s,<ref name=\"akatsuki\"/> [[word processor]]s, [[Industrial Computers|industrial computer]]s, and various [[game arcade]]s.\n\n== {{anchor}}Introduction ==\n\nNEC V60<ref name=\"maruzen\"/><ref name=\"V60-Prog-Ref-Man\"/> is a [[Complex instruction set computer|CISC]]<ref name=\"pj\"/> processor once manufactured by [[NEC]] started in 1986.<ref name=\"SIG-ARC-043\"/> It is the first 32-bit [[microprocessor|general-purpose microprocessor]] commercially available in Japan.<ref name=\"trend\"/>\n\nBased on a relatively traditional design at that moment,<ref name=\"MIPS-1984\"/><ref name=\"RISC-II\"/><ref name=\"R2000\"/><ref name=\"First-SPARC\"/><ref name=\"i860\"/> indeed it was a radical divorcing from NEC's previous 16-bit V\u2013Series; the [[NEC V20|V20-V50]].<ref name=\"V20-V50-progman\"/> Those were based on the [[Intel 8086]] model.<ref name=\"pj\"/> But V60 still retained the ability to emulate V20/V30.<ref name=\"V60-Prog-Ref-Man\"/>{{rp|\u00a710}}\nAccording to NEC's documentation, this [[Computer architecture|computer architectural]] change was made due to the increasing demands for, and the diversity of, [[high-level programming language]]s. Such trend called for a processor both with performance; doubling buses width to 32 bits, and with flexibility; having large numbers of general-purpose registers.<ref name=\"maruzen\"/><ref name=\"V60-Prog-Ref-Man\"/> These were a part of common features of [[Reduced instruction set computer|''Reduced Instruction Set Computer'']].<ref name=\"Computer-Architecture-4thEd\"/> This transition from [[Complex instruction set computer|CISC]] to [[Reduced instruction set computer|RISC]] brought much benefits to the emerging markets \u2014 at that moment.\n\nBut today, both of two [[Silicon Valley]] born [[Reduced instruction set computer|RISC]]s are pressed, instead [[x86|Intel's x86]] has been main stream for these decades. The reason is, though [[x86]] has [[Complex instruction set computer|CISC]] [[Instruction set architecture|ISA]], [[Intel 80486|80486]] internally adopts [[RISC]] features.<ref name=\"i486-ICCD89\"/><ref name=\"i486-Micro-1990\"/>\nAccording to [[Pat Gelsinger]]'s word, binary backward compatibility for the legacy software assets is much important than ISA change.<ref name=\"CNET-2007\"/>\n\n== {{anchor|V60|D70616|\u03bcPD70616|.mu.PD70616}}Overview ==\n\n=== Instruction set ===\n\nThe V60 (\u03bcPD70616) /.mu.PD70616/, however, staid in [[Complex instruction set computer|CISC]] features.<ref name=\"Wade, 1996\"/> Its manual describes them as [[Mainframe computer|mainframe-computer]]-based fully [[orthogonal instruction set]], in other words, ''Complex Instruction Set Computer'', which comprises; non-uniform length instructions, memory-to-memory operations including string manipulation, and fairly complex operand addressing schemes.<ref name=\"V60-Prog-Ref-Man\"/><ref name=\"maruzen\"/><ref name=\"Computer-Architecture-4thEd\"/>\n\n=== Family ===\n\nThe V60 has 32 bits internal buses although it has externally narrower 16 bits data and 24 bits address buses. In addition, V60 has 32 of 32-bit general-purpose registers.<ref name=\"V60-Prog-Ref-Man\"/>{{rp|\u00a71}}\nIts basic [[Computer architecture|architecture]] is inherited to the following models. The V70 (\u03bcPD70632) has 32 bits external buses, released in 1987. Launched in 1989, the V80 (\u03bcPD70832)<ref name=\"overview\"/> is the culmination of the series; having on-chip caches, having a branch predictor, and less reliance on [[microcode]] for complex operations.<ref name=\"micro1990\"/>\n\n=== Software ===\n\nThe [[operating system]]s, developed for the V60-V80 series, are generally oriented toward [[Real-time operating system|real-time operation]]s. Several OSs were ported on them, including real-time Unix and real-time I\u2011TRON.<ref name=\"rtos1997\"/><ref name=\"32b-itron\"/>\n\nBecause the V60/V70 has been used for various Japanese [[game arcade]]s, their ''[[instruction set architecture]]'' is still surviving as the [[Emulator#CPU simulator|CPU simulator]], called [[MAME|MAME, ''Multiple Arcade Machine Emulator'']], for this niche.<ref name=\"v60-cemu\"/> The latest [[open-source software|open-source]] [[source code|code]] is available from [[GitHub]] [[Repository (version control)|repository]] ([https://github.com/mamedev/mame/ <mamedev/mame>][https://github.com/mamedev/mame/tree/master/src/devices/cpu/v60/ </src/devices/cpu/v60/>]).\n\n=== FRM ===\n\nAll three processors has the synchronous multiple modular [[lockstep (computing)|''lockstep'' mechanism]] named FRM (Functional Redundancy Monitoring), which enables [[fault-tolerant computer system]]s. It requires plural of devices of the same model, then one of them becomes the \"master mode,\" while the other devices listen to the master device in the \"checker mode.\" If two or more devices arise different result via their \"fault output\" pins simultaneously, the majority voting decision can be made by external circuits. In addition, recovery method, either with ''roll-back'' by \"retry\" or with ''roll-forward'' by \"exception\" for the instruction which is detected mismatch, can be selected via an external pin.<ref name=\"IEEE-MICRO-FRM\"/><ref name=\"compcon1988\"/><ref name=\"V60-Prog-Ref-Man\"/>{{rp|\u00a711}}<ref name=\"overview\"/><ref name=\"SIG-ARC-069\"/><ref name=\"V60-Datasheet\"/>{{rp|\u00a73-229, 266}}\n{| class=\"wikitable\"\n|-\n! Pin Name !! I/O !! Function\n|-\n| BMODE (FRM) || Input || Select the normal bus (master) mode or FRM operating (checker) mode\n|-\n| {{overline|BLOCK}} ({{overline|MSMAT}}) || Output || Master output requesting bus lock, i.e. freezing bus operation<br/>Checker output indicating a mismatch has been detected\n|-\n| BFREZ || Input || Assertion for freezing bus operation\n|-\n| RT/{{overline|EP}} || Input || Selecting input for \"roll-back by retry\" or \"roll-forward by exception\"\n|}\n\n== {{anchor|\u03bcPD70615|.mu.PD70615|D70615|PS98-145-HMW}}V60 ==\nThe work on V60 processor began in 1982 under the leadership of Yoichi Yano.<ref name=\"dev-story\"/> About 250 engineers participated and the V60 (\u03bcPD70616) debuted in February 1986.<ref name=\"Meth\u00e91991\"/> It had a six-stage pipeline, built-in memory management unit and floating-point arithmetic. It was manufactured in 1.5&nbsp;[[\u03bcm]] on a two-layer aluminum metal CMOS process using 375,000 transistors on a {{nowrap|13.9 \u00d7 13.8 mm<sup>2</sup>}} die.<ref name=\"SIG-ARC-043\"/><ref name=\"dataquest-1986\"/> It operated at 5&nbsp;V and was initially packaged in a 68-pin [[pin grid array|PGA]].<ref name=\"dataquest-1987\"/> The first version ran at 16&nbsp;MHz and attained 3.5 [[Instructions per second#MIPS|MIPS]].<ref name=\"dataquest-1986\"/> Its sample price at launch was set to \u00a5100,000 ($588.23). It entered full-scale production in August 1986.<ref name=\"dataquest-1986\"/>\n\n[[File:VR_Virtua_Racing.jpg|thumb|Sega ''[[Virtua Racing]]'' based on [[List of Sega arcade system boards#Sega Model 1|''Sega Model 1'']]<br/> ([http://www.retroclinic.com/leopardcats/vrtwin/vrtwin.htm External Link])]]\n[[Sega]] employed this processor for the most of its arcade game sets in the 1990s; both the [[List of Sega arcade system boards#Sega System 32|Sega System 32]] and the [[List of Sega arcade system boards#Sega Model 1|Sega Model 1]] architectures used V60 for their main CPU. (The latter one used lower-cost variant  \u03bcPD70615 /.mu.PD70615/,<ref name=\"mamedev-model1\"/> which doesn't implement V20/V30 emulation and FRM.<ref name=\"cat95\"/>\n) The V60 was also used for the main CPU in the ''SSV'' arcade architecture\u2014so named because it was developed together by [[SETA Corporation|''Seta'']], [[Sammy Corporation|''Sammy'']], and [[Visco Corporation|''Visco'']].<ref name=\"mamedev-ssv\"/> Sega originally considered using a 16&nbsp;MHz V60 as the basis for its [[Sega Saturn]] console, but after receiving the word, that the [[PlayStation (console)|PlayStation]] employed a [[MIPS architecture|MIPS]] [[R3000|R3000A]] at 33.8&nbsp;MHz processor, instead chose the dual-[[SuperH|SH-2]] design for the eventual production model.<ref name=\"ric-tan\"/>\n\nIn 1988, NEC released a kit called PS98-145-HMW<ref name=\"ps98-145-hmw\"/> for [[Unix]] enthusiasts. The kit contained a V60 processor board that could be plugged into selected models of the [[PC-9800 series|PC-9800]] computer series and a '15 8\"-floppy disks distribution' of their [[UNIX System V]] port, the [[PC-UX|PC-UX/V]] [[UNIX System&nbsp;V#SVR2|Rel 2.0 (V60)]]. The suggested retail price for this kit was 450,000 Yen.<ref name=\"ps98-145-hmw\"/> NEC group companies themselves intensively employed V60 processor. Their [[telephone exchange|telephone circuit switcher]] (exchanger), which was one of the first intended target, used V60. In 1991, they expanded [[word processor]] products line, named [[:ja:\u6587\u8c6a|\"Bungou Mini\" (\u6587\u8c6a\u30df\u30cb in Japanese)]] series ''5SX'', ''7SX'', and ''7SD'', with a V60 for fast [[Computer font#Outline fonts|outline font]] processing, while the main system processor was a 16&nbsp;MHz [[NEC V20#Variants and successors|NEC V33]].<ref>{{YouTube|2kTVKjOWu3I|''Bungou Mini 5RX''}} with [[Computer font#Outline fonts|\"high speed outline font smoothing\"]] TV CM</ref><ref name=\"ipsj-bungo\"/> In addition, V60 has [[microcode]] variants for NEC's [[minicomputer]] ''MS-4100'' Series, which was the fastest one in Japan at that moment.<ref name=\"nec-tecj-ms4100\"/><ref name=\"ispj-ms4100\"/><ref name=\"nij-ms4100\"/>\n\n== {{anchor|\u03bcPD70632|.mu.PD70632|D70632}}V70 ==\n[[File:UPD70632GD-20 V70 01.JPG|thumb|V70 (\u03bcPD70632GD-20) in [[Quad Flat Package|QFP]] packaging, mounted on [[Jaleco]] ''[[:ja:\u30e1\u30ac\u30b7\u30b9\u30c6\u30e032|Mega System32]]'' [[Printed wiring board|PWB]] ]]\nThe V70 (\u03bcPD70632) /.mu.PD70632/ improved on V60 by widening external buses to 32 bits, then both internal and external buses became 32 bits width. It was also manufactured in a 1.5&nbsp;\u03bcm with two-metal layer process. Its {{nowrap|14.35 \u00d7 14.24 mm<sup>2</sup>}} die had 385,000 transistors and was packaged in a 132-pin ceramic [[Pin grid array|PGA]]. Its [[Memory management unit|MMU]] had support for [[demand paging]]. Its floating-point unit claimed [[IEEE 754]] compliance.<ref name=\"SIG-ARC-069\"/> The 20&nbsp;MHz version attained a peak performance of 6.6 MIPS and was priced at launch in August 1987 at \u00a5100,000 ($719.42). Initial production capacity was 20,000 units monthly.<ref name=\"dataquest-1987-2\"/> A later report describes it as [[Semiconductor device fabrication|fabricated]] in 1.2-micrometer CMOS and {{nowrap|12.23 \u00d7 12.32 mm<sup>2</sup>}} die.<ref name=\"overview\"/> The V70 had a two-cycle non-pipeline (T1-T2) external bus system, whereas that of the V60 operated at 3 or 4 cycles (T1-T3/T4).<ref name=\"overview\"/><ref name=\"maruzen\"/> Of course, the internal units were pipelined.\n\nV70 was used by [[Sega]] in its [[List of Sega arcade system boards#System Multi 32 specifications|''System Multi 32'']] design\n<ref name=\"mamedev1\"/> and by [[Jaleco]] in its [[:ja:\u30e1\u30ac\u30b7\u30b9\u30c6\u30e032|''Mega System 32'']] design. (See the top photo of the V70, which is mounted on the latter system's [[printed circuit board]].)<ref name=\"mamedev-mc32\"/>\n\n[[File:H-IIA F17 launching AKATSUKI.jpg|thumb|Liftoff of H&#8209;IIA Flight&nbsp;17, one of payload is [[Akatsuki (spacecraft)|Akatsuki; Venus Climate Orbiter]] ]]\nThe \"[[aerospace engineering|aerospace]]-spec\" ([[JAXA]] <sup>formerly [[National Space Development Agency of Japan|NASDA]]</sup> qualified EEE grade) variant of V70, running with [[RX616]], was embedded in the main control module called ''[[Guidance, navigation, and control|Guidance Control]] Computer'' by [[JAXA]] into the ''[[H-IIA|H&#8209;IIA]]'' [[carrier rocket]]s, and satellites such as [[Akatsuki (spacecraft)|''Akatsuki'' (Venus Climate Orbiter)]] and [[Kibo (ISS module)|''Kibo'' (ISS module)]].<ref name=\"akatsuki\"/><ref name=\"JAXA-Kibo\"/><ref name=\"Kibo-EDEE\"/> It had been used until their replacement in 2013 flight 22 with the 64-bit [[microprocessor]] ''HR5000'', which is based on [[MIPS architecture#MIPS32/MIPS64|MIPS64-5Kf architecture]],<ref name=\"MIPS64-5Kf-DS\"/> [[Semiconductor device fabrication|fabricated]] by HIREC.<ref name=\"nectech-jaxagcc\"/><ref name=\"jaxa-eee-parts\"/><ref name=\"HIREC-HR5000\"/> The ''[[H-IIA|H&#8209;IIA]]'' type ''[[launch vehicle]]s'' deployed domestically in Japan, although JAXA called for [[satellite]]s as its [[payload]] from the foreign countries. As is described in ''JAXA's LSI (MPU/ASIC) roadmap'', this V70 variant is \"32bit MPU (''H32/V70'')\" which development term, probably including QT phase, was \"from the middle of 1980s to early 1990s.\" In addition, the ''HR5000'' is \"64bit MPU (25MHz),\" which development is completed around 2011. Then V70 was retired.<ref name=\"jaxa-roadmap\"/>{{rp|9}}<ref name=\"jaxa-status-2013\"/>\n\n\"Space Environment Data Acquisition\" for the V70 was done by ''Kibo''-ISS exposed facility.\n{| class=\"wikitable\"\n|-\n! Item !! Part No. !! SEE (Single Event Effect)<br/>Monitored Item\n! Result <ref name=\"Kibo-SEE\"/>\n|-\n| V70-MPU || [[National Space Development Agency of Japan|NASDA]]<br/>38510/92101xz || [[Single event upset|SEU (Single Event Upset)]]<br/>[[Latch-up|SEL (Single Event Latch-up)]] || Not observed<br/>(\u20142010/9/30)\n|}\n\n== {{anchor|\u03bcPD70832|.mu.PD70832|D70832}}V80 ==\nThe V80 (\u03bcPD70832) /.mu.PD70832/<ref name=\"overview\"/> was launched in the spring of 1989. By incorporating on-chip caches and a [[branch predictor]], it was declared NEC's [[Intel 486|486]] by ''[[Computer Business Review]]''.<ref name=\"CBR-1\"/><ref name=\"CBR-2\"/> The performance of V80 was two to four times than that of V70, depending on application. For example, compared with V70, the V80 had a 32-bit hardware multiplier to reduce integer multiplication cycles to 9 from 23. (For more detailed differences, see hardware architecture section below.) The V80 was manufactured in 0.8-micrometer CMOS process with a die area of {{nowrap|14.49 \u00d7 15.47 mm<sup>2</sup>}} consisting of 980,000 transistors. It was packaged in a 280-pin [[Pin grid array|PGA]], and operated at 25 and 33&nbsp;MHz with claimed peak performance of 12.5 and 16.5 MIPS, respectively. V80 had separated 1&nbsp;KB on-die cache both for instructions and for data, and had 64-entry [[branch predictor]]; the performance gain, attributed to the latter, was about 5%. The launch prices of V80 were cited as equivalent to $1200 for the 33&nbsp;MHz model and $960 for the 25&nbsp;MHz model. Supposedly a 45&nbsp;MHz model was scheduled for 1990,<ref name=\"CBR-2\"/> but did not materialize.\n\nThe V80, associated with \u03bcPD72691 co-FPP and \u03bcPD71101 simple [[peripheral]] chips, was used for [[Industrial PC|industrial computer]] with the [[RX-UX832]] real-time UNIX and a [[X Window System|X11-R4]] based window system.<ref name=\"Meiden-Jiho-Jul92\"/><ref name=\"Meiden-Jiho-May93\"/>\n\n== {{anchor|\u03bcPD72691|.mu.PD72691|D72691|AFPP}}AFPP (co&#8209;FPP) ==\n\nThe AFPP (\u03bcPD72691) /.mu.PD72691/ is a co-processor for floating point arithmetic operations.<ref name=\"Majithi, 1987\"/> The name stands for Advanced Floating Point Processor as is described in NEC's data sheet. The V60/V70/V80 themselves can perform floating point arithmetic, but they are very slow because of microcode operations without dedicated hardware. In 1989, to compensate V60/V70/V80 for their fairly weak floating point performance, NEC launched the 80-bit floating point co-processor; for 32-bit [[Single-precision floating-point format|single precision]], for 64-bit [[Double-precision floating-point format|double precision]], and for 80-bit [[extended precision]] [[IEEE 754]] format operations.<ref name=\"coproc\"/><ref name=\"overview\"/> This chip claimed 6.7 [[MFLOPS]] in the vector-[[matrix multiplication]], operating at 20&nbsp;MHz. It was [[Semiconductor device fabrication|fabricated]] in 1.2-micrometer double-metal layer CMOS process containing 433,000 transistors on an {{nowrap|11.6 \u00d7 14.9 mm<sup>2</sup>}} die.<ref name=\"coproc\"/> It was packaged in a 68-pin [[Pin grid array|PGA]]. This co-processor connected to V80 via the dedicated bus. But in case of connecting to V60 and V70, it shared their main buses, which scenario diminished their peak performance.<ref name=\"overview\"/>\n\n== {{anchor|arch}}Hardware Architecture ==\nV60/V70/V80 shared the basic architecture. They had thirty-two 32-bit [[general-purpose register]]s, although the last three of them were commonly used as [[stack pointer]], [[frame pointer]], and [[argument pointer]], those were well matched with [[High-level programming language|high level language]] [[compiler]]s' [[calling convention]]s.<ref name=\"SIG-ARC-069\"/><ref name=\"GCC-Internal\"/> The V60 and V70 had a 119-instruction set,<ref name=\"SIG-ARC-069\"/> slightly extended to 123 instructions for the V80. The instructions have [[Complex instruction set computing|non-uniform length]] between one and 22 bytes,<ref name=\"V60-Prog-Ref-Man\"/> and they take two operands, both of which can be memory locations.<ref name=\"overview\"/> After studying the V60's reference manual, [[Paul Vixie]] described it as \"a very [[VAX]]-ish arch, with a V20/V30 emulation mode (which, if you recall, means it can run Intel 8086/8088 software)\".<ref name=\"google-groups\"/>\n\nV60-V80 had a built-in [[Memory management unit|MMU]]<ref name=\"SIG-ARC-043\"/><ref name=\"Majithi, 1987\"/> that divide the 4 GB [[Virtual memory|virtual address space]] into in four 1-GB sections, each section further divided in 1,024 1-MB areas, each area composed of 256 4-KB pages. On the V60/V70 four registers (ATBR0 to ATBR3) store section pointers on the processor, but the area tables entries (ATE) and [[Memory management unit#Page table entries|page tables entries (PTE)]] are stored into off-chip RAM. The V80 merged the ATE and ATBR registers, which are both on-chip with only the [[Memory management unit#Page table entries|PTE]] entries stored into external RAM, allowing for a faster execution of [[Translation lookaside buffer|TLB]] misses by eliminating one memory read.<ref name=\"overview\"/>\n\nThe TLBs on the V60/70 are 16-entry [[CPU cache#Associativity|fully associative]] with replacement done by [[microcode]]. The V80 in contrast has a 64-entry 2-way [[set associative]] [[Translation lookaside buffer|TLB]] with replacement done in hardware. [[Translation lookaside buffer|TLB]] replacement took 58 cycles in the V70 and also disrupted the pipelined execution of other instructions. On the V80 a TLB replacement took only 6/11 cycles depending if the page was in the same area or not; pipeline disruption no longer occurred in V80 because of the separate TLB replacement hardware unit which operated in parallel to the rest of the processor.<ref name=\"overview\"/>\n\nAll three processors used the same protection mechanism with 4 execution levels (set via a [[program status word]]), with [[ring 0]] being the privileged level that could access a special set of privileged registers on the processors.<ref name=\"overview\"/>\n\nAll three models supported a triple-mode redundancy configuration with three CPUs used in a [[byzantine fault tolerance]] scheme with bus freeze, instruction retry, and chip replacement signals.<ref name=\"overview\"/><ref name=\"compcon1988\"/> The V80 also added parity signals to its data and address buses.<ref name=\"overview\"/>\n\nString operations were implemented in [[microcode]] in the V60/V70, but aided by hardware Data Control Unit in the V80, running at full bus speed. This made string operations about five times faster in the V80.<ref name=\"overview\"/>\n\nAll floating point operations are largely implemented in microcode across the family and thus and are fairly slow. On the V60/V70 the 32-bit floating point operations took 120/116/137 cycles for addition/multiplication/division, while the corresponding 64-bit floating point operations took 178/270/590 cycles. The V80 had some limited hardware assist for parts of the floating point operations, e.g. decomposition into sign, exponent and mantissa, thus its floating point unit was claimed up to 3 times as effective as the one of the V70, with 32-bit operations taking 36/44/74 cycles while 64-bit floating point operations taking 75/110/533 cycles on the V80 (again, for addition/multiplication/division).<ref name=\"overview\"/>\n\n== {{anchor|PC-UX/V Rel 2.0 (V60)|Real-time UNIX RX-UX 832|RX-UX 832|RX-UX832|MUSTARD|RX616|NEC RX116|RX116|}}Operating Systems ==\n\n=== Unix (non-real-time and real-time) ===\n\nNEC ported several variants of [[Unix]] to its V60/V70/V80 processors for user-application-oriented systems, including real-time ones. The first flavor of NEC's [[UNIX System V]] port for V60 was called [[PC-UX/V]] [[UNIX System&nbsp;V#SVR2|Rel 2.0]] (V60).<ref name=\"PC-UX-R2-V60\"/> (also refer to [[#External links|external link]] photos below, much interesting) NEC also developed a variant for V60/V70/V80 with a focus on real-time operation called Real-time UNIX RX-UX 832.<ref name=\"RX-UX-832\"/> It has double layered kernel structure, and all the kernel call of Unix issues task to the real-time kernel. The multiprocessor version of RX-UX 832 was also developed, and was named MUSTARD (A Multiprocessor Unix for Embedded Real-Time Systems).<ref name=\"Suzuki1992\"/> The MUSTARD-powered computer prototype used eight V70 processors. It utilizes FRM function, and can configure and change the structure of master and checker upon request.<ref name=\"8-V70-Proc\"/>\n([https://books.google.co.jp/books?id=Hyn9Cqf8PZsC&pg=PA195#v=onepage&q&f=false Google Books])\n\n=== I&#8209;TRON (real-time) ===\n\nFor hardware-control-oriented [[embedded systems]], the [[Industrial TRON|I&#8209;TRON]] based real-time operating system, named RX616, was implemented by NEC for the V60/V70.<ref name=\"IEEE-MICRO-FRM\"/><ref name=\"rtos1997\"/> The 32-bit RX616 was a continuous fork from the 16-bit [[NEC RX116|RX116]], which was for the [[NEC V20|V20-V50]].<ref name=\"dataquest-1987-2\"/><ref name=\"32b-itron\"/>\n\n=== FlexOS (real-time) ===\n\nIn 1987, [[Digital Research|Digital Research, Inc.]] had also announced that they were planning on porting [[FlexOS]] to the V60 and V70.<ref name=\"FLEXOS\"/>\n\n=== CP/M and DOS (legacy 16-bit) ===\n\nThe V60 could also run [[CP/M]] and [[DOS]] programs (ported from the V20-V50 series) using V20/V30 emulation mode.<ref name=\"dataquest-1986\"/> According to a 1991 article in [[InfoWorld]], [[Digital Research]] was working on a version of [[Concurrent DOS]] for the V60 at some point, but this was never released as the V60/V70 processors were not imported in the US for use in PC clones.<ref name=\"Inc.1991\"/>\n\n== {{anchor|compiler|cross-compiler}}Development Tools ==\n\n=== {{anchor|PKG70616|MetaWare|MetaWare, Inc.|High C/C++}}C/C++ cross compilers ===\n\nRegarding the [[development tool]] kit and [[Integrated development environment|IDE]], NEC had its own C compiler the PKG70616; \"Software Generation tool package for V60/V70.\"<ref name=\"cat-fr\"/> In addition, GHS ([[Green Hills Software]]) made its native mode C compiler (MULTI), and [[MetaWare, Inc.]]<ref name=\"metaware\"/> (currently [[Synopsys]], via [[Synopsys#ARC International|ARC International]]) made one for V20/V30 emulation mode, i.e. 8086 model, called High C/C++.<ref name=\"high-c\"/><ref name=\"i486-Micro-1990\"/>{{rp|acknowledgement}}\n[[Cygnus Solutions]] (currently [[Red Hat]]) also ported [[GNU Compiler Collection|GCC]] in a part of [[EGCS]] fork,<ref name=\"egcs\"/> but it seems not to be public.<ref name=\"by-cygnus-1\"/><ref name=\"by-cygnus-2\"/>\n\nAs of 2018, the machine directory ''necv70'' is still kept alive in the [[newlib]] C language libraries (libc.a and libm.a) by [[RedHat]].<ref name=\"newlib\"/> Its home page is [https://sourceware.org/newlib/ https://sourceware.org/newlib/]. Recent maintenance seems to be done on [https://sourceware.org/git/gitweb.cgi?p=newlib-cygwin.git;a=history;f=newlib/libc/machine/necv70;hb=HEAD <2016-12-23>]. The latest source code is available from its [[git]] [[Repository (version control)|repository]] [https://sourceware.org/git/gitweb.cgi?p=newlib-cygwin.git;a=tree;f=newlib/libc/machine/necv70 <newlib/libc/machine/necv70>]. The assembler source code [https://sourceware.org/git/gitweb.cgi?p=newlib-cygwin.git;a=blob;f=newlib/libc/machine/necv70/setjmp.S <setjump.S>] is truly the mnemonic of V70.\n\n=== {{anchor|MV4000|MV&#8209;4000}}MV-4100 Ada 83 certified system ===\n\nThe [[Ada (programming language)|Ada 83]] certified ''platform system'' was named MV\u20114000, sometimes notified as MV4000. This certification was done with \"the target\" system, that utilized ''Real-time UNIX RX-UX 832'' OS running on the [[VMEbus]] (IEEE 1014) based system, a V70 processor board plugged in.  \"The host\" of the [[cross compiler]] was the ''NEC Engineering Work Station [[:ja:EWS4800|EWS 4800]]''. Its \"host os\" ''[[EWS-UX|EWS-US/V]]'' was also [[UNIX System&nbsp;V]] based.<ref name=\"ada83cpl\"/><ref name=\"MV&#8209;4000\"/><ref name=\"ews-4800\"/>\n\nThe certification status is issued as the [https://books.google.com/books?id=M3F-lhug50cC&pg=PA198&dq=MV4000+V70 ADA YEAR BOOK]. The status of MV\u20114000 (notified as MV4000) can be found such as 1994, and 1995 revision.\n\nAda 83 validation status by AETECH, Inc.<ref name=\"ada83cpl\"/>\n<br/>\nNOTE: In accordance with the [http://archive.adaic.com/compilers/val-proc/1222val.html Ada Validation Procedures (Version 5.0)], certificates will no longer be issued for Ada 83 compilers. Testing may be performed by an Ada Conformity Assessment Laboratory (ACAL) for specific procurement requirements, and the ACAA will issue a letter affirming such testing, but no certificates will be issued. All validation certificates ever issued for testing under Version 1.11 of the ACVC test suite expired on 31 March 1998.\n{| class=\"wikitable\"\n|-\n! System Name !! Certificate Number !! Compiler Type !! HOST Machine !! HOST OS !! TARGET Machine !! TARGET OS\n|-\n| NEC Ada Compiler System for EWS-UX/V to V70/RX-UX832, Version 1.0 || 910918S1.11217 || Base || NEC EWS4800/60 || EWS-UX/V R8.1 || NEC MV4000 || RX-UX832 V1.6\n|-\n| NEC Ada Compiler System for EWS-UX/V(Release 4.0) to V70/RX-UX832 Version Release 4.1 (4.6.4) || 910918S1.11217 ||  Derived || EWS4800 Superstation RISC Series || EWS-UX/V(R4.0) R6.2 || NEC MV4000 || RX-UX832 V1.63\n|}\n\n{| class=\"wikitable\"\n|-\n! MV\u20114000 Features <ref name=\"MV&#8209;4000\"/>\n|-\n| System bus: IEEE1014 D1.2/IEC821 Rev C.1 (8-slot)\n|-\n| Expansion bus: IEC822 Rev C or V70 cache bus (6-slot)\n|-\n| Built-in 100M byte (formatted) 3.5-inch SCSI hard disk\n|-\n| Built-in 1M-byte 3.5-inch floppy disk drive 1\n|-\n| Expansion SCSI (1 ch)\n|-\n| EMI evaluation: VCCI - 1 kind\n|}\n\n=== Evaluation board kits ===\n\nNEC released some of plug-in type evaluation board kits for V60/V70.\n{| class=\"wikitable\"\n|-\n! Parts No. !! Descriptions !! Remarks\n|-\n| EBIBM-7061UNX || V60 coprocessor slave board with Unix for [[IBM Personal Computer XT|PC-XT]]/[[IBM Personal Computer/AT|AT]] || w/ [[PC-UX]]/V Rel 2.0 (V60)\n|-\n| PS98-145-HMW || V60 coprocessor slave board with Unix for [[PC-9800 series|NEC PC-9801]] || w/ [[PC-UX]]/V Rel 2.0 (V60)\n|-\n| EBIBM-70616SBC || V60 single board computer for [[Multibus#Multibus I|Multibus I]] ||\n|-\n| A part of MV-4000 || V70 single board computer for [[VMEbus]] || [[Ada 83]] certified\n|-\n|}\n\n== {{anchor|hw-emulator|ICE}}In-Circuit Emulator ==\n\n=== On-chip software debug support ===\n\nNEC had its own full (non-ROM and non-JTAG) probe-based ''[[in-circuit emulator]]''; the IE-V60 because V60/V70 themselves had emulator-chip capabilities. NEC described it as \"user friendly software debug function.\"  In fact, they have various trapping exceptions, such as data read (or write) to the user specified address, and 2 break-points simultaneously. <sup>Section 9</sup>\n<ref name=\"V60-Prog-Ref-Man\"/>\n\n=== External bus status pins ===\n\nExternal bus system also indicates its bus status with 3 bits of status pins, such as the first [[instruction fetch]] after branch, continuous [[instruction fetch]], [[Translation lookaside buffer|TLB]] [[data access]], single [[data access]], [[Sequential access|sequential data access]]. <sup>Section 6.1, p.&nbsp;114</sup>\n<ref name=\"maruzen\"/>\n\n{| class=\"wikitable\"\n|-\n! ST[2:0] !! Description\n|-\n| 111 || [[Instruction fetch]]\n|-\n| 011 || [[Instruction fetch]] after branch\n|-\n| 101 || [[Translation lookaside buffer|\"TLB\"]] [[data access]]\n|-\n| 100 || \"System base (interrupt & exception vector) table\" [[data access]]\n|-\n| 011 || Single [[data access]]\n|-\n| 010 || Short-path data access (Skipped address by read-after-write)\n|-\n| 001 || [[Sequential access|Sequential data access]]\n|-\n|}\n\n=== Debugging with V80 ===\n\nThese software and hardware debugging functions were also built on the V80, but it did not have [[In-circuit emulation|in-circuit emulator]]. Probably because it succeeded much fruits from V60/V70, such as [[Real-time operating system|real-time]] [[UNIX System&nbsp;V|UNIX]] RX-UX 832 and [[Real-time operating system|real-time]] [[Industrial TRON|I&#8209;TRON]] RX616. Think, if once [[Unix]] boots up, who needs [[In-circuit emulation|in-circuit emulator]] both for developing [[device driver]] and for developing [[application software]]. What developer need is a [[C (programming language)|C]] [[compiler]], self as well as [[Cross compiler|cross]], and the [[Debugger#Debugger front-ends|screen debugger]], working with the target device, such as [[GNU Debugger#Graphical user interface|GDB-Tk]].\n\n=== IE-V60 ===\n\nThe IE-V60 was the first ''in-circuit emulator'' for V60 manufactured by NEC. It also had PROM programmer function. <sup>Section 9.4, p.&nbsp;205</sup><ref name=\"maruzen\"/>\n\n=== {{anchor|HP 64758}}HP 64758 ===\n\n[[Hewlett Packard]] (currently [[Keysight]]) offered a probing-pod-based ''[[In-circuit emulation]]'' hardware for the V70, built on their ''[[HP 64700]]'' Series systems,<ref name=\"HP-Vseries\"/><ref name=\"HP64700\"/> successor of ''[[HP 64000]]'' Series (detailed description is available within Wikipedia, with graphical image), more precisely the HP 64758<ref name=\"HP64758G\"/><ref name=\"HP-discon\"/> emulated the V70.<ref name=\"HP-Vseries\"/> It enables trace function like a [[logic analyzer]]. This [[Electronic test equipment|test equipment]] also displays [[Disassembler|disassembled instruction]] level [[source code]] automatically; with trace data display; ''without'' any [[object file]].<ref name=\"HP-Vseries\"/> And displays [[high-level language]] [[source code]] if user provide the [[source code]] and the [[object file]], which is [[compile]]d with [[DWARF]] information. Interface for V60 (10339G) is also listed in the catalog.<ref name=\"HP-discon\"/> But long probing-pod cable required \"special grade qualified\" devices, i.e. high speed grade V70.\n\nHP 64758: Main units, sub-nits, and hosted interface\n{| class=\"wikitable\"\n|-\n! Product !! Description\n|-\n| 64758A || V70 20&nbsp;MHz Emulator 512KB of Emul. mem.\n|-\n| 64758AX || One-Time-Update \n|-\n| 64758B || V70 20MHZ Emulator 1MB of Emulation mem.\n|-\n| 64758G || V70 20&nbsp;MHz emulation subsystem 512KB\n|-\n| 64758H || V70 20&nbsp;MHz emulation subsystem 1MB\n|-\n| 64758S || V70(uPD70632) Hosted User Interface\n|}\n\nSoftware options\n{| class=\"wikitable\"\n|-\n! Product !! Description\n|-\n| 64879L || V70 Assembler/Linker Single User License\n|-\n| 64879M || V70 Assembler/Linker Media & Manuals\n|-\n| 64879U || V70 Assembler/Linker Multi-user license\n|}\n\nHardware options\n{| class=\"wikitable\"\n|-\n! Product !! Description\n|-\n| B3068B || V70 Graphical Hosted User Interface\n|-\n| 10339G || NEC V60 INTERFACE\n|-\n| E2407A || NEC V70 INTERFACE\n|}\n\n== {{anchor|fading}}Fading and Successors ==\n\n=== Strategic failure of the V80 [[microarchitecture]] ===\n\nIn its development phase, the V80 was thought as the same performance chip as the [[Intel 80486]].<ref name=\"V80-rumor\"/> But, as the result, they became much different features. The internal execution for each instruction of the V80 needed at least 2 cycles, while that of i486 was 1. The internal pipeline of the V80 seemed [[Pipeline (computing)#Buffered, asynchronous pipelines|buffered A-synchronous]], but that of i486 was [[Pipeline (computing)#Buffered, synchronous pipelines|synchronous]]. In other words, the internal [[microarchitecture]] of V80 was [[Complex instruction set computer|CISC]], but that of i486 was [[Reduced instruction set computer|RISC]]. Both of their [[Instruction set architecture|ISA]] had long non-uniform [[Complex instruction set computer|CISC]] instructions, so i486 adopted wider 128-bit internal [[cache memory]], while that of V80 was 32-bit width. This difference can be seen on their die photos.<ref name=\"overview\"/><ref name=\"i486-Micro-1990\"/><ref name=\"micro1990\"/><ref name=\"i486-ICCD89\"/>\nThis strategic failure was fatal from the performance point of view, but NEC did not change its design. NEC might be able to throw away its [[Physical design (electronics)|physical design]], and to reconsider in [[register-transfer level]] as soon as possible, but it did not.\n\n=== Fading ===\nThe V60-V80 architecture did not enjoy much commercial success.<ref name=\"Meth\u00e91991\"/>\n\nThe V60, V70, and V80 were listed in 1989 and 1990 NEC catalogs in their [[Pin grid array|PGA]] packaging.<ref name=\"cat89\"/><ref name=\"cat90\"/> A NEC catalog from 1995 still listed the V60 and V70 (not only in their [[Pin grid array|PGA]] version but also in a [[Quad Flat Package|QFP]] packaging, and also included a low-cost variant of the V60 named \u03bcPD70615, which eliminated V20/V30 emulation and FRM function), alongside their assorted chipset, but the V80 is not offered in this catalog.<ref name=\"cat95\"/> The 1999 edition of the same catalog no longer has any V60-V80 products.<ref name=\"cat99\"/>\n\n=== {{anchor|NEC V810|NEC V820|NEC V830|\u03bcPD70732|\u03bcPD70742}}The V800&nbsp;Series ===\n\nIn 1992, NEC launched new model, the V800&nbsp;Series 32-bit [[microcontroller]], but it does not have [[Memory management unit|MMU (Memory Management Unit)]].<ref name=\"1992-ARC-06\"/> Those were much different from CISC, but [[Reduced instruction set computer|RISC]]-based architecture, inspired by the [[Intel i960]], [[MIPS architecture]], and other [[Reduced instruction set computer|RISC]] processor instructions, such as JARL (Jump and Register Link), and [[load/store architecture]].\n\nAt this moment, all the huge software assets of the V60/V70, like real-time Unix, were lost and never returned to their successors. The scenario Intel circumvents.\n\nThe V800&nbsp;Series had 3 product line variants, the V810&nbsp;Family, the V830&nbsp;Family, and the [[V850|V850&nbsp;Family]].<ref name=\"EDN\"/><ref name=\"IEIEC-1995\"/><ref name=\"IEEE-1998\"/>\n\nV820 (\u03bcPD70742) was a simple variant of V810 (\u03bcPD70732) with peripherals. The [[:ja:\u30b7\u30d0\u30f3\u30e0\u30b7|#4]] seems to be skipped (see page 58 <ref name=\"cat95\"/>), probably because of Japanese [[tetraphobia]].  One [[Japanese pronunciation]] of \"4\" means \"death.\" So the successors well avoid the [[Deathwatch beetle|Death-watch]]; Shi-ban (#4; Shi-ban) ''[[Software bug|Bug]]'' ({{nihongo2|[[:ja:\u30b7\u30d0\u30f3\u30e0\u30b7|\u6b7b\u756a\u866b]]}}, precisely ''[[deathwatch beetle]]''). As of 2005, it was already the [[V850]] era, and the [[V850]]&nbsp;Family has been enjoying great success.<ref name=\"cat05\"/> As of 2018, it is called Renesas V850&nbsp;Family and RH850&nbsp;Family with V850/V850E1/V850E2 and V850E2/V850E3 CPU cores, respectively. Those CPU cores have extended [[Instruction set architecture|ISA]] of original V810 CPU core;<ref name=\"V810-GCC\"/> running with V850 compiler.<ref name=\"GHS-V850\"/>\n\n== {{anchor|sw-emulator|ISS|MEME}}Emulator (CPU Simulator) Software ==\n\n=== MAME ===\n\nBecause the V60/V70 had been used for many Japanese [[game arcade]]s, their [[instruction set architecture]] has still survived as [[Emulator#CPU simulator|CPU simulator]] for this niche market. It is called [[MAME|MAME (''Multiple Arcade Machine Emulator'')]], which emulates multiple old [[game arcade]]s for enthusiasts.<ref name=\"v60-cemu\"/> It is a kind of an [[instruction set simulator]], not for developers but for users.\n\nNowadays, it has been kept providing by the [http://www.mamedev.org/ ''MAME development team'']. The latest [[open-source software|open-source]] [[source code|code]], written in [[C++]], is available from [[GitHub]] [[Repository (version control)|repository]] ([https://github.com/mamedev/mame/ <mamedev/mame>][https://github.com/mamedev/mame/tree/master/src/devices/cpu/v60/ </src/devices/cpu/v60/>]). The ''[[operation code]]s'' in the file [https://github.com/mamedev/mame/blob/master/src/devices/cpu/v60/optable.hxx optable.hxx] are exactly the same as those of V60.<ref name=\"V60-Prog-Ref-Man\"/>\n\n== See also ==\n* [[NEC V20]]\n* [[V850]]\n* [[R4200]]\n\n== References ==\n\n{{reflist|colwidth=30em\uff5crefs=\n\n<!----------------->\n<!----- BOOKS ----->\n<!----------------->\n\n<!----- BOOKS, AUTHOR=NEC ----->\n\n<ref name=\"V60-Prog-Ref-Man\">\n{{cite book|author1=NEC|title=\u03bcPD70616 Programmer's Reference Manual|date=November 1986|publisher=The Internet Archive, a 501(c)(3) non-profit|edition=PRELIMINARY|url=https://archive.org/details/NEC_V60pgmRef|quote=<br/>EPUB, KINDLE, PDF, PDF w/text, FULL TEXT, etc, are available}}\n</ref>\n\n<ref name=\"V60-Datasheet\">\n{{cite book|title=1987 Microcomputer Data Book: Vol. 2|date=August 1986|publisher=NEC|pages=3-229\u20133-232|url=http://bitsavers.org/components/nec/_dataBooks/1987_Microcomputer_Products_Vol_2.pdf}}\n</ref>\n\n<ref name=\"V20-V50-progman\">\n{{cite book|author1=NEC|title=16-BIT V SERIES; INSTRUCTIONS|date=June 1997|publisher=The Internet Archive, a 501(c)(3) non-profit|edition=5|url=https://archive.org/details/bitsavers_necdatabooBITVSeriesJun97_693718|quote=<br/>EPUB, KINDLE, PDF, FULL TEXT, etc, are available.}}\n</ref>\n\n<ref name=\"Computer-Architecture-4thEd\">\n{{cite book|last1=Hennessy: Stanford University|first1=John L|last2=Patterson: University of California at Berkeley|first2=David A.|title=Computer Architecture: A Quantitative Approach|date=2007|publisher=MORGAN KAUFMANN PUBLISHERA|url=https://archive.org/details/2007ComputerArchitectureAQuantitativeApproach|isbn=978-0-12-370490-0|edition=Fourth|quote=<br/>Open Access: EPUB, KINDLE, PDF, FULL TEXT, etc, are available.}}\n</ref>\n\n<!----- BOOKS, JAPANESE ----->\n\n<ref name=\"maruzen\">\n{{Cite book |last=Kani |first=Dr. Kenji |date=April 1987 |trans-title=V-Series Microcomputer 2|title=V\u30b7\u30ea\u30fc\u30ba\u30de\u30a4\u30af\u30ed\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf 2|publisher=Maruzen | isbn=978-4621031575 |language=japanese|quote=<br/>\u672c\u66f8\u306f\u65e5\u672c\u96fb\u6c17(\u682a)\u304c\u3001\u308f\u304c\u56fd\u3067\u306f\u3058\u3081\u3066\u958b\u767a\u3057\u305f32\u30d3\u30c3\u30c8\u30de\u30a4\u30af\u30ed\u30d7\u30ed\u30bb\u30c3\u30b5V60\u306b\u3064\u3044\u3066\u89e3\u8aac\u3057\u305f\u3082\u306e\u3067\u3042\u308b\u3002[This book explains the V60, Japanese first developed 32-bit microprocessor by NEC.]}}\n</ref>\n\n<!----- BOOKS, AUTHOR NOT NEC ----->\n\n<ref name=\"Meth\u00e91991\">\n{{cite book|author=David T. Meth\u00e9|title=Technological Competition in Global Industries: Marketing and Planning Strategies for American Industry|url=https://books.google.com/books?id=_wHx9wlDVlcC&pg=PA128|year=1991|publisher=Greenwood Publishing Group|isbn=978-0-89930-480-9|page=128}}\n</ref>\n\n<!------------------->\n<!----- JOURNAL ----->\n<!------------------->\n\n<!----- JOURNAL, AUTHOR==NEC ----->\n\n<ref name=\"isscc1986\">\n{{cite journal|last1=Yano|first1=Y|last2=Iwasaki|first2=J|last3=Sato|first3=Y|last4=Iwata|first4=T|last5=Nakagawa|first5=K|last6=Ueda|first6=M|title=A 32b CMOS VLSI microprocessor with on-chip virtual memory management|journal=Solid-State Circuits Conference. Digest of Technical Papers. 1986 IEEE International|volume=XXIX|date=Feb 1986|pages=36\u201337|doi=10.1109/ISSCC.1986.1156924|publisher=IEEE|quote=<br/>The execution unit (EXU) is a microprogrammed 32b data path processor which has thirty-two 32b general-purpose registers, sixteen 32b scratch-pad registers, a 64b barrel shifter, a 32b arithmetic logic unit (ALU); and a couple of control registers. Three data-buses that are running}}<br/>\n{{cite journal|title=ditto|url=https://www.researchgate.net/publication/3994148|publisher=Research Gate|url-access=registration}}\n</ref>\n\n<ref name=\"acm86\">\n{{cite journal|last1=Kaneko|first1=H|last2=Miki|first2=Y|last3=Koya|first3=K|last4=Araki|first4=M|title=A 32-bit CMOS microprocessor with six-stage pipeline structure|journal=Proceedings of 1986 ACM Fall Joint Computer Conference|date=November 1986|pages=1000\u20131007|publisher=IEEE Computer Society Press|quote=<br/>Abstract<br/>32-bit microprocessors are the key devices which carry high data processing capability, that was obtained by earlier general purpose computer systems and mini-computer systems, in much lower cost. Earlier 32-bit microprocessors were limited to adopt excellent architecture and design using appropriate hardware by number of devices could be fabricated on a chip. Complex functions such as Virtual Memory management and \u2026\n}}<br/>\n{{cite journal|title=ditto|publisher=ACM|url-access=subscription|url=https://scholar.google.com/scholar?q=%22A+32-Bit+CMOS+Microprocessor+with+Six-Stage+Pipeline+Structure%22}}\n</ref>\n<ref name=\"IEEE-MICRO-FRM\">\n{{Cite journal | doi = 10.1109/40.527 | title = Implementation of the V60/V70 and its FRM function| journal = IEEE Micro| volume = 8| issue = 2| pages = 22\u201336| date =April 1988| last1 = Kimura | first1 = S.| last2 = Komoto | first2 = Y.| last3 = Yano | first3 = Y.|quote=<br/>Abstract:<br/>A description is given of the V60/V70, the first commercially based, general-purpose 32-bit microprocessor in Japan. Its functions include on-chip floating-point operations, a high-level-language-oriented architecture, software debugging support, and support functions to promote a high level of system reliability. Because high reliability is so important, the V60/V70 contains functional redundancy monitoring (FRM) support functions. The discussion covers the overall design considerations, architecture, implementation, hazard detection and control, and FRM functions. The V60/V70 uses a TRON real-time operating system specification.}}\n</ref>\n\n<ref name=\"compcon1988\">\n{{Cite book | doi = 10.1109/CMPCON.1988.4824 | isbn = 0-8186-0828-5 | title = V60/V70 microprocessor and its systems support functions | publisher = Digest of Papers. COMPCON Spring 88 Thirty-Third IEEE Computer Society International Conference | pages = [https://archive.org/details/compconspring8830000ieee/page/36 36\u201342] | date = Spring 1988 | last1 = Yano | first1 = Y. | last2 = Koumoto | first2 = Y. | last3 = Sato | first3 = Y. | quote = <br/>Abstract:<br/>Two advanced 32-bit microprocessors, the V60 and V70 ( mu PD70616 and mu PD70632, respectively), and their support functions for operating systems and high-reliability systems are described. Three operating system functions, namely, the virtual memory support functions, context-switch functions, and asynchronous trap functions are examined. A basic mechanism for high-reliability-system implementation, called FRM (functional redundancy monitoring), is discussed. FRM allows a system to be designed in which multiple V60s (or V70s) form a configuration in which one processor in the system acts as a master while the others act as monitors. An FRM board that uses three V60s in its redundant core is introduced. | url = https://archive.org/details/compconspring8830000ieee/page/36 }}\n</ref>\n\n<ref name=\"micro1990\">\n{{cite journal|last1=Kaneko|first1=Hiroaki|last2=Suzuki|first2=Nariko|last3=Wabuka|first3=Hhiroaki|last4=Maemura|first4=Koji|title=Realizing the V80 and its system support functions|journal=IEEE Micro|date=April 1990|volume=10|issue=2|pages=56\u201369|doi=10.1109/40.52947|issn=0272-1732|quote=<br/>Abstract:<br/>An overview is given of the architecture of an overall design considerations for the 11-unit, 32-b V80 microprocessor, which includes two 1-kB cache memories and a branch prediction mechanism that is a new feature for microprocessors. The V80's pipeline processing and system support functions for multiprocessor and high-reliability systems are discussed. Using V80 support functions, multiprocessor and high-reliability systems were realized without any performance drop. Cache memories and a branch prediction mechanism were used to improve pipeline processing. Various hardware facilities replaced the usual microprogram to ensure high performance.}}\n<br/>{{Cite journal|title=ditto|journal=IEEE Micro|volume=10|issue=2|pages=56\u201369|publisher=ACM|url-access=subscription|url=https://dl.acm.org/citation.cfm?id=623503|doi=10.1109/40.52947|date=March 1990|last1=Kaneko|first1=Hiraoki|last2=Suzuki|first2=Nariko|last3=Wabuka|first3=Hiroshi|last4=Maemura|first4=Koji}}</ref>\n\n<ref name=\"IEEE-MICRO-FRM\">\n{{Cite journal | doi = 10.1109/40.527 | title = Implementation of the V60/V70 and its FRM function| journal = IEEE Micro| volume = 8| issue = 2| pages = 22\u201336| date =April 1988| last1 = Kimura | first1 = S.| last2 = Komoto | first2 = Y.| last3 = Yano | first3 = Y.|quote=<br/>Abstract:<br/>A description is given of the V60/V70, the first commercially based, general-purpose 32-bit microprocessor in Japan. Its functions include on-chip floating-point operations, a high-level-language-oriented architecture, software debugging support, and support functions to promote a high level of system reliability. Because high reliability is so important, the V60/V70 contains functional redundancy monitoring (FRM) support functions. The discussion covers the overall design considerations, architecture, implementation, hazard detection and control, and FRM functions. The V60/V70 uses a TRON real-time operating system specification.}}\n</ref>\n\n<ref name=\"coproc\">\n{{Cite journal | doi = 10.1109/JSSC.1989.572608|issn=1558-173X| title = A 6.7-MFLOPS floating-point coprocessor with vector/matrix instructions| journal = IEEE Journal of Solid-State Circuits| volume = 24| issue = 5| pages = 1324\u20131330| date =Oct 1989| last1 = Nakayama | first1 = T.| last2 = Harigai | first2 = H.| last3 = Kojima | first3 = S.| last4 = Kaneko | first4 = H.| last5 = Igarashi | first5 = H.| last6 = Toba | first6 = T.| last7 = Yamagami | first7 = Y.| last8 = Yano | first8 = Y.|quote=<br/>Abstract:<br/>An 80-bit floating-point coprocessor which implements 24 vector/matrix instructions and 22 mathematical functions is described. This processor can execute floating-point addition/rounding and pipelined multiplication concurrently, under the control of horizontal-type microinstructions. The SRT division method and CORDIC trigonometrical algorithm are used for a favorable cost/performance implementation. The performance of 6.7 MFLOPS in the vector-matrix multiplication at 20&nbsp;MHz has been attained by the use of parallel operations. The vector/matrix instruction is about three times faster than conventional add and multiply instructions. The chip has been fabricated in 1.2- mu m double-metal layer CMOS process containing 433000 transistors on an 11.6*14.9-mm/sup 2/ die size.| bibcode=1989IJSSC..24.1324N }}\n</ref>\n\n<ref name=\"overview\">\n{{cite journal |last1=Komoto |first1=Yasuhiko |last2=Saito |first2=Tatsuya|last3=Mine|first3=Kazumasa |date=1990-08-25 |title=Overview of 32-bit V-Series Microprocessor |format=pdf | url= https://ipsj.ixsq.nii.ac.jp/ej/index.php?action=pages_view_main&active_action=repository_action_common_download&item_id=59745&item_no=1&attribute_id=1&file_no=1&page_id=13&block_id=8 |journal=Journal of Information Processing |volume=13 |issue=2 |pages=110\u2013122 |doi= |issn=1882-6652 |language=en|access-date=2018-01-08|quote=Open Access<br/>Abstract:<br />The advances in semiconductor manufacturing technology make it possible to integrate a floating-point unit and a memory management unit noto one microprocessor chip. They also permit the designers of a microprocessor to implement techniques used in the design of mainframe computers especially with regard to pipeline structures. The architecture of the V60 V70 and V80 was made possible by there advances. The V60 and V70 are NEC's first 32-bit microprocessors and include almost all the functions required by applied systems in a chip. The instruction set provides a high-level-language-oriented structure operating system sup-port functions and support functions for highly reliable systems. The V80 also employs the same architecture and achieves higher performance by means of cache memories and branch prediction mechanisms. The V80achieved a performance from two to four times higher than that of the V70.}}\n</ref>\n\n<!----- JOURNAL, SOFTWARE ----->\n\n<ref name=\"PC-UX-R2-V60\">\n{{cite journal|url=http://id.nii.ac.jp/1001/00113909/|format=pdf|publisher=Information Society of Japan|title=PORTING UNIX System&nbsp;V TO THE V60 SYSTEMS|journal=\u5168\u56fd\u5927\u4f1a\u8b1b\u6f14\u8ad6\u6587\u96c6|volume=\u7b2c33\u56de|issue=\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u304a\u3088\u3073\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2|pages=163\u2013164|language=Japanese|access-date=2018-01-07|date=October 1986|last1=\u96c5\u5247|first1=\u5bfa\u672c|last2=\u5065\u6cbb|first2=\u8d64\u7fbd|last3=\u826f\u5f66|first3=\u548c\u7530|last4=\u7531\u7d00\u5b50|first4=\u6c34\u6a4b|last5=\u6ecb|first5=\u5ddd\u53c8}}\n</ref>\n\n<ref name=\"RX-UX-832\">\n{{Cite journal | doi = 10.1016/0165-6074(89)90105-1| title = Real-time UNIX operating system: RX-UX 832| journal = Microprocessing and Microprogramming| volume = 27| issue = 1\u20135| pages = 533\u2013538| date = August 1989| last1 = Mizuhashi | first1 = Yukiko | last2 = Teramoto | first2 = Msanoro |quote= <br/>Abstract:<br/>This paper describes requirements for real-time UNIX operating systems, design concept and the implementation of RX-UX 832 real-time UNIX operating system for v60/v70 microprocessor which are NEC's 32-bit microprocessors. RX-UX 832 is implemented adopting the building block structure, composed of three modules, real-time kernel, file-server and Unix supervisor. To guarantee a real-time responsibility, several enhancements were introduced such as, fixed priority task scheduling scheme, contiguous block file system and fault tolerant functions.<br/>Thus, RX-UX 832 allows system designers to use standard Unix as its man-machine interface to build fault tolerant systems with sophisticated operability and provides high-quality software applications on the high performance microchips. }}\n</ref>\n\n<ref name=\"Suzuki1992\">\n{{cite book|author=Norihisa Suzuki|title=Shared Memory Multiprocessing|url=https://books.google.com/books?id=Hyn9Cqf8PZsC&pg=PA195|date=January 1992|publisher=MIT Press|isbn=978-0-262-19322-1|page=195}}\n</ref>\n\n<ref name=\"8-V70-Proc\">\n[http://www.dtic.mil/dtic/tr/fulltext/u2/a240438.pdf Office of Naval Research Asian Office, Scientific Information Bulletin, Vol 16, No. 3 July-September 1991], p. 3\n</ref>\n\n<ref name=\"Inc.1991\">\n{{cite journal|author=Brett Glass|title=Answer Line|url=https://books.google.com/books?id=VlAEAAAAMBAJ&pg=PA72|date=6 May 1991|journal=InfoWorld|page=72|issn=0199-6649}}\n</ref>\n\n<ref name=\"FLEXOS\">\n{{cite journal |title=Digital Research launches FlexOS 286 Real-Time Manufacturing Operating System |editor=CBR |journal=Computer Business Review |date=1987-01-15 |url=http://www.cbronline.com/news/digital_research_launches_flexos_286_real_time_manufacturing_operating_system |access-date=2018-09-15 |url-status=live |archive-url=https://archive.is/U9oeA |archive-date=2013-01-18}}</ref>\n<ref name=rtos1997>\n{{cite journal |last1=Shimojima |first1=Takehiko |last2=Teramoto |first2=Masanori|year=1987 |title=V60 real-time operating system |journal=Microprocessing and Microprogramming|volume=21 |issue=1\u20135 |pages=197\u2013204 |doi=10.1016/0165-6074(87)90038-X|issn=0165-6074|quote=<br/>Abstract:<br/>This paper describes the requirements for 32-bit microprocessor real-time operating systems, design objectives and the implementation of the V60/V70 Real-Time Operating System (RTOS) and its programming supports.}}\n</ref>\n\n<!----- JOURNAL, CAD ----->\n\n<ref name=\"cad\">\n{{cite journal|last1=Kurosawa|first1=A.|last2=Yamada|first2=K.|last3=Kishimoto|first3=A.|last4=Mori|first4=K.|last5=Nishiguchi|first5=N.|title=A Practical CAD System Application for Full Custom VLSI Microcomputer Chips|journal=IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems|date=May 1987|volume=6|issue=3|pages=364\u2013373|doi=10.1109/TCAD.1987.1270281|issn=1937-4151|quote=<br/>Abstract:<br/>This paper presents a practical CAD system application for layout and verification, resulting in producible full-cutom VLSI microcomputer chips. The CAD system supports three design methodologies--symbolic layout mixed with mask level layout, compaction as an optimizer, and fully automated verification. For the area optimization, the symbolic layout and compactor subsystem supports a flexible description of orthogonal layout patterns with arbitrary dimensions in a loose placement manner. The layout patterns include path data, polygonal data, and symbolic cells. For power and delay optimization, the compactor compacts layout data, decreasing both resistance and capacitance for wires and ion-implanted layers. This feature is pioneering the new generation compactor. Emphasis should be put on the fact that it can compact layout data to a format 10-15 percent smaller than that accomplished manually. The verification subsystem can detect all kinds of errors, more than 30 items. A novel feature of the electrical rule check is that it investigates complementary logic errors for CMOS circuits. The synergy of those three design methodologies has brought about several significant advantages. One is manpower reduction by more than half, in the most complicated design process for unique random logic. The other is a 1600-transistors compaction output, smaller by 365 mils/sup 2/ than that manually compacted. The circuit implementation on a chip works at more than a 15&nbsp;MHz clock rate. Another is the first silicon success. It has been accomplished in a full-custom VLSI microcomputer chip consisting of more than 100 000 transistors.}}\n</ref>\n\n<!----- JOURNAL, V800 ----->\n\n<ref name=\"1992-ARC-06\">\n{{cite journal|last1=Harigai|first1=Hisao|last2=Kusuda|first2=Masaori|last3=Kojima|first3=Shingo|last4=Moriyama|first4=Masatoshi|last5=Ienaga|first5=Takashi|last6=Yano|first6=Yoichi|title=\u4f4e\u6d88\u8cbb\u96fb\u529b\u30fb\u4f4e\u96fb\u5727\u52d5\u4f5c\u306e32\u30d3\u30c3\u30c8\u30de\u30a4\u30af\u30ed\u30d7\u30ed\u30bb\u30c3\u30b5V810|journal=SIG Technical Reports, Information Processing Society of Japan|date=1992-10-22|volume=1992|issue=82 (1992-ARC-096)|pages=41\u201348|url=https://ci.nii.ac.jp/naid/170000021173|trans-title=A low power consumption and low voltage operation 32-bit RISC Microprocessor|quote=<br/>Abstract:<br/>An advanced 32-bit RISC microprocessor for embedded control; V810 is introduced in this paper. The V810 has high performance and application specified functions. V810 dissipates less power than any other RISC chips. The V810 is the first 32-bit RISC microprocessor that operates at 2.2V.<br/>The V810 chip is fabricated by using 0.8\u03bcm CMOS double metal layer process technology to integrate 240,000 transistors on a 7.7\u00d77.7mm<sup>2</sup> die.}}\n</ref>\n\n<ref name=\"IEIEC-1995\">\n{{cite journal|last1=Suzuki|first1=Hiroaki|last2=Sakai|first2=Toshichika|last3=Harigai|first3=Hisao|last4=Yano|first4=Yoichi|title=A 0.9-V, 2.5&nbsp;MHz CMOS 32-bit Microprocessor|journal=IEICE TRANSACTIONS on Electronics|date=1995-04-25|volume=E78-C|issue=4|pages=389\u2013393|url-access=subscription|url=http://search.ieice.org/bin/summary.php?id=e78-c_4_389&category=C&year=1995&lang=E|accessdate=2018-01-09|issn=0916-8516|quote=<br/>Summary:<br/>A 32-bit RISC microprocessor \"V810\" that has 5-stage pipeline structure and a 1 Kbyte, direct-mapped instruction cache realizes 2.5&nbsp;MHz operation at 0.9 V with 2.0 mW power consumption. The supply voltage can be reduced to 0.75 V. To overcome narrow noise margin, all the signals are set to have rail-to-rail swing by pseudo-static circuit technique. The chip is fabricated by a 0.8 \u03bcm double metal-layer CMOS process technology to integrate 240,000 transistors on a 7.4 mm7.1 mm die.}}\n</ref>\n\n<ref name=\"IEEE-1998\">\n{{cite journal |last1=Suzuki |first1=K. |last2=Arai |first2=T. |last3=Nadehara|first3=K.| last4=Kuroda|first4=I.|year=1998 |title=V830R/AV: embedded multimedia superscalar RISC processor |url= |journal=IEEE Micro |volume=18 |issue=2 |pages=36\u201347 |issn=0272-1732|doi=10.1109/40.671401 |access-date=|quote=<br/>Abstract:<br/>The V830R/AV's real-time decoding of MPEG-2 video and audio data enables practical embedded-processor-based multimedia systems.}}\n</ref>\n\n<!----- JOURNAL, JAPANESE ----->\n\n<ref name=\"SIG-ARC-043\">\n{{cite journal|last1=Yamahata|first1=Hitoshi|last2=Suzuki|first2=Nariko|last3=Koumoto|first3=Yasuhiko|last4=Shiiba|first4=Tadaaki|title=\u30de\u30a4\u30af\u30ed\u30d7\u30ed\u30bb\u30c3\u30b5V60\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3|journal=SIG Technical Reports; Microcomputer 43-2|date=1987-02-06|volume=1987|issue=8(1986-ARC-043)|pages=1\u20138|url=https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_uri&item_id=24887&file_id=1&file_no=1|trans-title=Architecture of the microprocessor V60|publisher=Information Processing Society of Japan|language=ja|format=PDF|id=AN10096105|quote=<br/>This report will describe a single chip 32-bit CMOS VLSI microprocessor V60. It has been implemented by using a double metal-layer CMOS process technology with 1.5 um design rule to integrate 375,000 transistors. It integrates the virtual memory management unit for demand paging and the floating-point operations that conform to the IEEE-754 Floating-Point Standard. By using V20/V30 emulation mode, it can directly execute object programs of 16-bit CPU (V30). Instruction formats are suited to code-generation phase of compilers. 237 instructions are provided for high-level language and operating system. It can execute 3.5 MIPS (Million Instructions per Second) at 16-MHz operation with 16-bit data bus.}}\n</ref>\n\n<ref name=\"SIG-ARC-069\">\n{{cite journal|last1=Takahashi|first1=Toshiya|last2=Yano|first2=Yoichi|title=V60/V70\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3|journal=SIG Technical Reports|date=1988-01-21|volume=1988|issue=4(1987-ARC-069)|pages=57\u201364|url=https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_uri&item_id=24816&file_id=1&file_no=1|trans-title=The Architecture of V60/V70 Microprocessors|publisher=Information Processing Society of Japan|language=ja|format=PDF|id=AN10096105|quote=<br/>This report describes the architecture of V60/V70 32-bit microprocessors. The architecture integrates various features into a single silicon die, such as a rich set of general purpose registers, high level language oriented instruction set, floating-point data handling which is suitable for scientific applications, and the FRM (Functionality Redundancy Monitoring) operation mode which supports highly-reliable systems configuration. These features will be introduced.}}\n</ref>\n\n<ref name=\"dev-story\">\n{{Cite web|url=http://www.shmj.or.jp/dev_story/pdf/develop46.pdf|first1=Yoichi|last1=Yano|date=April 2012|publisher=Semiconductor History Museum of Japan|language=Japanese|access-date=2018-01-08|title=32\u30d3\u30c3\u30c8\u30fb\u30de\u30a4\u30b3\u30f3\u300cV60\u300d\u958b\u767a\u7269\u8a9e|trans-title=Development story of the 32-bit microcomputer V60}}<br/>\n{{Cite journal|format=pdf|url=http://www.ssis.or.jp/encore/encore2012.html#no75|journal=Bulletin \"Encore\"|date=April 2012|volume=75|pages=17\u201320|publisher=Society of Semiconductor Industry Specialists|title=ditto|language=Japanese|access-date=2018-01-08}}\n</ref>\n\n<ref name=\"32b-itron\">\n{{cite journal|last1=Monden|first1=Hiroshi|last2=Teramoto|first2=Takashi|last3=Koga|first3=Masanori|title=V60\u7528\u30a2\u30eb\u30bf\u30a4\u30e0OS\u306e\u691c\u8a0e\u3000\uff0d32\u30d3\u30c3\u30c8I&#8209;TRON\u306b\u5411\u3051\u3066\uff0d|journal=SIG (ARC) Technical Reports|date=1986-03-14|volume=1986|issue=19(1985-ARC-061)|pages=1\u20138|url=https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_action_common_download&item_id=24938&item_no=1&attribute_id=1&file_no=1|trans-title=Feasibility study of real-time OS for the V60 - toward for the 32-bit I&#8209;TRON -|publisher=Information Processing Society of Japan|language=Japanese|format=PDF|id=AN10096105|quote=Open Access}}</ref>\n\n<!----- JOURNAL, NEC-TECHNICAL ----->\n\n<ref name=\"nectech-jaxagcc\">\nHAYASHI, N. [http://www.nec.com/en/global/techrep/journal/g11/n01/pdf/110130.pdf Guidance Control Computer for Launch Vehicle], NEC Technical Journal, Vol. 6, No. 1/2001, pp. 145-148\n</ref>\n\n<ref name=\"nec-tecj-ms4100\">\n{{Cite journal|url=http://jglobal.jst.go.jp/en/public/20090422/200902041619492749|title=The outline of NEC super minicomputer MS4100 Series, NEC Technical Journal |journal=Nec\u6280\u5831 |volume=39 |issue=11 |pages=113\u2013124 |publisher=NEC Technical Journal, Vol.39 Iss.11 p.p.113-124, Nov. 1986|language=Japanese|year=1986 |last1=Takeo |first1=Sakurai |last2=Osamu |first2=Oizumi }}\n</ref>\n\n<!----- JOURNAL, Meidensha Corp ----->\n\n<ref name=\"Meiden-Jiho-Jul92\">\n{{cite journal|last1=OSAMU|first1=TSUJI|last2=SATORU|first2=KOMIYAMA|last3=TOSHIYUKI|first3=DOI|last4=TETSUYA|first4=IWAKI|title=\u60c5\u5831\u6a5f\u5668 \u5de5\u696d\u7528\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u03bcPORT\u2010III|journal=\u660e\u96fb\u6642\u5831 [Meiden Jiho]|date=July 1992|issue=225|pages=24\u201332|url=http://jglobal.jst.go.jp/en/public/20090422/200902079033599746|trans-title=Information-processing equipment.Industrial computer .MU.PORT-III.|language=ja|issn=0386-1570}}\n</ref>\n\n<ref name=\"Meiden-Jiho-May93\">\n{{cite journal|last1=HISAO|first1=SASAKI|last2=AKIRA|first2=SATO|last3=TOSHIO|first3=KARAKAMA|title=\u5de5\u696d\u7528\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u03bcPORT\u2010III\u3068\u9069\u7528\u4e8b\u4f8b|journal=\u660e\u96fb\u6642\u5831 [Meiden Jiho]|date=May 1993|issue=230|pages=41\u201344|url=http://jglobal.jst.go.jp/en/public/20090422/200902104337850113|trans-title=Applications of industrial computer .MU.PORT-III.|language=ja|issn=0386-1570}}\n</ref>\n\n<!----- JOURNAL, AUTHOR==OTHERS ----->\n\n<ref name=\"MIPS-1984\">\n{{cite journal|last1=Rowen|first1=C.|last2=Przbylski|first2=S.|authorlink3=Norman Jouppi|last3=Jouppi|first3=N.|last4=Gross|first4=T.|last5=Shott|first5=J.|last6=Hennessy|first6=J.|title=A pipelined 32b NMOS microprocessor|journal=1984 IEEE International Solid-State Circuits Conference. Digest of Technical Papers|date=1984|volume=XXVII|pages=180\u2013181|doi=10.1109/ISSCC.1984.1156607|quote=<br/>Stanford MIPS}}\n</ref>\n\n<ref name=\"RISC-II\">\n{{cite journal|last1=Sherburne|first1=R. W.|last2=Katevenis|first2=M. G. H.|last3=Patterson|first3=D. A.|last4=Sequin|first4=C. H.|title=A 32-bit NMOS microprocessor with a large register file|journal=IEEE Journal of Solid-State Circuits|date=1984|volume=19|issue=5|pages=682\u2013689|doi=10.1109/JSSC.1984.1052208|issn=0018-9200|quote=<br/>UCB RISC-II|bibcode=1984IJSSC..19..682S}}\n</ref>\n\n<ref name=\"R2000\">\n{{cite journal|last1=Riordan|first1=T.|last2=Grewal|first2=G. P.|last3=Hsu|first3=S.|last4=Kinsel|first4=J.|last5=Libby|first5=J.|last6=March|first6=R.|last7=Mills|first7=M.|last8=Ries|first8=P.|last9=Scofield|first9=R.|title=The MIPS M2000 system|journal=Proceedings 1988 IEEE International Conference on Computer Design: VLSI|date=1988|pages=366\u2013369|doi=10.1109/ICCD.1988.25724|quote=<br/>MIPS M2000 (R2000)|isbn=0-8186-0872-2}}\n</ref>\n\n<ref name=\"First-SPARC\">\n{{cite journal|last1=Namjoo|first1=M.|last2=Agrawal|first2=A.|last3=Jackson|first3=D. C.|last4=Quach|first4=L.|title=CMOS gate array implementation of the SPARC architecture|journal=Digest of Papers. COMPCON Spring 88 Thirty-Third IEEE Computer Society International Conference|date=1988|pages=[https://archive.org/details/compconspring8830000ieee/page/10 10\u201313]|doi=10.1109/CMPCON.1988.4818|url=https://archive.org/details/compconspring8830000ieee/page/10|quote=<br/>SPARC, 1st Gen.|isbn=0-8186-0828-5}}\n</ref>\n\n<ref name=\"i860\">\n{{cite journal|last1=Kohn|first1=L.|last2=Fu|first2=S. W.|title=A 1,000,000 transistor microprocessor|journal=IEEE International Solid-State Circuits Conference, 1989 ISSCC. Digest of Technical Papers|date=1989|pages=54\u201355|doi=10.1109/ISSCC.1989.48231|quote=<br/>Intel 860}}\n</ref>\n\n<ref name=\"i486-ICCD89\">\n{{cite journal|last1=Fu|first1=B.|last2=Saini|first2=A.|last3=Gelsinger|first3=P. P.|title=Performance and microarchitecture of the i486 processor|journal=Proceedings 1989 IEEE International Conference on Computer Design: VLSI in Computers and Processors|date=1989|pages=182\u2013187|doi=10.1109/ICCD.1989.63352|isbn=0-8186-1971-6|quote=<br/>Intel 80486<br/>Abstract:<br/>The i486 microprocessor includes a carefully tuned, five-stage pipeline with an integrated 8-kB cache. A variety of techniques previously associated only with RISC (reduced-instruction-set computer) processors are used to execute the average instruction in 1.8 clocks. This represents a 2.5* reduction from its predecessor, the 386 microprocessor. The pipeline and clock count comparisons are described in detail. In addition, an onchip floating-point unit is included which yields a 4* clock count reduction from the 387 numeric coprocessor. The microarchitecture enhancements and optimizations used to achieve this goal, most of which are non-silicon-intensive, are discussed. All instructions of the 386 microprocessor and the 387 numeric coprocessor are implemented in a completely compatible fashion.}}\n</ref>\n\n<ref name=\"i486-Micro-1990\">\n{{cite journal|last1=Crawford|first1=J.H.|title=The i486 CPU: executing instructions in one clock cycle|journal=IEEE Micro|date=February 1990|volume=10|issue=1|pages=27\u201336|doi=10.1109/40.46766|issn=0272-1732|citeseerx=10.1.1.126.4216}}\n</ref>\n\n<ref name=\"pj\">\n{{cite journal|last1=Hardenbergh |first1=Hal W | title=RISCs CISCs and Fabs|journal=Programmer's Journal|year=1988|publisher=Avant-Garde Creations|volume=6|issue=2|page=15|quote=<br/>So far we haven't mentioned two 32-bit CISC chips, the NEC V60/70 and the AT&T WE32 family. Unlike the NEC V20/25/30/50, the V60/70 is ''not'' based on the Intel architecture. NEC is targeting the V60/70 at embedded applications, ... }}\n[https://books.google.com/books?id=iX8qAAAAMAAJ&q=V60/70 Google Books]\n</ref>\n\n<ref name=\"trend\">\n{{cite journal |last1=Sakamura|first1=Ken|date=April 1988 |title=Recent Trends |url=http://www.computer.org/csdl/mags/mi/1988/02/m2010.pdf |journal=IEEE Micro |volume=8 |issue=2 |pages=10\u201311 |doi= |issn=0272-1732|pmc= |pmid= |access-date=2018-01-08 |quote=<br/>The V60/V70, NEC's proprietary CPU, is the first commercial-base, general-purpose, 32-bit microprocessor in Japan.}}\n</ref>\n\n<ref name=\"Wade, 1996\">\n{{cite journal|last1=Wade|first1=James|title=A Community-Level Analysis of Sources and Rates of Technological Variation in the Microprocessor Market|journal=Academy of Management Journal|date=1 October 1996|volume=39|issue=5|pages=1218\u20131244|doi=10.2307/256997|url=http://amj.aom.org/content/39/5/1218.short|language=en|issn=0001-4273|quote=<br/>7 The sponsors that did not use RISC technology were NEC, AT&T, and Followers of the TRON standard. All three of these microprocessors were specialized for users for whom performance was the highest priority. The Hitachi microprocessor followed the TRON standard, a high-performance CISC technology that, Japanese developers suggested, would be a viable alternative to RISC. The AT&T chip was portrayed as a chip suitable for building top-of-the-line, minicomputer-like computing systems. Similarly, NEC's V60 and V70 were patterned after one of NEC's 36-bit mainframe computers.|jstor=256997}}\n</ref>\n\n<ref name=\"Majithi, 1987\">\n{{cite journal|last1=Majithi|first1=Kenneth|title=The New Generation of Microprocessors|journal=IEEE Micro|date=1987|volume=7|issue=4|pages=4\u20135|doi=10.1109/MM.1987.304873|issn=0272-1732|quote=<br/>The Japanese have been equally aggressive in their new designs of high-performance microprocessors. NEC's V60 and V70 microprocessors use architectures that include not only the MMU but also an arithmetic floating-point unit on chip. Hitachi and Fujitsu have collaborated to produce a family of microprocessors adapted to the TRON operating system. These processors incorporate instruction pipelines as well as instruction and stack caches. However, unlike NEC, their FPU function is off chip.}}\n</ref>\n\n<!------------------->\n<!----- CATALOG ----->\n<!------------------->\n\n<ref name=\"cat-fr\">\n{{cite web|author1=NEC|title=Microprocessors and Peripherals Data Book|url=http://matthieu.benoit.free.fr/cross/data_sheets/NEC_Microprocessors-and-Peripherals_Data_Book.htm}}\n</ref>\n\n<ref name=\"cat89\">\n{{cite book|author1=NEC|title=Intelligent Peripheral Devices Data Book|url=https://archive.org/details/bitsavers_necdataBootPeripheralDevicesDataBook_33483764|publisher=The Internet Archive, a 501(c)(3) non-profit|page=18|date=June 1989}}\n</ref>\n\n<ref name=\"cat90\">\n{{cite book|author1=NEC|title=Single-Chip Microcontroller Data Book|url=https://archive.org/details/bitsavers_necdatabooMicrocontrollerDataBook_57118308|publisher=The Internet Archive, a 501(c)(3) non-profit|page=30|date=May 1990}}\n</ref>\n\n<ref name=\"cat95\">\n{{cite web|author1=NEC|title=SEMICONDUCTOR SELECTION GUIDE|edition=10th|date=Oct 1995|url=http://icbank.com/data/ICBShop/board/D72611GF.pdf}}\n</ref>\n\n<ref name=\"cat99\">\n{{cite web|author1=NEC|title=SEMICONDUCTORS SELECTION GUIDE|edition=17th|url=http://www.littlediode.com/datasheets/pdf/Datasheets-NEC/NEC-SHORTFORM.PDF|date=April 1999}}\n</ref>\n\n<ref name=\"cat05\">\n{{cite web|title=Microcontrollers and Development Tools Selection Guide|url=http://www1.futureelectronics.com/doc/RENESAS%20ELECTRONICS/NECMicrocontrollerGuide%5B1%5D.pdf|author=NEC|date=May 2005}}\n</ref>\n\n<!------------------------>\n<!----- WEB MATERIAL ----->\n<!------------------------>\n\n<!----- WEB, ACADEMIC ----->\n\n<ref name=ric-tan>\n{{cite web|url=http://www.stanford.edu/group/htgg/sts145papers/rtan_2001_2.pdf|author=Richard Tan|title=STS 145 Case Study Sega: The effect of corporate conflict on game design| quote=<br/>\"The Saturn originally ran on a NEC V60 chip at 16MHz. Compare this to the PlayStation CPU ([[MIPS architecture|MIPS]] R3000A 32bit [[Reduced instruction set computer|RISC]] chip) which runs are 33.8MHz, almost double the speed. According to one Sega staff member, when Nakayama first received design specifications for the PlayStation, he was \u2018the maddest I have ever seen him\u2019, calling up the entire R&D division to his office to shout at them. An effort was made to compensate by adding another CPU for dual operation; however, this solution made the system so hard to develop for that, according to Yu Suzuki himself, \u201conly 1 out of 100 programmers could use the Saturn to its full potential.\u201d\"}}\n</ref>\n\n<!----- WEB, NEC ----->\n\n<ref name=\"ps98-145-hmw\">\n{{Cite web|url=http://121ware.com/support/product/data/spec/sft/sw225d-1.html |title=Model Number: PS98-145-HMW, Item Name: PC-UX/V(Rel2.0)(V60) |publisher=NEC product sheet}}\n</ref>\n\n<!----- WEB, GHS ----->\n\n<ref name=\"GHS-V850\">\n{{cite web|title=V850 and RH850 Embedded Software Solutions|url=https://www.ghs.com/products/v850_development.html|website=www.ghs.com|publisher=Green Hills Software}}\n</ref>\n\n<!----- WEB, MIPS ----->\n\n<ref name=\"HIREC-HR5000\">\n{{cite web|last1=Voica|first1=Alex|title=Back to the future: 64-bit MIPS CPU explores the origins of the solar system \u2013 MIPS|url=https://www.mips.com/blog/back-to-the-future-64-bit-mips-cpu-explores-rare-asteroid/|website=www.mips.com|publisher=MIPS|language=en|date=2015-07-29}}\n</ref>\n\n<ref name=\"MIPS64-5Kf-DS\">\n{{cite book|title=MIPS64 5Kf Processor Core Datasheet|date=2005-01-31|publisher=MIPS Technologies Inc.|edition=01.04|url=http://wiki.prplfoundation.org/w/images/f/f1/MD00111-2B-4KEC-DTS-02.03.pdf|language=en}}\n</ref>\n\n<!----- WEB, MAME DEV ----->\n\n<ref name=\"v60-cemu\">\n{{cite web|url=http://mamedev.org/source/src/emu/cpu/v60/v60.c.html |title=MAME:/src/emu/cpu/v60/v60.c |publisher=Mamedev.org |date= |accessdate=2014-02-15 |archiveurl=https://web.archive.org/web/20140222070653/http://mamedev.org/source/src/emu/cpu/v60/v60.c.html |archivedate=2014-02-22 }}\n</ref>\n\n<ref name=\"mamedev1\">\n{{cite web|url=http://mamedev.org/source/src/mame/drivers/segas32.c.html |title=MAME:/src/mame/drivers/segas32.c |publisher=Mamedev.org |date= |accessdate=2014-02-15 |archiveurl=https://web.archive.org/web/20140403190647/http://mamedev.org/source/src/mame/drivers/segas32.c.html |archivedate=2014-04-03}}\n</ref>\n\n<ref name=\"mamedev-model1\">\n{{cite web|url=http://mamedev.org/source/src/mame/drivers/model1.c.html |title=MAME:/src/mame/drivers/model1.c |publisher=Mamedev.org |date= |accessdate=2014-02-15 |archiveurl=https://web.archive.org/web/20140403180645/http://mamedev.org/source/src/mame/drivers/model1.c.html |archivedate=2014-04-03}}\n</ref>\n\n<ref name=\"mamedev-ssv\">\n{{cite web|url=http://mamedev.org/source/src/mame/drivers/ssv.c.html |title=MAME:/src/mame/drivers/ssv.c |publisher=Mamedev.org |date= |accessdate=2014-02-15 |archiveurl=https://web.archive.org/web/20140403215238/http://mamedev.org/source/src/mame/drivers/ssv.c.html |archivedate=2014-04-03}}\n</ref>\n\n<ref name=\"mamedev-mc32\">\n{{cite web|url=http://mamedev.org/source/src/mame/drivers/ms32.c.html |title=MAME:/src/mame/drivers/ms32.c |publisher=Mamedev.org |date= |accessdate=2014-02-15 |archiveurl=https://web.archive.org/web/20140403182226/http://mamedev.org/source/src/mame/drivers/ms32.c.html |archivedate=2014-04-03}}\n</ref>\n\n<!----- WEB, PLANET VIRTUAL BOY ----->\n\n<ref name=\"V810-GCC\">\n{{cite web|title=A newer GCC compiler. \u00ab Virtual Boy Development Board \u00ab Forum \u00ab Planet Virtual Boy|url=http://www.planetvb.com/modules/newbb/viewtopic.php?topic_id=6456|website=www.planetvb.com|language=en}}\n</ref>\n\n<!----- WEB, DATAQUEST ----->\n\n<ref name=\"dataquest-1986\">\n[[Dataquest]], \"Japanese Semiconductor Industry Service\", 1st Quarter 1986, p. 18 (pdf p. 44 in [http://archive.computerhistory.org/resources/access/text/2013/04/102723432-05-01-acc.pdf this multi-volume archive])\n</ref>\n\n<ref name=\"dataquest-1987\">\n[[Dataquest]], \"Japanese Semiconductor Industry Service\", 1st Quarter 1987, p. 18 (pdf p. 182 in [http://archive.computerhistory.org/resources/access/text/2013/04/102723432-05-01-acc.pdf this multi-volume archive])</ref>\n\n<ref name=\"dataquest-1987-2\">\n[[Dataquest]], \"Japanese Semiconductor Industry Service\", 2nd Quarter 1987, p. 21 (pdf p. 223 in [http://archive.computerhistory.org/resources/access/text/2013/04/102723432-05-01-acc.pdf this multi-volume archive])</ref>\n\n<!----- WEB, COMPUTER BUSINESS REVIEW ----->\n\n<ref name=\"CBR-1\">\nNEC LAUNCHES V80 ANSWER TO INTEL's 80486 - Computer Business Review, 1989-03-15\nBalcklist:www.cbronline.com/news/nec_launches_v80_answer_to_intels_80486\n</ref>\n\n<ref name=\"CBR-2\">\nNEC MAY HAVE THE EDGE WITH ITS 930,000 TRANSISTOR V80 ANSWER TO INTEL'S 80486 - Computer Business Review, 1989-04-06\nBalcklist:www.cbronline.com/news/nec_may_have_the_edge_with_its_930000_transistor_v80_answer_to_intels_80486\n</ref>\n\n<!----- WEB, MUSEUM ----->\n\n<ref name=\"ipsj-bungo\">\n{{cite web|url=http://museum.ipsj.or.jp/en/computer/word/0058.html|publisher=museum.ipsj.or.jp|title=Bungo mini 5SX\uff0cBungo mini 7SX\uff0cBungo mini 7SD \u2013 Computer Museum |access-date=2017-04-22}}\n</ref>\n\n<ref name=\"ispj-ms4100\">\n{{Cite web |url=http://museum.ipsj.or.jp/en/computer/mini/0027.html |publisher=museum.ipsj.or.jp | title=MS-4100 Series - Computer Museum|language=en|access-date=2018-01-07}}\n</ref>\n\n<ref name=\"nij-ms4100\">\n{{Cite web|url=https://dbnst.nii.ac.jp/pro/detail/282|title=MS4100 Series|publisher=dbnst.nii.ac.jp|language=Japanese|access-date=2018-01-08}}\n</ref>\n\n<ref name=\"HP64700\">\n{{Cite web|url=http://www.hpmuseum.net/display_item.php?hw=1086|title=HP Computer Museum|language=en|access-date=2018-01-07}}\n</ref>\n\n<!----- WEB, JAXA ----->\n\n<ref name=\"JAXA-Kibo\">\n{{cite web|title=Kibo HANDBOOK|url=http://iss.jaxa.jp/kibo/library/fact/data/kibo-handbook_en.pdf|publisher=JAXA|page=101|date=September 2007}}\n</ref>\n\n<ref name=\"Kibo-EDEE\">\n{{cite web|title=Space Environment Data Acquisition equipment-Attached Payload (SEDA/AP)|url=http://iss.jaxa.jp/en/kiboexp/ef/seda-ap/|website=iss.jaxa.jp|publisher=JAXA|language=en|date=2007-03-30}}\n</ref>\n\n<ref name=\"jaxa-roadmap\">\n{{cite web|title=JAXA's LSI (MPU/ASIC) roadmap, p. 9; excl. front|url=https://eeepitnl.tksc.jaxa.jp/mews/en/21st/data/2-1.pdf |website=Development Status for JAXA Critical Parts, 2008|publisher=JAXA}}\n</ref>\n\n<ref name=\"jaxa-status-2013\">\n{{cite web|title=Development Status of JAXA EEE Parts |url=https://eeepitnl.tksc.jaxa.jp/mews/jp/26th/data/2_12_1.pdf  |website=Development Status for JAXA Critical Parts, 2008|publisher=JAXA}}\n</ref>\n\n<ref name=\"jaxa-eee-parts\">\n{{Cite web|url=https://eeepitnl.tksc.jaxa.jp/en/Critical_P/completed/index_e.html|title=Database of JAXA Qualified EEE Parts and Material: Critical Parts|publisher=JAXA|language=en|access-date=2018-01-07}}\n</ref>\n\n<ref name=\"Kibo-SEE\">\n{{cite web|title=\u56fd\u969b\u5b87\u5b99\u30b9\u30c6\u30fc\u30b7\u30e7\u30f3\u300c\u304d\u307c\u3046\u300d\u8239\u5916\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u642d\u8f09 \u5b87\u5b99\u74b0\u5883\u8a08\u6e2c\u30df\u30c3\u30b7\u30e7\u30f3\u88c5\u7f6e\uff08\uff33\uff25\uff24\uff21\uff0d\uff21\uff30\uff09|url=http://www.icrr.u-tokyo.ac.jp/~hmiya/5th_sympo/Goka_Chimon2010.pdf|pages=52\u201353|language=ja|trans-title=Space Environment Data Acquisition Equipment \u2013 Attached Payload (SEDA-AP) on the ISS - \u201cKibo\u201d Exposed Facility}}\n</ref>\n\n<!----- WEB, CODE ----->\n\n<ref name=\"GCC-Internal\">\n{{Cite web|url=https://gcc.gnu.org/onlinedocs/gccint/Frame-Registers.html|title=GNU Compiler Internals}}\n</ref>\n\n<ref name=\"by-cygnus-1\">\n{{cite mailing list |url=https://gcc.gnu.org/ml/gcc-patches/1999-02n/msg00703.html |title=Patch to replace CYGNUS LOCAL with EGCS LOCAL in config.sub |date=1999-02-25 |mailing-list=gcc-patches |last= |first= |author=[[Cygnus Solutions]] |authorlink= |language= |ref= |quote=<br/>Hi Guys,<br/>I would like to submit the following patch.  It renames all occurrences of CYGNUS LOCAL to EGCS LOCAL, which seems slightly more accurate! :-)<br/>Cheers<br/>Nick}}\n</ref>\n\n<ref name=\"by-cygnus-2\">\n{{cite mailing list |url=https://gcc.gnu.org/ml/gcc-patches/1999-02n/msg00704.html |title=Re: Patch to replace CYGNUS LOCAL with EGCS LOCAL in config.sub |date=1999-02-25 |accessdate= |mailing-list=gcc-patches |last= |first= |author=[[Cygnus Solutions]] |authorlink= |language= |ref= |quote=<br/>Seems like a misguided exercise to me.<br/>If the changes are truly Cygnus-specific, they should not be in Egcs. Otherwise, they should be merged into the config.sub master copy (whose maintainer, by the way, in Ben!).}}\n</ref>\n\n<ref name=\"egcs\">\n{{Cite web|url=https://opensource.apple.com/source/gcc/gcc-926/config.sub.auto.html|title=gcc/gcc-926/config.sub|author=Cygnus Solutions|publisher=Apple Inc.|access-date=2018-01-07}}</ref>\n\n<ref name=\"newlib\">\n{{cite web|url=http://www.embedded.com/design/prototyping-and-development/4024867/Embedding-with-GNU-Newlib |title=Embedding with GNU: Newlib |publisher=Embedded |date=2001-12-28 |access-date=2014-02-15}}\n</ref>\n\n<ref name=\"Inc.1991\">\n{{cite journal|author=Brett Glass|title=Answer Line|url=https://books.google.com/books?id=VlAEAAAAMBAJ&pg=PA72|date=6 May 1991|journal=InfoWorld|page=72|issn=0199-6649}}\n</ref>\n\n<ref name=\"ada83cpl\">\n{{cite web|url=http://archive.adaic.com/compilers/ada83cpl.html |title=Ada 83 Certified Processor List |publisher=Archive.adaic.com |date=1998-03-31 |accessdate=2014-02-15}}\n</ref>\n\n<ref name=\"MV&#8209;4000\">\n{{cite web|url=http://www.chipcatalog.com/NEC/MV&#8209;4000.htm |title=MV&#8209;4000 |publisher=Chipcatalog.com |date= |accessdate=2014-02-15}}\n</ref>\n\n<ref name=\"ews-4800\">\n[http://www006.upp.so-net.ne.jp/tati/docs/48summary.txt History-of-48series] (refers to the [[:ja:EWS4800|''EWS 4800'']] NEC computers)\n</ref>\n\n<!----- WEB, KEYSIGHT ----->\n\n<ref name=\"HP64758G\">\n{{Cite web|url=https://www.keysight.com/en/pd-64758G%3Aepsg%3Apro-pn-64758G/v70-20mhz-emulation-subsystem-512kb?lc=eng|title=64758G V70 20MHz emulation subsystem 512KB|publisher=Keysight|language=en|access-date=2018-01-08}}\n</ref>\n\n<ref name=\"HP-discon\">\n{{Cite web|url=https://www.keysight.com/upload/cmc_upload/All/Disco_Products_not_on_site.pdf|page=97|title=Agilent Test & Measurement Discontinued Products|publisher=Keysight|access-date=2018-01-08}}\n</ref>\n\n<ref name=\"HP-Vseries\">\n{{Cite web|url=http://literature.cdn.keysight.com/litweb/pdf/5091-2705E.pdf |title=HP Emulators and Development Solutions for NEC V Series Microprocessors|page=13|publisher=Keysight|language=en|access-date=2018-01-07}}\n</ref>\n\n<!----- WEB, GENERAL ----->\n\n<ref name=\"google-groups\">\n{{cite web|url=https://groups.google.com/d/msg/comp.arch/o99tLF7STeE/OjX1y09VggwJ|title=Google Groups \u2013 Some comments on the NEC V60/V70 |accessdate=2017-04-22}}\n</ref>\n\n<ref name=\"V80-rumor\">\n{{cite web|title=NEC V80|url=https://groups.google.com/forum/#!topic/comp.arch/NMTvNkMzef0|website=groups.google.com|publisher=Google Groups}}</ref>\n\n<ref name=\"akatsuki\">\n{{Cite web|url=http://www.cpushack.com/2015/12/11/akatsuki-dawn-rises-again-at-venus/|title=Akatsuki: Dawn rises again at Venus|language=en|access-date=2018-01-07}}\n</ref>\n\n<ref name=\"EDN\">\n{{cite web|url=http://www.edn.com/electronics-news/4347599/NEC-Wraps-ARM-into-Gate-Arrays-4347599|publisher=edn.com|title=NEC Wraps ARM into Gate Arrays &#124; EDN|accessdate=2017-04-22}}\n</ref>\n\n<ref name=\"metaware\">\n{{cite web|title=MetaWare, Inc.|url=https://www.crunchbase.com/organization/metaware-inc|publisher=crunchbase|quote=<br/>MetaWare, Inc.<br/>MetaWare, Inc. is a supplier of tools and technologies for software developers.<br/>Santa Cruz, California, United States<br/>MetaWare, Inc. is a privately held company operates as a supplier of tools and technologies for software developers.}}\n</ref>\n\n<ref name=\"high-c\">\n{{cite web|title=MetaWare High C/C++|url=http://www.edm2.com/index.php/MetaWare_High_C/C%2B%2B|publisher=EDM/2}}\n</ref>\n\n<ref name=\"CNET-2007\">\n{{cite web|title=Despite its aging design, the x86 is still in charge|url=https://www.cnet.com/news/despite-its-aging-design-the-x86-is-still-in-charge/|website=CNET|language=en}}\n</ref>\n\n}}\n\n== External links ==\n* [http://itpro.nikkeibp.co.jp/article/COLUMN/20051201/225552/?SS=imgview&FD=-791347235&ST=system Die photo of the V60; at Nikkei BP (in Japanese)]\n* [http://www.shmj.or.jp/shimura/ssis_shimura2_19.htm Die photo of the V60]; at Semiconductor History Museum of Japan (in Japanese)\n* [https://cn.freeimages.com/photo/silicon-chip-1564335 Die photo of the V60], mounted on [[Pin grid array|PGA]] package (much clear, in Chinese)\n* [https://cn.freeimages.com/photo/silicon-chip-with-die-1564477 Die photo of the V60] with [[Pin grid array|PGA]] packaging, removed ceramic cap (in Chinese)\n* [http://canoro.altervista.org/cpu/fotogallery2.php?idcpu=necd70616r-16mio Photo of the V60] in [[Pin grid array|PGA]] packaging w/ ceramic cap shield; glass shield\n* [https://www.cpucollection.ca/NecD70616R-16.jpg Photo of the V60] in [[Pin grid array|PGA]] packaging w/ metal cap shield; seam weld\n* [http://ozuma.o.oo7.jp/unix/ux-v/ Blog: PS98-145-HMW kit: \"PC-UX/V\" w/ 15 disks & \"V60 Sub board\"]  for [[NEC PC-9801]] slot (in Japanese)\n* [http://www.cpushack.com/2015/12/11/akatsuki-dawn-rises-again-at-venus/ Article: V70 in PGA packaging] and the [[H-IIA|H-IIA rocket]] (in English)\n* [http://www.retroclinic.com/leopardcats/vrtwin/vrtwin.htm Photo of NEC V60 CPU board] of the [[Virtua Racing|Sega Virtua Racing]] (in English)\n* [http://www.system16.com/hardware.php?id=709 Site: \"System 16\"] - [[List of Sega arcade system boards#Sega System 32|Sega System 32]] Hardware (in English)\n* [http://www.system16.com/hardware.php?id=712 Site: \"System 16\"] - [[List of Sega arcade system boards#Sega Model 1|Sega Model 1]] Hardware (in English)\n* [http://www.system16.com/hardware.php?id=710 Site: \"System 16\"] - [[List of Sega arcade system boards#System Multi 32 specifications|Sega System Multi 32]] Hardware (in English)\n* Original documents for the V60 (\u03bcPD70616) & V70 (\u03bcPD70632) is available from [http://mess.redump.net/datasheets/nec/ here].\n* Datasheets for the AFPP (\u03bcPD72691) is available from [http://www.datasheetarchive.com/uPD72691-datasheet.html here].\n* [https://www.renesas.com/en-us/products/microcontrollers-microprocessors/v850.html Renesas V850 Family web site]\n* [https://www.renesas.com/en-us/products/microcontrollers-microprocessors/rh850.html Renesas RH850 Family web site]\n\n<!-- * [https://www.cpu-world.com/forum/viewtopic.php?t=19572 Photos of the V60 and V70 in their packaging] -->\n\n[[Category:NEC microprocessors|V60|V70|V80|AFPP|NEC V60|NEC V70|NEC V80|NEC AFPP]]\n[[Category:Microprocessors|NEC V60]]\n[[Category:Coprocessors|NEC AFPP|NEC \u03bcPD72691]]\n[[Category:Video game hardware|NEC V60]]\n[[Category:32-bit microprocessors]]\n", "name_user": "Alistair1978", "label": "safe", "comment": "copyedit", "url_page": "//en.wikipedia.org/wiki/NEC_V60"}
{"title_page": "Laplace transform", "text_new": "{{redirect|\u2112|the Lagrangian|Lagrangian mechanics}}\nIn [[mathematics]], the '''Laplace transform''' is an [[integral transform]] named after its inventor [[Pierre-Simon Laplace]] ({{IPAc-en|l|\u0259|\u02c8|p|l|\u0251:|s}}).  It transforms a function of a real variable {{math|''t''}} (often time) to a function of a [[complex analysis|complex variable]] {{mvar|s}} ([[complex frequency]]). The transform has many applications in science and engineering.\n\n{{Gallery|width=265 | height=150 |lines=2 |align=right|File:Graph of e^t cos(10t).png|An example curve of e^t cos(10t) that is added together with similar curves to form a Laplace Transform.|File:Laplace animation of Cubic Polynomial.gif|Animation showing how adding together curves can approximate a function.}}\n\nThe Laplace transform is similar to the [[Fourier transform]].  While the Fourier transform of a function is a [[complex function]] of a ''real'' variable (frequency), the Laplace transform of a function is a complex function of a ''complex variable''.  The Laplace transform is usually restricted to transformation of functions of {{math|''t''}} with {{math|''t'' \u2265 0}}.  A consequence of this restriction is that the Laplace transform of a function is a [[holomorphic function]] of the variable {{math|''s''}}.  Unlike the Fourier transform, the Laplace transform of a [[distribution (mathematics)|distribution]] is generally a [[well-behaved]] function.  Techniques of complex variables can also be used to  directly study Laplace transforms.  As a holomorphic function, the Laplace transform has a power series representation.  This power series expresses a function as a linear superposition of [[moment (mathematics)|moments]] of the function.  This perspective has applications in [[probability theory]].\n\nThe Laplace transform is invertible on a large class of functions. The inverse Laplace transform takes a function of a complex variable ''s'' (often frequency) and yields a function of a real variable ''t'' (often time).  Given a simple mathematical or functional description of an input or output to a [[system]], the Laplace transform provides an alternative functional description that often simplifies the process of analyzing the behavior of the system, or in synthesizing a new system based on a set of specifications.<ref>{{harvnb|Korn|Korn|1967|loc=\u00a78.1}}</ref>  So, for example, Laplace transformation from the [[time domain]] to the [[frequency domain]] transforms differential equations into algebraic equations and [[convolution]] into multiplication.\n\nLaplace wrote extensively about the use of [[Generating function|generating functions]] in ''Essai philosophique sur les probabilit\u00e9s'' (1814) and the integral form of the Laplace transform evolved naturally as a result.<ref>{{Cite book|title=Probability theory : the logic of science|last=Jaynes, E. T. (Edwin T.)|date=2003|publisher=Cambridge University Press|others=Bretthorst, G. Larry|isbn=0511065892|location=Cambridge, UK|oclc=57254076}}</ref>\n\n== History ==\nThe Laplace transform is named after mathematician and astronomer Pierre-Simon Laplace, who used a similar transform in his work on probability theory.<ref>{{citation |url=https://archive.org/details/thorieanalytiqu01laplgoog |title=Th\u00e9orie analytique des Probabilit\u00e9s |location=Paris |date=1814 |edition=2nd |at=chap.I sect.2-20 |chapter=Des Fonctions g\u00e9n\u00e9ratrices |trans-title=Analytical Probability Theory |trans-chapter=On generating functions |language=fr}}</ref> Laplace's use of generating functions was similar to what is now known as the z-transform and he gave little attention to the continuous variable case which was discussed by [[Niels Henrik Abel]].<ref>{{citation |first=Niels H. |last=Abel|authorlink=Niels Henrik Abel |chapter=Sur les fonctions g\u00e9n\u00e9ratrices et leurs d\u00e9terminantes |date=1820 |title=\u0152uvres Compl\u00e8tes |language=fr |publication-date=1839 |volume=II |pages=77\u201388}} [https://books.google.com/books?id=6FtDAQAAMAAJ&pg=RA2-PA67&lpg=RA2-PA67 1881 edition]</ref> The theory was further developed in the 19th and early 20th centuries by [[Mathias Lerch]],<ref>{{citation |first=Mathias |last=Lerch |author-link=Mathias Lerch |title=Sur un point de la th\u00e9orie des fonctions g\u00e9n\u00e9ratrices d'Abel |journal=[[Acta Mathematica]] |volume=27 |date=1903 |pages=339\u2013351 |doi=10.1007/BF02421315 |trans-title=Proof of the inversion formula |language=fr}}</ref> [[Oliver Heaviside]],<ref>{{citation |first=Oliver |last=Heaviside |author-link=Oliver Heaviside |chapter=The solution of definite integrals by differential transformation |title=Electromagnetic Theory |location=London |at=section 526 |volume=III |chapter-url=https://books.google.com/books?id=y9auR0L6ZRcC&pg=PA234&lpg=PA234|isbn=9781605206189 |date=January 2008 }}</ref> and [[Thomas John I'Anson Bromwich|Thomas Bromwich]].<ref>{{citation |first=Thomas J. |last=Bromwich |author-link=Thomas John I'Anson Bromwich |title=Normal coordinates in dynamical systems |journal=[[Proceedings of the London Mathematical Society]] |volume=15 |pages=401\u2013448 |date=1916 |doi=10.1112/plms/s2-15.1.401|url=https://zenodo.org/record/2319588 }}</ref> The current widespread use of the transform (mainly in engineering) came about during and soon after World War II<ref>An influential book was: {{citation |first=Murray F. |last=Gardner |first2=John L. |last2=Barnes |title=Transients in Linear Systems studied by the Laplace Transform |date=1942 |location=New York |publisher=Wiley}}</ref> replacing the earlier Heaviside operational calculus. The advantages of the Laplace transform had been emphasized by [[Gustav Doetsch]]<ref>{{citation |first=Gustav |last=Doetsch |title=Theorie und Anwendung der Laplacesche Transformation |location=Berlin |date=1937 |publisher=Springer |language=de |trans-title=Theory and Application of the Laplace Transform}} translation 1943</ref> to whom the name Laplace Transform is apparently due.  \n\nThe early history of methods having some similarity to Laplace transform is as follows. From 1744, [[Leonhard Euler]] investigated integrals of the form\n: <math> z = \\int X(x) e^{ax}\\, dx \\quad\\text{ and }\\quad z = \\int X(x) x^A \\, dx</math>\nas solutions of [[Laplace transform applied to differential equations|differential equations]] but did not pursue the matter very far.<ref>{{harvnb|Euler|1744}}, {{harvnb|Euler|1753}}, {{harvnb|Euler|1769}}</ref>\n\n[[Joseph Louis Lagrange]] was an admirer of Euler and, in his work on integrating [[probability density function]]s, investigated expressions of the form\n: <math> \\int X(x) e^{- a x } a^x\\, dx,</math>\nwhich some modern historians have interpreted within modern Laplace transform theory.<ref>{{harvnb|Lagrange|1773}}</ref><ref>{{harvnb|Grattan-Guinness| 1997|p=260}}</ref>{{Clarify|date=May 2010}}\n\nThese types of integrals seem first to have attracted Laplace's attention in 1782 where he was following in the spirit of Euler in using the integrals themselves as solutions of equations.<ref>{{harvnb|Grattan-Guinness|1997|p=261}}</ref> However, in 1785, Laplace took the critical step forward when, rather than just looking for a solution in the form of an integral, he started to apply the transforms in the sense that was later to become popular. He used an integral of the form\n: <math> \\int x^s \\varphi (x)\\, dx,</math>\nakin to a [[Mellin transform]], to transform the whole of a [[difference equation]], in order to look for solutions of the transformed equation. He then went on to apply the Laplace transform in the same way and started to derive some of its properties, beginning to appreciate its potential power.<ref>{{harvnb|Grattan-Guinness|1997|pp=261\u2013262}}</ref>\n\nLaplace also recognised that [[Joseph Fourier]]'s method of [[Fourier series]] for solving the [[diffusion equation]] could only apply to a limited region of space because those solutions were periodic. In 1809, Laplace applied his transform to find solutions that diffused indefinitely in space.<ref>{{harvnb|Grattan-Guinness|1997|pp=262&ndash;266}}</ref>\n\n== Formal definition ==\nThe Laplace transform of a [[function (mathematics)|function]] {{math|''f''(''t'')}}, defined for all [[real number]]s {{math|''t'' \u2265 0}}, is the function {{math|''F''(''s'')}}, which is a unilateral transform defined by\n{{Equation box 1\n|indent =\n|title=\n|equation = {{NumBlk||<math>F(s) =\\int_0^\\infty f(t)e^{-st} \\, dt</math>|{{EquationRef|Eq.1}}}}\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nwhere ''s'' is a [[complex number]] frequency parameter\n: <math>s = \\sigma + i \\omega</math>, with real numbers {{math|''\u03c3''}} and {{math|''\u03c9''}}.\n\nAn alternate notation for the Laplace transform is <math>\\mathcal{L}\\{f\\}</math> instead of {{math|''F''}}.\n\nThe meaning of the integral depends on types of functions of interest.  A necessary condition for existence of the integral is that {{math|''f''}} must be [[locally integrable]] on {{closed-open|0, \u221e}}.  For locally integrable functions that decay at infinity or are of [[exponential type]], the integral can be understood to be a (proper) [[Lebesgue integral]]. However, for many applications it is necessary to regard it as a [[conditionally convergent]] [[improper integral]] at {{math|\u221e}}.  Still more generally, the integral can be understood in a [[distribution (mathematics)|weak sense]], and this is dealt with below.\n\nOne can define the Laplace transform of a finite [[Borel measure]] {{math|''\u03bc''}} by the Lebesgue integral<ref>{{harvnb|Feller|1971|loc=\u00a7XIII.1}}</ref>\n: <math>\\mathcal{L}\\{\\mu\\}(s) = \\int_{[0,\\infty)} e^{-st}\\, d\\mu(t).</math>\n\nAn important special case is where {{math|''\u03bc''}} is a [[probability measure]], for example, the [[Dirac delta function]]. In [[operational calculus]], the Laplace transform of a measure is often treated as though the measure came from a probability density function {{math|''f''}}.  In that case, to avoid potential confusion, one often writes\n: <math>\\mathcal{L}\\{f\\}(s) = \\int_{0^-}^\\infty f(t)e^{-st} \\, dt,</math>\nwhere the lower limit of {{math|0<sup>\u2212</sup>}} is shorthand notation for\n: <math>\\lim_{\\varepsilon\\rightarrow 0^+}\\int_{-\\varepsilon}^\\infty.</math>\n\nThis limit emphasizes that any point mass located at {{math|0}} is entirely captured by the Laplace transform. Although with the Lebesgue integral, it is not necessary to take such a limit, it does appear more naturally in connection with the [[Laplace\u2013Stieltjes transform]].\n\n=== Bilateral Laplace transform ===\n{{Main article|Two-sided Laplace transform}}\n\nWhen one says \"the Laplace transform\" without qualification, the unilateral or one-sided transform is normally intended. The Laplace transform can be alternatively defined as the ''bilateral Laplace transform'' or [[two-sided Laplace transform]] by extending the limits of integration to be the entire real axis.  If that is done the common unilateral transform simply becomes a special case of the bilateral transform where the definition of the function being transformed is multiplied by the [[Heaviside step function]].\nThe bilateral Laplace transform is defined as follows:\n{{math|''F''(''s'')}}, which is a bilateral transform defined by\n{{Equation box 1\n|indent =\n|title=\n|equation = {{NumBlk||<math>F(s) = \\int_{-\\infty}^\\infty e^{-st} f(t)\\, dt</math>|{{EquationRef|Eq.2}}}}\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nAn alternate notation for the bilateral Laplace transform is <math>\\mathcal{B}\\{f\\}</math> instead of <math>F</math>.\n\n=== Inverse Laplace transform ===\n{{Main article|Inverse Laplace transform}}\nTwo integrable functions have the same Laplace transform only if they differ on a set of [[Lebesgue measure]] zero. This means that, on the range of the transform, there is an inverse transform. In fact, besides integrable functions, the Laplace transform is a [[one-to-one function|one-to-one]] mapping from one function space into another in many other function spaces as well, although there is usually no easy characterization of the range. Typical function spaces in which this is true include the spaces of bounded continuous functions, the space [[Lp space|{{math|''L''<sup>&infin;</sup>(0, &infin;)}}]], or more generally [[Distribution (mathematics)#Tempered distributions and Fourier transform|tempered distributions]] on {{open-open|0, &infin;}}.  The Laplace transform is also defined and injective for suitable spaces of tempered distributions.\n\nIn these cases, the image of the Laplace transform lives in a space of [[analytic function]]s in the [[#Region of convergence|region of convergence]].  The [[inverse Laplace transform]] is given by the following complex integral, which is known by various names (the '''Bromwich integral''', the '''Fourier\u2013Mellin integral''', and '''Mellin's inverse formula'''):\n{{Equation box 1\n|indent =\n|title=\n|equation = {{NumBlk||<math>f(t) = \\mathcal{L}^{-1}\\{F\\}(t) = \\frac{1}{2 \\pi i} \\lim_{T\\to\\infty}\\oint_{\\gamma - i T}^{\\gamma + i T} e^{st} F(s)\\, ds</math>|{{EquationRef|Eq.3}}}}\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nwhere {{math|''\u03b3''}} is a real number so that the contour path of integration is in the region of convergence of {{math|''F''(''s'')}}. An alternative formula for the inverse Laplace transform is given by [[Post's inversion formula]]. The limit here is interpreted in the [[weak-* topology#Weak-* topology|weak-* topology]].\n\nIn practice, it is typically more convenient to decompose a Laplace transform into known transforms of functions obtained from a table, and construct the inverse by inspection.\n\n=== Probability theory ===\nIn [[probability theory|pure]] and [[applied probability]], the Laplace transform is defined as an [[expected value]]. If {{math|''X''}} is a [[random variable]] with probability density function {{math|''f''}}, then the Laplace transform of {{math|''f''}} is given by the expectation\n: <math>\\mathcal{L}\\{f\\}(s) = \\operatorname{E}\\! \\left[e^{-sX} \\right]\\! .</math>\n\nBy [[abuse of notation|convention]], this is referred to as the Laplace transform of the random variable {{math|''X''}} itself. Replacing {{math|''s''}} by {{math|\u2212''t''}} gives the [[moment generating function]] of {{math|''X''}}. The Laplace transform has applications throughout probability theory, including [[first passage time]]s of [[stochastic processes]] such as [[Markov chain]]s, and [[renewal theory]].\n\nOf particular use is the ability to recover the [[cumulative distribution function]] of a continuous random variable {{math|''X''}} by means of the Laplace transform as follows<ref>The cumulative distribution function is the integral of the probability density function.</ref>\n: <math>F_X(x) = \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s}\\operatorname{E}\\left[e^{-sX}\\right]\\right\\}\\! (x) = \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s}\\mathcal{L}\\{f\\}(s)\\right\\}\\! (x).</math>\n\n== Region of convergence ==\nIf {{math|''f''}} is a locally integrable function (or more generally a Borel measure locally of bounded variation), then the Laplace transform {{math|''F''(''s'')}} of {{math|''f''}} converges provided that the limit\n: <math>\\lim_{R\\to\\infty}\\int_0^R f(t)e^{-st}\\,dt</math>\nexists.\n\nThe Laplace transform converges absolutely if the integral\n: <math>\\int_0^\\infty \\left|f(t)e^{-st}\\right|\\,dt</math>\nexists (as a proper Lebesgue integral).  The Laplace transform is usually understood as conditionally convergent, meaning that it converges in the former instead of the latter sense.\n\nThe set of values for which {{math|''F''(''s'')}} converges absolutely is either of the form {{math|Re(''s'') > ''a''}} or else {{math|Re(''s'') \u2265 ''a''}}, where {{math|''a''}} is an [[extended real number|extended real constant]], {{math|\u2212\u221e \u2264 ''a'' \u2264 \u221e}}.  (This follows from the [[dominated convergence theorem]].) The constant {{math|''a''}} is known as the abscissa of absolute convergence, and depends on the growth behavior of {{math|''f''(''t'')}}.<ref>{{harvnb|Widder|1941|loc=Chapter II, \u00a71}}</ref> Analogously, the two-sided transform converges absolutely in a strip of the form  {{math|''a'' < Re(''s'') < ''b''}}, and possibly including the lines {{math|1=Re(''s'') = ''a''}} or {{math|1=Re(''s'') = ''b''}}.<ref>{{harvnb|Widder|1941|loc=Chapter VI, \u00a72}}</ref>  The subset of values of {{math|''s''}} for which the Laplace transform converges absolutely is called the region of absolute convergence or the domain of absolute convergence.  In the two-sided case, it is sometimes called the strip of absolute convergence. The Laplace transform is analytic in the region of absolute convergence: this is a consequence of [[Fubini's theorem]] and [[Morera's theorem]]. \n\nSimilarly, the set of values for which {{math|''F''(''s'')}} converges (conditionally or absolutely) is known as the region of conditional convergence, or simply the '''region of convergence''' (ROC).  If the Laplace transform converges (conditionally) at {{math|1=''s'' = ''s''<sub>0</sub>}}, then it automatically converges for all {{math|''s''}} with {{math|Re(''s'') > Re(''s''<sub>0</sub>)}}.  Therefore, the region of convergence is a half-plane of the form {{math|Re(''s'') > ''a''}}, possibly including some points of the boundary line {{math|1=Re(''s'') = ''a''}}.\n\nIn the region of convergence {{math|Re(''s'') > Re(''s''<sub>0</sub>)}}, the Laplace transform of {{math|''f''}} can be expressed by [[integration by parts|integrating by parts]] as the integral\n: <math>F(s) = (s-s_0)\\int_0^\\infty e^{-(s-s_0)t}\\beta(t)\\,dt,\\quad \\beta(u) = \\int_0^u e^{-s_0t}f(t)\\,dt.</math>\n\nThat is, in the region of convergence {{math|''F''(''s'')}} can effectively be expressed as the absolutely convergent Laplace transform of some other function.  In particular, it is analytic.\n\nThere are several [[Paley\u2013Wiener theorem]]s concerning the relationship between the decay properties of {{math|''f''}} and the properties of the Laplace transform within the region of convergence.\n\nIn engineering applications, a function corresponding to a [[LTI system|linear time-invariant (LTI) system]] is ''stable'' if every bounded input produces a bounded output.  This is equivalent to the absolute convergence of the Laplace transform of the impulse response function in the region {{math|Re(''s'') \u2265 0}}.  As a result, LTI systems are stable provided the poles of the Laplace transform of the impulse response function have negative real part.\n\nThis ROC is used in knowing about the causality and stability of a system.\n\n== Properties and theorems ==\nThe Laplace transform has a number of properties that make it useful for analyzing linear [[dynamical system]]s. The most significant advantage is that [[derivative|differentiation]] becomes multiplication, and [[integral|integration]] becomes division, by  {{math|''s''}} (similarly to [[logarithm]]s changing multiplication of numbers to addition of their logarithms).\n\nBecause of this property, the Laplace variable {{math|''s''}} is also known as ''operator variable'' in the {{math|''L''}} domain: either ''derivative operator'' or (for {{math|''s''<sup>\u22121</sup>)}} ''integration operator''. The transform turns [[integral equation]]s and [[differential equation]]s to [[polynomial equation]]s, which are much easier to solve.  Once solved, use of the inverse Laplace transform reverts to the original domain.\n\nGiven the functions {{math|''f''(''t'')}} and {{math|''g''(''t'')}}, and their respective Laplace transforms {{math|''F''(''s'')}} and {{math|''G''(''s'')}},\n: <math>\\begin{align}\nf(t) &= \\mathcal{L}^{-1}\\{F(s)\\},\\\\\ng(t) &= \\mathcal{L}^{-1}\\{G(s)\\},\n\\end{align}</math>\n\nThe following '''table''' is a list of properties of unilateral Laplace transform:<ref>{{harvnb|Korn|Korn|1967|pp=226&ndash;227}}</ref>\n\n{| class=\"wikitable\" id=\"291017_tableid\"\n|+ Properties of the unilateral Laplace transform\n|-\n !\n ! Time domain\n ! {{math|''s''}} domain\n ! Comment\n|-\n ! [[Linearity]]\n | <math> a f(t) + b g(t) \\ </math>\n | <math> a F(s) + b G(s) \\ </math>\n | Can be proved using basic rules of integration.\n|-\n ! Frequency-domain derivative\n | <math> t f(t) \\ </math>\n | <math> -F'(s) \\ </math>\n | {{math|''F''\u2032}} is the first derivative of {{math|''F''}} with respect to {{math|''s''}}.\n|-\n ! Frequency-domain general derivative\n | <math> t^{n} f(t) \\ </math>\n | <math> (-1)^{n} F^{(n)}(s) \\ </math>\n | More general form, {{math|''n''}}th derivative of {{math|''F''(''s'')}}.\n|-\n ! [[Derivative]]\n | <math> f'(t) \\ </math>\n | <math> s F(s) - f(0^{+}) \\ </math>\n | {{math|''f''}} is assumed to be a [[differentiable function]], and its derivative is assumed to be of exponential type.  This can then be obtained by integration by parts\n|-\n ! Second derivative\n | <math> f''(t) \\ </math>\n | <math> s^2 F(s) - s f(0^{+}) - f'(0^{+}) \\ </math>\n | {{math|''f''}} is assumed twice differentiable and the second derivative to be of exponential type. Follows by applying the Differentiation property to {{math|''f''\u2032(''t'')}}.\n|-\n ! General derivative\n | <math> f^{(n)}(t)  \\ </math>\n | <math> s^n F(s) - \\sum_{k=1}^{n} s^{n-k} f^{(k-1)}(0^{+}) \\ </math>\n | {{math|''f''}} is assumed to be {{math|''n''}}-times differentiable, with {{math|''n''}}th derivative of exponential type.  Follows by [[mathematical induction]].\n|-\n ! [[Frequency|Frequency-domain integration]]\n | <math> \\frac{1}{t}f(t)  \\ </math>\n | <math> \\int_s^\\infty F(\\sigma)\\, d\\sigma \\ </math>\n | This is deduced using the nature of frequency differentiation and conditional convergence.\n|-\n ! Time-domain [[integral|integration]]\n | <math> \\int_0^t f(\\tau)\\, d\\tau  =  (u * f)(t)</math>\n | <math> {1 \\over s} F(s) </math>\n | {{math|''u''(''t'')}} is the Heaviside step function and {{math|(''u''&nbsp;\u2217&nbsp;''f'')(''t'')}} is the [[convolution]] of {{math|''u''(''t'')}} and {{math|''f''(''t'')}}.\n|-\n ! Frequency shifting\n | <math> e^{at} f(t)  \\ </math>\n | <math> F(s - a) \\ </math>\n |\n|-\n ! Time shifting\n | <math> f(t - a) u(t - a) \\ </math>\n | <math> e^{-as} F(s) \\ </math>\n | {{math|''u''(''t'')}} is the Heaviside step function\n|-\n ! Time scaling\n | <math>f(at)</math>\n | <math> \\frac{1}{a} F \\left ( {s \\over a} \\right )</math>\n | <math> a > 0 \\ </math>\n|-\n ! [[Multiplication]]\n | <math>f(t)g(t)</math>\n | <math> \\frac{1}{2\\pi i}\\lim_{T\\to\\infty}\\int_{c - iT}^{c + iT}F(\\sigma)G(s - \\sigma)\\,d\\sigma \\ </math>\n | The integration is done along the vertical line {{nowrap|1=Re(''\u03c3'') = ''c''}} that lies entirely within the region of convergence of {{math|''F''}}.<ref>{{harvnb|Bracewell|2000|loc=Table 14.1, p. 385}}</ref>\n|-\n ! [[Convolution]]\n | <math> (f * g)(t) = \\int_{0}^{t} f(\\tau)g(t - \\tau)\\,d\\tau</math>\n | <math> F(s) \\cdot G(s) \\ </math>\n | \n|-\n ! [[Complex conjugation]]\n | <math> f^*(t) </math>\n | <math> F^*(s^*) </math>\n |\n|-\n ! [[Cross-correlation]]\n | <math> f(t)\\star g(t) </math>\n | <math> F^*(-s^*)\\cdot G(s) </math>\n |\n|-\n ! [[Periodic function]]\n | <math>f(t)</math>\n | <math>{1 \\over 1 - e^{-Ts}} \\int_0^T e^{-st} f(t)\\,dt </math>\n | {{math|''f''(''t'')}} is a periodic function of period {{math|''T''}} so that {{math|1=''f''(''t'') = ''f''(''t'' + ''T'')}}, for all {{math|''t'' \u2265 0}}. This is the result of the time shifting property and the [[geometric series]].\n|}\n\n* '''[[Initial value theorem]]''':\n: <math>f(0^+)=\\lim_{s\\to \\infty}{sF(s)}.</math>\n* '''[[Final value theorem]]''':\n: <math>f(\\infty)=\\lim_{s\\to 0}{sF(s)}</math>, if all [[Pole (complex analysis)|poles]] of ''sF''(''s'') are in the left half-plane.\n: The final value theorem is useful because it gives the long-term behaviour without having to perform [[partial fraction]] decompositions or other difficult algebra. If {{math|''F''(''s'')}} has a pole in the right-hand plane or poles on the imaginary axis (e.g., if <math>f(t) = e^t</math> or <math>f(t) = \\sin(t)</math>), the behaviour of this formula is undefined.\n\n=== Relation to power series ===\nThe Laplace transform can be viewed as a [[continuous function|continuous]] analogue of a [[power series]].<ref>{{cite web |last1=Mattuck |first1=Arthur |title=Where the Laplace Transform comes from |url=https://www.youtube.com/watch?v=zvbdoSeGAgI}}</ref> If  {{math|''a''(''n'')}} is a discrete function of a positive integer {{math|''n''}}, then the power series associated to  {{math|''a''(''n'')}} is the series\n:<math>\\sum_{n=0}^{\\infty} a(n) x^n</math>\nwhere  {{math|''x''}} is a real variable (see [[Z transform]]). Replacing summation over {{math|''n''}} with integration over  {{math|''t''}}, a continuous version of the power series becomes\n:<math>\\int_{0}^{\\infty} f(t) x^t\\, dt</math>\nwhere the discrete function {{math|''a''(''n'')}} is replaced by the continuous one {{math|''f''(''t'')}}. \n\nChanging the base of the power from {{math|''x''}} to {{math|''e''}} gives\n:<math>\\int_{0}^{\\infty} f(t) \\left(e^{\\ln{x}}\\right)^t\\, dt</math>\n\nFor this to converge for, say, all bounded functions {{math|''f''}}, it is necessary to require that {{math|ln ''x'' < 0}}. Making the substitution {{math|1=&minus;''s'' = ln ''x''}} gives just the Laplace transform:\n:<math>\\int_{0}^{\\infty} f(t) e^{-st}\\, dt</math>\n\nIn other words, the Laplace transform is a continuous analog of a power series in which the discrete parameter {{math|''n''}} is replaced by the continuous parameter {{math|''t''}}, and {{math|''x''}} is replaced by {{math|''e''<sup>&minus;''s''</sup>}}.\n\n=== Relation to moments ===\n{{main article|Moment generating function}}\nThe quantities\n:<math>\\mu_n = \\int_0^\\infty t^nf(t)\\, dt</math>\n\nare the ''moments'' of the function {{math|''f''}}.  If the first {{math|''n''}} moments of {{math|''f''}} converge absolutely, then by repeated [[differentiation under the integral]], \n:<math>(-1)^n(\\mathcal L f)^{(n)}(0) = \\mu_n .</math>\nThis is of special significance in probability theory, where the moments of a random variable {{math|''X''}} are given by the expectation values <math>\\mu_n=\\operatorname{E}[X^n]</math>.  Then, the relation holds\n:<math>\\mu_n = (-1)^n\\frac{d^n}{ds^n}\\operatorname{E}\\left[e^{-sX}\\right](0).</math>\n\n=== Proof of the Laplace transform of a function's derivative ===\nIt is often convenient to use the differentiation property of the Laplace transform to find the transform of a function's derivative.  This can be derived from the basic expression for a Laplace transform as follows:\n\n: <math>\\begin{align}\n  \\mathcal{L} \\left\\{f(t)\\right\\} &= \\int_{0^-}^\\infty e^{-st} f(t)\\, dt \\\\[6pt]\n                                  &= \\left[\\frac{f(t)e^{-st}}{-s} \\right]_{0^-}^\\infty -\n                                       \\int_{0^-}^\\infty \\frac{e^{-st}}{-s} f'(t) \\, dt\\quad \\text{(by parts)} \\\\[6pt]\n                                  &= \\left[-\\frac{f(0^+)}{-s}\\right] + \\frac 1 s \\mathcal{L} \\left\\{f'(t)\\right\\},\n\\end{align}</math>\n\nyielding\n\n: <math>\\mathcal{L} \\{ f'(t) \\} = s\\cdot\\mathcal{L} \\{ f(t) \\}-f(0^+), </math>\n\nand in the bilateral case,\n\n: <math> \\mathcal{L} \\{ f'(t) \\} = s \\int_{-\\infty}^\\infty e^{-st} f(t)\\,dt  = s \\cdot \\mathcal{L} \\{ f(t) \\}. </math>\n\nThe general result\n\n: <math>\\mathcal{L} \\left\\{ f^{(n)}(t) \\right\\} = s^n \\cdot \\mathcal{L} \\{ f(t) \\} - s^{n - 1} f(0^+) - \\cdots - f^{(n - 1)}(0^+),</math>\n\nwhere <math>f^{(n)}</math> denotes the {{math|''n''}}<sup>th</sup> derivative of {{math|''f''}}, can then be established with an inductive argument.\n\n=== Evaluating integrals over the positive real axis ===\nA useful property of the Laplace transform is the following:\n\n: <math>\\int_0^\\infty f(x)g(x)\\,dx = \\int_0^\\infty(\\mathcal{L} f)(s)\\cdot(\\mathcal{L}^{-1}g)(s)\\,ds </math>\n\nunder suitable assumptions on the behaviour of <math>f,g</math> in a right neighbourhood of <math>0</math> and on the decay rate of <math>f,g</math> in a left neighbourhood of <math>\\infty</math>. The above formula is a variation of integration by parts, with the operators \n<math>\\frac{d}{dx}</math> and <math>\\int \\,dx</math> being replaced by <math>\\mathcal{L}</math> and <math>\\mathcal{L}^{-1}</math>. Let us prove the equivalent formulation:\n\n: <math>\\int_0^\\infty(\\mathcal{L} f)(x)g(x)\\,dx = \\int_0^\\infty f(s)(\\mathcal{L}g)(s)\\,ds. </math>\n\nBy plugging in <math>(\\mathcal{L}f)(x)=\\int_0^\\infty f(s)e^{-sx}\\,ds</math> the left-hand side turns into:\n\n: <math>\\int_0^\\infty\\int_0^\\infty f(s)g(x) e^{-sx}\\,ds\\,dx, </math>\n\nbut assuming Fubini's theorem holds, by reversing the order of integration we get the wanted right-hand side.\n\n=== Relationship to other transforms ===\n\n==== Laplace\u2013Stieltjes transform ====\nThe (unilateral) Laplace\u2013Stieltjes transform of a function {{math|''g'' : '''R''' \u2192 '''R'''}} is defined by the [[Lebesgue\u2013Stieltjes integral]]\n\n: <math>\\{\\mathcal{L}^*g\\}(s) = \\int_0^\\infty e^{-st} \\, dg(t).</math>\n\nThe function {{math|''g''}} is assumed to be of [[bounded variation]].  If {{math|''g''}} is the [[antiderivative]] of {{math|''f''}}:\n\n: <math>g(x) = \\int_0^x f(t)\\,dt</math>\n\nthen the Laplace\u2013Stieltjes transform of {{math|''g''}} and the Laplace transform of {{math|''f''}} coincide.  In general, the Laplace\u2013Stieltjes transform is the Laplace transform of the [[Stieltjes measure]] associated to {{math|''g''}}.  So in practice, the only distinction between the two transforms is that the Laplace transform is thought of as operating on the density function of the measure, whereas the Laplace\u2013Stieltjes transform is thought of as operating on its [[cumulative distribution function]].<ref>{{harvnb|Feller|1971|p=432}}</ref>\n\n==== Fourier transform ====\n{{Main|Fourier transform}}\nThe continuous Fourier transform is equivalent to evaluating the bilateral Laplace transform with imaginary argument {{math|1=''s'' = ''i\u03c9''}} or {{math|1=''s'' = 2''\u03c0fi''}}<ref>{{harvnb|Takacs|1953|p=93}}</ref> when the condition explained below is fulfilled, \n:<math>\\begin{align}\n  \\widehat{f}(\\omega) &= \\mathcal{F}\\{f(t)\\} \\\\[4pt]\n                  &= \\mathcal{L}\\{f(t)\\}|_{s = i\\omega}  =  F(s)|_{s = i \\omega} \\\\[4pt]\n                  &= \\int_{-\\infty}^\\infty e^{-i \\omega t} f(t)\\,dt~.\n\\end{align}</math>\n\nThis definition of the Fourier transform requires a prefactor of {{math|1/(2''\u03c0'')}} on the reverse Fourier transform. This relationship between the Laplace and Fourier transforms is often used to determine the [[frequency spectrum]] of a [[signal (information theory)|signal]] or dynamical system.\n\nThe above relation is valid as stated if and only if the region of convergence (ROC) of  {{math|''F''(''s'')}} contains the imaginary axis,  {{math|1=''\u03c3'' = 0}}.\n\nFor example, the function {{math|1=''f''(''t'') = cos(''\u03c9''<sub>0</sub>''t'')}} has a Laplace transform  {{math|1=''F''(''s'') =  ''s''/(''s''<sup>2</sup> + ''\u03c9''<sub>0</sub><sup>2</sup>)}} whose ROC is {{math|Re(''s'') > 0}}. As {{math|1=''s'' = ''i\u03c9''}} is a pole of  {{math|''F''(''s'')}}, substituting  {{math|1=''s'' = ''i\u03c9''}} in {{math|''F''(''s'')}} does not yield the Fourier transform of  {{math|''f''(''t'')''u''(''t'')}}, which is proportional to the [[Dirac delta-function]] {{math|''\u03b4''(''\u03c9'' \u2212 ''\u03c9''<sub>0</sub>)}}.\n\nHowever, a relation of the form\n: <math>\\lim_{\\sigma\\to 0^+} F(\\sigma+i\\omega) = \\widehat{f}(\\omega)</math>\nholds under much weaker conditions.  For instance, this holds for the above example provided that the limit is understood as a [[weak limit]] of measures (see [[vague topology]]).  General conditions relating the limit of the Laplace transform of a function on the boundary to the Fourier transform take the form of [[Paley\u2013Wiener theorem]]s.\n\n==== Mellin transform ====\n{{Main|Mellin transform}}\nThe Mellin transform and its inverse are related to the two-sided Laplace transform by a simple change of variables.\n\nIf in the Mellin transform\n: <math>G(s) = \\mathcal{M}\\{g(\\theta)\\} = \\int_0^\\infty \\theta^s g(\\theta) \\, \\frac{d\\theta} \\theta </math>\nwe set {{math|1=''\u03b8'' = ''e''<sup>\u2212''t''</sup>}} we get a two-sided Laplace transform.\n\n==== Z-transform ====\n{{Main|Z-transform}}\nThe unilateral or one-sided Z-transform is simply the Laplace transform of an ideally sampled signal with the substitution of\n: <math> z \\stackrel{\\mathrm{def}}{{}={}} e^{sT} ,</math>\nwhere {{math|1=''T'' = 1/''f<sub>s</sub>''}} is the [[Sampling theorem|sampling]] period (in units of time e.g., seconds) and  {{math|''f<sub>s</sub>''}} is the [[sampling rate]] (in [[sample (signal)|samples per second]] or [[hertz]]).\n\nLet\n: <math> \\Delta_T(t) \\ \\stackrel{\\mathrm{def}}{=}\\  \\sum_{n=0}^{\\infty}  \\delta(t - n T) </math>\nbe a sampling impulse train (also called a [[Dirac comb]]) and\n:<math>\\begin{align}\n  x_q(t) \\  &\\stackrel{\\mathrm{def}}{=}\\  x(t) \\Delta_T(t) = x(t) \\sum_{n=0}^{\\infty}  \\delta(t - n T) \\\\\n            &= \\sum_{n=0}^{\\infty} x(n T) \\delta(t - n T) = \\sum_{n=0}^{\\infty} x[n] \\delta(t - n T)\n\\end{align}</math>\nbe the sampled representation of the continuous-time {{math|''x''(''t'')}}\n: <math> x[n] \\stackrel{\\mathrm{def}}{{}={}}  x(nT) ~.</math>\n\nThe Laplace transform of the sampled signal {{math|''x''<sub>''q''</sub>(''t'') }} is\n: <math>\\begin{align}\n  X_q(s) &= \\int_{0^-}^\\infty x_q(t) e^{-s t} \\,dt \\\\\n         &= \\int_{0^-}^\\infty \\sum_{n=0}^\\infty x[n] \\delta(t - n T) e^{-s t} \\, dt \\\\\n         &= \\sum_{n=0}^\\infty x[n] \\int_{0^-}^\\infty \\delta(t - n T) e^{-s t} \\, dt \\\\\n         &= \\sum_{n=0}^\\infty x[n] e^{-n s T}~.\n\\end{align}</math>\n\nThis is the precise definition of the unilateral Z-transform of the discrete function {{math|''x''[''n'']}}\n\n: <math> X(z) = \\sum_{n=0}^{\\infty} x[n] z^{-n} </math>\nwith the substitution of {{math|''z'' \u2192 e<sup>''sT''</sup>}}.\n\nComparing the last two equations, we find the relationship between the unilateral Z-transform and the Laplace transform of the sampled signal,\n: <math>X_q(s) =  X(z) \\Big|_{z=e^{sT}}.</math>\n\nThe similarity between the {{math|''Z''}} and Laplace transforms is expanded upon in the theory of [[time scale calculus]].\n\n==== Borel transform ====\nThe integral form of the [[Borel summation|Borel transform]]\n\n: <math>F(s) = \\int_0^\\infty f(z)e^{-sz}\\, dz</math>\n\nis a special case of the Laplace transform for {{math|''f''}} an [[entire function]] of exponential type, meaning that\n\n: <math>|f(z)|\\le Ae^{B|z|}</math>\n\nfor some constants {{math|''A''}} and {{math|''B''}}.  The generalized Borel transform allows a different weighting function to be used, rather than the exponential function, to transform functions not of exponential type. [[Nachbin's theorem]] gives necessary and sufficient conditions for the Borel transform to be well defined.\n\n==== Fundamental relationships ====\nSince an ordinary Laplace transform can be written as a special case of a two-sided transform, and since the two-sided transform can be written as the sum of two one-sided transforms, the theory of the Laplace-, Fourier-, Mellin-, and Z-transforms are at bottom the same subject. However, a different point of view and different characteristic problems are associated with each of these four major integral transforms.\n\n== Table of selected Laplace transforms ==\n{{main article|List of Laplace transforms}}\n\nThe following table provides Laplace transforms for many common functions of a single variable.<ref>{{Citation |edition=3rd |page=455 |first1=K. F. |last1=Riley |first2=M. P. |last2=Hobson |first3=S. J. |last3=Bence |title=Mathematical methods for physics and engineering |publisher=Cambridge University Press |year=2010 |isbn=978-0-521-86153-3}}</ref><ref>{{Citation |first1=J. J. |last1=Distefano |first2=A. R. |last2=Stubberud |first3=I. J. |last3=Williams |page=78 |title=Feedback systems and control |edition=2nd |publisher=McGraw-Hill |series=Schaum's outlines |year=1995 |isbn=978-0-07-017052-0}}</ref> For definitions and explanations, see the ''Explanatory Notes'' at the end of the table.\n\nBecause the Laplace transform is a linear operator,\n\n* The Laplace transform of a sum is the sum of Laplace transforms of each term.\n\n:: <math>\\mathcal{L}\\{f(t) + g(t)\\}  = \\mathcal{L}\\{f(t)\\} + \\mathcal{L}\\{ g(t)\\}  </math>\n\n* The Laplace transform of a multiple of a function is that multiple times the Laplace transformation of that function.\n\n:: <math>\\mathcal{L}\\{a f(t)\\}  = a \\mathcal{L}\\{ f(t)\\}</math>\n\nUsing this linearity, and various [[List of trigonometric identities|trigonometric]], [[Hyperbolic function|hyperbolic]], and complex number (etc.) properties and/or identities, some Laplace transforms can be obtained from others more quickly than by using the definition directly.\n\nThe unilateral Laplace transform takes as input a function whose time domain is the [[non-negative]] reals, which is why all of the time domain functions in the table below are multiples of the Heaviside step function, {{math|''u''(''t'')}}.\n\nThe entries of the table that involve a time delay {{math|''\u03c4''}} are required to be [[causal system|causal]] (meaning that {{math|''\u03c4'' > 0}}).  A causal system is a system where the [[impulse response]] {{math|''h''(''t'')}} is zero for all time {{mvar|t}} prior to {{math|1=''t'' = 0}}. In general, the region of convergence for causal systems is not the same as that of [[anticausal system]]s.\n\n{| class=\"wikitable\"\n|-\n! Function\n! Time domain <br> <math>f(t) = \\mathcal{L}^{-1}\\{F(s)\\}</math> \n! Laplace {{math|s}}-domain <br> <math>F(s) = \\mathcal{L}\\{f(t)\\}</math> \n! Region of convergence \n! Reference\n\n|- style=\"text-align:center;\"\n| unit impulse\n|| <math> \\delta(t) \\ </math> \n|| <math> 1  </math> \n|| all {{math|''s''}}\n|| inspection\n\n|- style=\"text-align:center;\"\n| delayed impulse \n|| <math> \\delta(t - \\tau) \\ </math> \n|| <math> e^{-\\tau s} \\ </math> \n|| \n|| time shift of<br>unit impulse\n\n|- style=\"text-align:center;\"\n| unit step\n|| <math> u(t) \\ </math> \n|| <math> { 1 \\over s } </math> \n|| {{math|Re(''s'') > 0}}\n|| integrate unit impulse\n\n|- style=\"text-align:center;\"\n| delayed unit step \n|| <math> u(t - \\tau) \\ </math> \n|| <math> \\frac 1 s e^{-\\tau s} </math> \n|| {{math|Re(''s'') > 0}} \n|| time shift of<br>unit step\n\n|- style=\"text-align:center;\"\n| [[ramp function|ramp]] \n|| <math> t \\cdot u(t)\\ </math> \n|| <math>\\frac 1 {s^2}</math> \n|| {{math|Re(''s'') > 0}}\n|| integrate unit<br>impulse twice\n\n|- style=\"text-align:center;\"\n| {{math|''n''}}th power <br /> (for integer {{math|''n''}}) \n|| <math> t^n \\cdot u(t) </math> \n|| <math> { n! \\over s^{n + 1} } </math> \n|| {{math|Re(''s'') > 0}}   <br /> ({{math|''n'' > \u22121}})\n|| Integrate unit<br>impulse {{math|''n''}} times\n\n|- style=\"text-align:center;\"\n| {{math|''q''}}th power <br /> (for complex {{math|''q''}}) \n|| <math> t^q \\cdot u(t) </math> \n|| <math> { \\Gamma(q + 1) \\over s^{q + 1} } </math> \n|| {{math|Re(''s'') > 0}} <br /> {{math|Re(''q'') > \u22121}} \n||<ref>{{citation |title=Mathematical Handbook of Formulas and Tables |edition=3rd |first1=S. |last1=Lipschutz |first2=M. R. |last2=Spiegel |first3=J. |last3=Liu |series=Schaum's Outline Series |publisher=McGraw-Hill |page=183 |year=2009 |isbn=978-0-07-154855-7}} \u2013 provides the case for real {{math|''q''}}.</ref><ref>http://mathworld.wolfram.com/LaplaceTransform.html \u2013 Wolfram Mathword provides case for complex {{math|''q''}}</ref>\n\n|- style=\"text-align:center;\"\n| {{math|''n''}}th root \n|| <math> \\sqrt[n]{t} \\cdot u(t) </math> \n|| <math> { 1 \\over s^{\\frac 1 n + 1} } \\Gamma\\left(\\frac 1 n + 1\\right) </math> \n|| {{math|Re(''s'') > 0}} \n|| Set {{math|1=''q'' = 1/''n''}} above.\n\n|- style=\"text-align:center;\"\n| {{math|''n''}}th power with frequency shift \n|| <math>t^{n} e^{-\\alpha t} \\cdot u(t) </math> \n|| <math>\\frac{n!}{(s+\\alpha)^{n+1}}</math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}}\n|| Integrate unit step,<br>apply frequency shift\n\n|- style=\"text-align:center;\"\n| delayed {{math|''n''}}th power <br /> with frequency shift \n|| <math>(t-\\tau)^n e^{-\\alpha (t-\\tau)} \\cdot u(t-\\tau) </math> \n|| <math> \\frac{n! \\cdot e^{-\\tau s}}{(s+\\alpha)^{n+1}} </math>\n|| {{math|Re(''s'') > \u2212''\u03b1''}} \n|| Integrate unit step,<br>apply frequency shift,<br>apply time shift\n\n|- style=\"text-align:center;\"\n| [[exponential decay]] \n|| <math> e^{-\\alpha t} \\cdot u(t)   </math> \n|| <math> { 1 \\over s+\\alpha } </math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}}\n|| Frequency shift of<br>unit step\n\n|- style=\"text-align:center;\"\n| [[Two-sided Laplace transform|two-sided]] exponential decay <br>(only for bilateral transform)\n|| <math> e^{-\\alpha|t|}  \\ </math> \n|| <math> { 2\\alpha \\over \\alpha^2 - s^2 } </math> \n|| {{math|\u2212''\u03b1'' < Re(''s'') < ''\u03b1''}} \n|| Frequency shift of<br>unit step\n\n|- style=\"text-align:center;\"\n| exponential approach \n|| <math>( 1-e^{-\\alpha t})  \\cdot u(t)  \\ </math> \n|| <math>\\frac{\\alpha}{s(s+\\alpha)} </math> \n|| {{math|Re(''s'') > 0}}\n|| Unit step minus<br>exponential decay\n\n|- style=\"text-align:center;\"\n| [[sine]] \n|| <math> \\sin(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { \\omega \\over s^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > 0}}\n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| [[cosine]] \n|| <math> \\cos(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { s \\over s^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > 0}}\n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| [[hyperbolic sine]] \n|| <math> \\sinh(\\alpha t) \\cdot u(t) \\ </math> \n|| <math> { \\alpha \\over s^2 - \\alpha^2 } </math> \n|| {{math|Re(''s'') > {{abs|''\u03b1''}}}} \n|| {{Harvnb|Williams|1973|p=88}}\n\n|- style=\"text-align:center;\"\n| [[hyperbolic cosine]] \n|| <math> \\cosh(\\alpha t) \\cdot u(t) \\ </math> \n|| <math> { s \\over s^2 - \\alpha^2  } </math> \n|| {{math|Re(''s'') > {{abs|''\u03b1''}}}}\n|| {{Harvnb|Williams|1973|p=88}}\n\n|- style=\"text-align:center;\"\n| exponentially decaying <br /> sine wave \n|| <math>e^{-\\alpha t}  \\sin(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { \\omega \\over (s+\\alpha )^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}} \n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| exponentially decaying <br /> cosine wave \n|| <math>e^{-\\alpha t}  \\cos(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { s+\\alpha \\over (s+\\alpha )^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}}\n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| [[natural logarithm]] \n|| <math> \\ln (t) \\cdot u(t) </math> \n|| <math> - { 1 \\over s}\\, \\left[ \\ln(s)+\\gamma \\right] </math> \n|| {{math|Re(''s'') > 0}} \n|| {{Harvnb|Williams|1973|p=88}}\n\n|- style=\"text-align:center;\"\n| [[Bessel function]] <br> of the first kind, <br /> of order ''n'' \n|| <math> J_n( \\omega t) \\cdot u(t)</math> \n|| <math>\\frac{ \\left(\\sqrt{s^2+ \\omega^2}-s\\right)^n}{\\omega^n \\sqrt{s^2 + \\omega^2}}</math> \n|| {{math|Re(''s'') > 0}}   <br /> ({{math|''n'' > \u22121}}) \n|| {{Harvnb|Williams|1973|p=89}}\n\n|- style=\"text-align:center;\"\n| [[Error function]] \n|| <math> \\operatorname{erf}(t) \\cdot u(t) </math> \n|| <math> \\frac 1 s e^{(1/4)s^2} \\left(1 - \\operatorname{erf} \\frac s 2 \\right)</math> \n|| {{math|Re(''s'') > 0}}\n|| {{Harvnb|Williams|1973|p=89}}\n\n|-\n| colspan=5|'''Explanatory notes:'''\n{{col-begin}}\n{{col-break}}\n\n* {{math|''u''(''t'')}} represents the [[Heaviside step function]].\n* {{math|''\u03b4''}}  represents the [[Dirac delta function]].\n* {{math|\u0393(''z'')}} represents the [[gamma function]].\n* {{math|''\u03b3''}} is the [[Euler&ndash;Mascheroni constant]].\n\n{{col-break}}\n\n*  {{math|''t''}}, a real number, typically represents ''time'', <br />although it can represent ''any'' independent dimension.\n*  {{math|''s''}} is the [[complex number|complex]] frequency domain parameter, and  {{math|Re(''s'')}} is its [[real part]].\n*  {{math|''\u03b1'', ''\u03b2'', ''\u03c4,'' and ''\u03c9''}} are [[real numbers]].\n*  {{math|''n''}} is an [[integer]].\n\n{{col-end}}\n|}\n\n== ''s''-domain equivalent circuits and impedances ==\nThe Laplace transform is often used in circuit analysis, and simple conversions to the {{math|''s''}}-domain of circuit elements can be made. Circuit elements can be transformed into [[Electrical impedance|impedance]]s, very similar to [[Phasor (sine waves)|phasor]] impedances.\n\nHere is a summary of equivalents:\n\n: [[File:S-Domain circuit equivalents.svg|alt={{math|''s''}}-domain equivalent circuits|centre|frameless|400x400px|{{math|''s''}}-domain equivalent circuits]]\n\nNote that the resistor is exactly the same in the time domain and the {{math|''s''}}-domain. The sources are put in if there are initial conditions on the circuit elements. For example, if a capacitor has an initial voltage across it, or if the inductor has an initial current through it, the sources inserted in the {{math|''s''}}-domain account for that.\n\nThe equivalents for current and voltage sources are simply derived from the transformations in the table above.\n\n== Examples and applications ==\n<!--A few worked examples are provided here to enable the reader to assess comprehension of the factual presentation.  Elaboration beyond the role of supporting factual comprehension belongs at [[v:|Wikiversity]] or [[b:|Wikibooks]].-->\n\nThe Laplace transform is used frequently in [[engineering]] and [[physics]]; the output of a [[linear time-invariant]] system can be calculated by convolving its unit impulse response with the input signal. Performing this calculation in Laplace space turns the convolution into a multiplication; the latter being easier to solve because of its algebraic form. For more information, see [[control theory]].\n\nThe Laplace transform can also be used to solve differential equations and is used extensively in [[mechanical engineering]] and [[electrical engineering]].  The Laplace transform reduces a linear differential equation to an algebraic equation, which can then be solved by the formal rules of algebra.  The original differential equation can then be solved by applying the inverse Laplace transform.  The English electrical engineer Oliver Heaviside first proposed a similar scheme, although without using the Laplace transform; and the resulting operational calculus is credited as the Heaviside calculus.\n\n=== Evaluating improper integrals ===\nLet <math>\\mathcal{L}\\left\\{f(t)\\right\\} = F(s)</math>, then (see the table above)\n\n: <math>\\mathcal{L} \\left\\{\\frac{f(t)} t \\right\\} = \\int_s^\\infty F(p)\\, dp,</math>\n\nor\n\n: <math>\\int_0^\\infty \\frac{f(t)}{t}e^{-st}\\, dt = \\int_s^\\infty F(p)\\, dp.</math>\n\nLetting {{math|''s'' \u2192 0}}, gives one the identity\n\n: <math>\\int_0^\\infty \\frac{f(t)} t \\, dt = \\int_0^\\infty F(p)\\, dp.</math>\n\nprovided that the interchange of limits can be justified. Even when the interchange cannot be justified the calculation can be suggestive. For example, with ''a''&nbsp;\u2260&nbsp;0&nbsp;\u2260&nbsp;''b'', proceeding formally one has\n\n: <math>\n\\begin{align}\n& \\int_0^\\infty \\frac 1 t ( \\cos(at) - \\cos(bt) )\\, dt =\n  \\int_0^\\infty \\left(\\frac p {p^2 + a^2} - \\frac{p}{p^2 + b^2}\\right)\\, dp \\\\[6pt]\n= {} & \\frac 1 2 \\left. \\ln\\frac{p^2 + a^2}{p^2 + b^2} \\right|_{p\\,:=\\,0}^\\infty = \\ln|b| - \\ln |a|.\n\\end{align}\n</math>\n\nThe validity of this identity can be proved by other means. It is an example of a [[Frullani integral]].\n\nAnother example is [[Dirichlet integral]].\n\n=== Nuclear physics ===\nIn [[nuclear physics]], the following fundamental relationship governs [[radioactive decay]]: the number of radioactive atoms {{math|''N''}} in a sample of a radioactive [[isotope]] decays at a rate proportional to {{math|''N''}}.  This leads to the first order linear differential equation\n\n: <math>\\frac{dN}{dt} = -\\lambda N,</math>\n\nwhere {{math|''\u03bb''}} is the [[decay constant]]. The Laplace transform can be used to solve this equation.\n\nRearranging the equation to one side, we have\n\n: <math>\\frac{dN}{dt} + \\lambda N = 0.</math>\n\nNext, we take the Laplace transform of both sides of the equation:\n\n: <math>\\left( s \\widetilde{N}(s) - N_0 \\right) + \\lambda \\widetilde{N}(s) = 0,</math>\n\nwhere\n\n: <math>\\widetilde{N}(s) = \\mathcal{L}\\{N(t)\\}</math>\n\nand\n\n: <math>N_0 = N(0).</math>\n\nSolving, we find\n\n: <math>\\widetilde{N}(s) = \\frac{N_0}{s + \\lambda}.</math>\n\nFinally, we take the inverse Laplace transform to find the general solution\n\n: <math>\\begin{align}\n  N(t) &= \\mathcal{L}^{-1} \\{\\widetilde{N}(s)\\} = \\mathcal{L}^{-1}\\! \\left\\{ \\frac{N_0}{s + \\lambda} \\right\\}\\\\\n       &= \\ N_0 e^{-\\lambda t},\n\\end{align}</math>\n\nwhich is indeed the correct form for radioactive decay.\n\n=== Complex impedance of a capacitor ===\nIn the theory of [[electrical circuit]]s, the current flow in a [[capacitor]] is proportional to the capacitance and rate of change in the electrical potential (in [[International System of Units|SI]] units). Symbolically, this is expressed by the differential equation\n\n: <math>i = C { dv \\over dt} ,</math>\n\nwhere {{math|''C''}} is the capacitance (in [[farad]]s) of the capacitor, {{math|1=''i'' = ''i''(''t'')}} is the [[electric current]] (in [[ampere]]s) through the capacitor as a function of time, and {{math|1=''v'' = ''v''(''t'')}} is the [[electrostatic potential|voltage]] (in [[volt]]s) across the terminals of the capacitor, also as a function of time.\n\nTaking the Laplace transform of this equation, we obtain\n\n: <math>I(s) = C(s V(s) - V_0),</math>\n\nwhere\n\n: <math>\\begin{align}\n  I(s) &= \\mathcal{L} \\{ i(t) \\},\\\\\n  V(s) &= \\mathcal{L} \\{ v(t) \\},\n\\end{align}</math>\n\nand\n\n: <math>V_0 = v(t)\\Big|_{t=0}. \\, </math>\n\nSolving for {{math|''V''(''s'')}} we have\n\n: <math>V(s) = { I(s) \\over sC } + { V_0 \\over s }.</math>\n\nThe definition of the complex impedance {{math|''Z''}} (in [[ohm]]s) is the ratio of the complex voltage {{math|''V''}} divided by the complex current {{math|''I''}} while holding the initial state {{math|''V''<sub>0</sub>}} at zero:\n\n: <math>Z(s) = \\left. { V(s) \\over I(s) } \\right|_{V_0 = 0}.</math>\n\nUsing this definition and the previous equation, we find:\n\n: <math>Z(s) = \\frac{1}{sC}, </math>\n\nwhich is the correct expression for the complex impedance of a capacitor. \nIn addition, the Laplace transform has large applications in control theory.\n\n=== Partial fraction expansion ===\n<!-- [[Partial fractions in Laplace transforms]] redirect here -->\nConsider a linear time-invariant system with [[transfer function]]\n: <math>H(s) = \\frac{1}{(s + \\alpha)(s + \\beta)}.</math>\n\nThe [[impulse response]] is simply the inverse Laplace transform of this transfer function:\n: <math>h(t) = \\mathcal{L}^{-1}\\{H(s)\\}.</math>\n\nTo evaluate this inverse transform, we begin by expanding {{math|''H''(''s'')}} using the method of partial fraction expansion,\n\n: <math>\\frac{1}{(s + \\alpha)(s + \\beta)} = { P \\over s + \\alpha } + { R \\over s+\\beta }.</math>\n\nThe unknown constants {{math|''P''}} and {{math|''R''}} are the [[residue (complex analysis)|residue]]s located at the corresponding poles of the transfer function. Each residue represents the relative contribution of that [[mathematical singularity|singularity]] to the transfer function's overall shape.\n\nBy the [[residue theorem]], the inverse Laplace transform depends only upon the poles and their residues. To find the residue {{math|''P''}}, we multiply both sides of the equation by {{math|''s'' + ''\u03b1''}} to get\n: <math>\\frac{1}{s + \\beta} = P  + { R (s + \\alpha) \\over s + \\beta }.</math>\n\nThen by letting {{math|1=''s'' = \u2212''\u03b1''}}, the contribution from {{math|''R''}} vanishes and all that is left is\n: <math>P = \\left.{1 \\over s+\\beta}\\right|_{s=-\\alpha} = {1 \\over \\beta - \\alpha}.</math>\n\nSimilarly, the residue {{math|''R''}} is given by\n: <math>R = \\left.{1 \\over s + \\alpha}\\right|_{s=-\\beta} = {1 \\over \\alpha - \\beta}.</math>\n\nNote that\n: <math>R = {-1 \\over \\beta - \\alpha} = - P</math>\nand so the substitution of {{math|''R''}} and {{math|''P''}} into the expanded expression for {{math|''H''(''s'')}} gives\n: <math>H(s)  = \\left( \\frac{1}{\\beta - \\alpha} \\right) \\cdot \\left(  { 1 \\over s + \\alpha } - { 1  \\over s + \\beta }  \\right).</math>\n\nFinally, using the linearity property and the known transform for exponential decay (see ''Item'' #''3'' in the ''Table of Laplace Transforms'', above), we can take the inverse Laplace transform of {{math|''H''(''s'')}} to obtain\n: <math>h(t) = \\mathcal{L}^{-1}\\{H(s)\\} = \\frac{1}{\\beta - \\alpha}\\left(e^{-\\alpha t} - e^{-\\beta t}\\right),</math>\nwhich is the impulse response of the system.\n\n;Convolution\nThe same result can be achieved using the [[Convolution theorem|convolution property]] as if the system is a series of filters with transfer functions of {{math|1/(''s'' + ''a'')}} and {{math|1/(''s'' + ''b'')}}. That is, the inverse of\n\n: <math>H(s) = \\frac{1}{(s + a)(s + b)} = \\frac{1}{s+a} \\cdot \\frac{1}{s + b}</math>\n\nis\n\n: <math> \\mathcal{L}^{-1}\\! \\left\\{ \\frac{1}{s + a} \\right\\} * \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s + b} \\right\\} = e^{-at} * e^{-bt} = \\int_0^t e^{-ax}e^{-b(t - x)}\\, dx = \\frac{e^{-a t}-e^{-b t}}{b - a}.</math>\n\n=== Phase delay ===\n{| class=\"wikitable\"\n|-\n! Time function\n! Laplace transform\n|-\n| <math>\\sin{(\\omega t + \\varphi)}</math>\n| <math>\\frac{s\\sin(\\varphi) + \\omega \\cos(\\varphi)}{s^2 + \\omega^2}</math>\n|-\n| <math>\\cos{(\\omega t + \\varphi)}</math>\n| <math>\\frac{s\\cos(\\varphi) - \\omega \\sin(\\varphi)}{s^2 + \\omega^2}.</math>\n|}\n\nStarting with the Laplace transform,\n\n: <math>X(s) = \\frac{s\\sin(\\varphi) + \\omega \\cos(\\varphi)}{s^2 + \\omega^2}</math>\n\nwe find the inverse by first rearranging terms in the fraction:\n\n: <math>\\begin{align}\n  X(s) &= \\frac{s \\sin(\\varphi)}{s^2 + \\omega^2} + \\frac{\\omega \\cos(\\varphi)}{s^2 + \\omega^2} \\\\\n       &= \\sin(\\varphi) \\left(\\frac{s}{s^2 + \\omega^2} \\right) + \\cos(\\varphi) \\left(\\frac{\\omega}{s^2 + \\omega^2} \\right).\n\\end{align}</math>\n\nWe are now able to take the inverse Laplace transform of our terms:\n\n: <math>\\begin{align}\n  x(t) &= \\sin(\\varphi) \\mathcal{L}^{-1}\\left\\{\\frac{s}{s^2 + \\omega^2} \\right\\} + \\cos(\\varphi) \\mathcal{L}^{-1}\\left\\{\\frac{\\omega}{s^2 + \\omega^2} \\right\\} \\\\\n       &= \\sin(\\varphi)\\cos(\\omega t) + \\sin(\\omega t)\\cos(\\varphi).\n\\end{align}</math>\n\nThis is just the [[Trigonometric identity#Angle sum and difference identities|sine of the sum]] of the arguments, yielding:\n\n:<math>x(t) = \\sin (\\omega t + \\varphi).</math>\n\nWe can apply similar logic to find that\n\n: <math>\\mathcal{L}^{-1} \\left\\{ \\frac{s\\cos\\varphi - \\omega \\sin\\varphi}{s^2 + \\omega^2} \\right\\} = \\cos{(\\omega t + \\varphi)}.</math>\n\n=== {{Anchor|Inferring spatial structure from spectrum}}Determining structure of astronomical object from spectrum ===\nThe wide and general applicability of the Laplace transform and its inverse is illustrated by an application in astronomy which provides some information on the ''spatial distribution'' of matter of an [[Astronomy|astronomical]] source of [[Radio frequency|radio-frequency]] [[thermal radiation]] too distant to [[Angular resolution|resolve]] as more than a point, given its [[flux density]] [[spectrum]], rather than relating the ''time'' domain with the spectrum (frequency domain).\n\nAssuming certain properties of the object, e.g. spherical shape and constant temperature, calculations based on carrying out an inverse Laplace transformation on the spectrum of the object can produce the only possible [[Mathematical model|model]] of the distribution of matter in it (density as a function of distance from the center) consistent with the spectrum.<ref>{{citation |first1=M. |last1=Salem |first2=M. J. |last2=Seaton |year=1974 |title=I. Continuum spectra and brightness contours |journal=[[Monthly Notices of the Royal Astronomical Society]] |volume=167 |issue=3 |pages=493\u2013510 |doi=10.1093/mnras/167.3.493 |bibcode=1974MNRAS.167..493S}}, and<br/>{{citation |first1=M. |last1=Salem |year=1974 |title=II. Three-dimensional models |journal=Monthly Notices of the Royal Astronomical Society |volume=167 |issue=3 |pages=511\u2013516 |doi=10.1093/mnras/167.3.511 |bibcode=1974MNRAS.167..511S}}</ref> When independent information on the structure of an object is available, the inverse Laplace transform method has been found to be in good agreement.\n\n=== Statistical mechanics ===\nIn [[statistical mechanics]], the Laplace transform of the density of states <math>g(E)dE</math> defines the [[partition function (statistical mechanics)|partition function]].<ref>{{cite book|author1=RK Pathria|author2=Paul Beal|title=Statistical mechanics|edition=2nd|publisher=Butterworth-Heinemann|year=1996|page=56}}</ref> That is, the partition function <math>Z(\\beta)</math> is given by\n:<math> Z(\\beta) = \\int_0^\\infty e^{-\\beta E}g(E)dE</math>\nand the inverse is given by\n:<math> g(E) = \\frac{1}{2\\pi i} \\int_{\\beta_0-i\\infty}^{\\beta_0+i\\infty} e^{\\beta E}Z(\\beta) d\\beta</math>\n\n== See also ==\n{{div col}}\n* [[Analog signal processing]]\n* [[Bernstein's theorem on monotone functions]]\n* [[Continuous-repayment mortgage#Mortgage difference and differential equation|Continuous-repayment mortgage]]\n* [[Hamburger moment problem]]\n* [[Hardy\u2013Littlewood tauberian theorem]]\n* [[Laplace\u2013Carson transform]]\n* [[Moment-generating function]]\n* [[Nonlocal operator]]\n* [[Pierre-Simon Laplace]]\n* [[Post's inversion formula]]\n* [[Signal-flow graph]]\n* [[Symbolic integration]]\n* [[Transfer function]]\n{{div col end}}\n\n== Notes ==\n{{Reflist|30em}}\n\n== References ==\n\n=== Modern ===\n* {{Citation |last=Bracewell |first=Ronald N. |title=The Fourier Transform and its Applications |edition=2nd |year=1978 |publisher=McGraw-Hill Kogakusha |isbn=978-0-07-007013-4 }}<!-- This edition is used for pinpoint citations in the transform table. -->\n* {{citation|first=R. N.|last=Bracewell|title=The Fourier Transform and Its Applications|edition=3rd|location=Boston|publisher=McGraw-Hill|year=2000|isbn=978-0-07-116043-8}}\n* {{Citation | last1=Feller | first1=William | author1-link=William Feller | title=An introduction to probability theory and its applications. Vol. II. | publisher=[[John Wiley & Sons]] | location=New York | series=Second edition | mr=0270403  | year=1971}}\n* {{citation |first1=G. A. |last1=Korn |first2=T. M. |last2=Korn |title=Mathematical Handbook for Scientists and Engineers |publisher=McGraw-Hill Companies |edition=2nd |year=1967 |isbn=978-0-07-035370-1 }}\n* {{Citation | last1=Widder | first1=David Vernon | title=The Laplace Transform | publisher=[[Princeton University Press]] | series=Princeton Mathematical Series, v. 6 | mr=0005923  | year=1941}}\n* {{Citation | last=Williams |first=J. |title=Laplace Transforms |series=Problem Solvers |volume= |publisher=George Allen & Unwin |year=1973 |isbn= 978-0-04-512021-5 }}\n* {{Citation | last=Takacs | first= J.|title=Fourier amplitudok meghatarozasa operatorszamitassal | year=1953 | journal=Magyar Hiradastechnika | volume=IV | issue=7\u20138|pages=93\u201396 |language=Hungarian }}\n\n=== Historical ===\n<!-- Citations to Opera omnia [The Complete Works] are wrong. Opera omnia was published 1911 and after, so the citations should be |origyear=17xx |year=1992... Handling of Euler's volume number and Opera omnia volume is problematic -->\n* {{citation |last=Euler |first=L. |authorlink=Leonhard Euler |year=1744 |title=De constructione aequationum |trans-title=The Construction of Equations |language=la |journal=Opera Omnia |series=1st series |volume=22 |pages=150\u2013161}}\n* {{citation |last=Euler |first=L. |authorlink=Leonhard Euler |year=1753 |title=Methodus aequationes differentiales |trans-title=A Method for Solving Differential Equations |language=la |journal=Opera Omnia |series=1st series |volume=22 |pages=181\u2013213}}\n* {{citation |last=Euler |first=L. |authorlink=Leonhard Euler |origyear=1769 |title=Institutiones calculi integralis, Volume 2 |trans-title=Institutions of Integral Calculus |language=la |journal=Opera Omnia |series=1st series |volume=12 |year=1992 |location=Basel |publisher=Birkh\u00e4user |isbn=978-3764314743 <!-- isbn for the entire first series-->}}, Chapters 3\u20135\n* {{citation |last=Euler |first=Leonhard |authorlink=Leonhard Euler |year=1769 |title=Institutiones calculi integralis |trans-title=Institutions of Integral Calculus |language=la |volume=II <!--Secundum--> |at=ch. 3\u20135, pp. 57\u2013153 |location=Paris |publisher=Petropoli |url=https://books.google.com/books?id=BFqWNwpfqo8C }}\n* {{citation|last=Grattan-Guinness|first=I|authorlink=Ivor Grattan-Guinness|year=1997|contribution=Laplace's integral solutions to partial differential equations|editor=Gillispie, C. C.|title=Pierre Simon Laplace 1749\u20131827: A Life in Exact Science|location=Princeton|publisher=Princeton University Press|isbn=978-0-691-01185-1}}\n* {{citation|last=Lagrange|first=J. L.|authorlink=Joseph Louis Lagrange|year=1773|title=M\u00e9moire sur l'utilit\u00e9 de la m\u00e9thode|series=\u0152uvres de Lagrange|volume=2|pages=171\u2013234}}\n\n==Further reading==\n* {{citation|first1=Wolfgang|last1=Arendt|first2=Charles J.K.|last2=Batty|first3=Matthias|last3=Hieber|first4=Frank|last4=Neubrander|title=Vector-Valued Laplace Transforms and Cauchy Problems|publisher=Birkh\u00e4user Basel|year=2002|isbn=978-3-7643-6549-3 |ref=none}}.\n* {{citation|last=Davies|first=Brian|title=Integral transforms and their applications|edition=Third|publisher=Springer|location=New York|year=2002|isbn= 978-0-387-95314-4 |ref=none}}\n* {{citation | last=Deakin|first= M. A. B. | year=1981 | title=The development of the Laplace transform | journal=Archive for History of Exact Sciences | volume=25 | pages=343\u2013390 | doi=10.1007/BF01395660 | issue=4 |ref=none}}\n* {{citation | last=Deakin|first= M. A. B. | year=1982 | title=The development of the Laplace transform | journal=Archive for History of Exact Sciences | volume=26 | pages=351\u2013381 | doi=10.1007/BF00418754 | issue=4 |ref=none}}\n* {{citation |last=Doetsch |first=Gustav |authorlink=Gustav Doetsch |date=1974 |title=Introduction to the Theory and Application of the Laplace Transformation |publisher=Springer |isbn=978-0-387-06407-9 |ref=none}}\n* Mathews, Jon; Walker, Robert L. (1970), ''Mathematical methods of physics'' (2nd ed.), New York: W. A. Benjamin, {{isbn|0-8053-7002-1}}\n* {{citation|first1=A. D.|last1=Polyanin|first2=A. V.|last2=Manzhirov|title=Handbook of Integral Equations|publisher=CRC Press|location=Boca Raton|year=1998|isbn=978-0-8493-2876-3 |ref=none}}\n* {{Citation | last1=Schwartz | first1=Laurent | author-link=Laurent Schwartz | title=Transformation de Laplace des distributions | mr=0052555  | year=1952 | journal=Comm. S\u00e9m. Math. Univ. Lund [Medd. Lunds Univ. Mat. Sem.] | volume=1952 | pages=196\u2013206 |language=French |ref=none}}\n* {{Citation |last=Schwartz |first=Laurent |author-link=Laurent Schwartz |year=2008 |origyear=1966 |title=Mathematics for the Physical Sciences |publisher=Dover Publications |location=New York |series=Dover Books on Mathematics |pages=215\u2013241 |isbn=978-0-486-46662-0 |url={{Google books|-_AuDQAAQBAJ|Mathematics for the Physical Sciences|page=215|plainurl=yes}} |ref=none}} - See Chapter VI. The Laplace transform.\n* {{citation|first=William McC.|last=Siebert|title=Circuits, Signals, and Systems|publisher=MIT Press|location=Cambridge, Massachusetts|year=1986|isbn=978-0-262-19229-3 |ref=none}}\n* {{Citation | last1=Widder | first1=David Vernon | title=What is the Laplace transform? | mr=0013447  | year=1945 | journal=[[American Mathematical Monthly|The American Mathematical Monthly]] | issn=0002-9890 |volume=52 |issue=8 | pages=419\u2013425 | doi=10.2307/2305640 | jstor=2305640 |ref=none}}\n\n== External links ==\n{{wikiquote}}\n{{commons category|Laplace transformation}}\n* {{springer|title=Laplace transform|id=p/l057540}}\n* [http://wims.unice.fr/wims/wims.cgi?lang=en&+module=tool%2Fanalysis%2Ffourierlaplace Online Computation] of the transform or inverse transform, wims.unice.fr\n* [http://eqworld.ipmnet.ru/en/auxiliary/aux-inttrans.htm Tables of Integral Transforms] at EqWorld: The World of Mathematical Equations.\n* {{MathWorld|title=Laplace Transform|urlname=LaplaceTransform}}\n* [http://fourier.eng.hmc.edu/e102/lectures/Laplace_Transform/ Good explanations of the initial and final value theorems]\n* [http://www.mathpages.com/home/kmath508/kmath508.htm Laplace Transforms] at MathPages\n* [http://www.wolframalpha.com/input/?i=laplace+transform+example Computational Knowledge Engine] allows to easily calculate Laplace Transforms and its inverse Transform.\n* [http://www.laplacetransformcalculator.com/easy-laplace-transform-calculator/ Laplace Calculator] to calculate Laplace Transforms online easily.\n* [https://johnflux.com/2019/02/12/laplace-transform-visualized/ Code to visualize Laplace Transforms] and many example videos.\n\n{{Authority control}}\n\n{{DEFAULTSORT:Laplace Transform}}\n[[Category:Laplace transforms| ]]\n[[Category:Differential equations]]\n[[Category:Fourier analysis]]\n[[Category:Mathematical physics]]\n", "text_old": "{{redirect|\u2112|the Lagrangian|Lagrangian mechanics}}\nIn [[mathematics]], the '''Laplace transform''' is an [[integral transform]] named after its inventor [[Pierre-Simon Laplace]] ({{IPAc-en|l|\u0259|\u02c8|p|l|\u0251:|s}}).  It transforms a function of a real variable {{math|''t''}} (often time) to a function of a [[complex analysis|complex variable]] {{mvar|s}} ([[complex frequency]]). The transform has many applications in science and engineering.\n\n{{Gallery|width=265 | height=150 |lines=2 |align=right|File:Graph of e^t cos(10t).png|An example curve of e^t cos(10t) that is added together with similar curves to form a Laplace Transform.|File:Laplace animation of Cubic Polynomial.gif|Animation showing how adding together curves can approximate a function.}}\n\nThe Laplace transform is similar to the [[Fourier transform]].  While the Fourier transform of a function is a [[complex function]] of a ''real'' variable (frequency), the Laplace transform of a function is a complex function of a ''complex variable''.  The Laplace transform is usually restricted to transformation of functions of {{math|''t''}} with {{math|''t'' \u2265 0}}.  A consequence of this restriction is that the Laplace transform of a function is a [[holomorphic function]] of the variable {{math|''s''}}.  Unlike the Fourier transform, the Laplace transform of a [[distribution (mathematics)|distribution]] is generally a [[well-behaved]] function.  Techniques of complex variables can also be used to  directly study Laplace transforms.  As a holomorphic function, the Laplace transform has a power series representation.  This power series expresses a function as a linear superposition of [[moment (mathematics)|moments]] of the function.  This perspective has applications in [[probability theory]].\n\nThe Laplace transform is invertible on a large class of functions. The inverse Laplace transform takes a function of a complex variable ''s'' (often frequency) and yields a function of a real variable ''t'' (often time).  Given a simple mathematical or functional description of an input or output to a [[system]], the Laplace transform provides an alternative functional description that often simplifies the process of analyzing the behavior of the system, or in synthesizing a new system based on a set of specifications.<ref>{{harvnb|Korn|Korn|1967|loc=\u00a78.1}}</ref>  So, for example, Laplace transformation from the [[time domain]] to the [[frequency domain]] transforms differential equations into algebraic equations and [[convolution]] into multiplication.\n\nLaplace wrote extensively about the use of [[Generating function|generating functions]] in ''Essai philosophique sur les probabilit\u00e9s'' (1814) and the integral form of the Laplace transform evolved naturally as a result.<ref>{{Cite book|title=Probability theory : the logic of science|last=Jaynes, E. T. (Edwin T.)|date=2003|publisher=Cambridge University Press|others=Bretthorst, G. Larry|isbn=0511065892|location=Cambridge, UK|oclc=57254076}}</ref>\n\n== History ==\nThe Laplace transform is named after mathematician and astronomer Pierre-Simon Laplace, who used a similar transform in his work on probability theory.<ref>{{citation |url=https://archive.org/details/thorieanalytiqu01laplgoog |title=Th\u00e9orie analytique des Probabilit\u00e9s |location=Paris |date=1814 |edition=2nd |at=chap.I sect.2-20 |chapter=Des Fonctions g\u00e9n\u00e9ratrices |trans-title=Analytical Probability Theory |trans-chapter=On generating functions |language=fr}}</ref> Laplace's use of generating functions was similar to what is now known as the z-transform and he gave little attention to the continuous variable case which was discussed by [[Niels Henrik Abel]].<ref>{{citation |first=Niels H. |last=Abel|authorlink=Niels Henrik Abel |chapter=Sur les fonctions g\u00e9n\u00e9ratrices et leurs d\u00e9terminantes |date=1820 |title=\u0152uvres Compl\u00e8tes |language=fr |publication-date=1839 |volume=II |pages=77\u201388}} [https://books.google.com/books?id=6FtDAQAAMAAJ&pg=RA2-PA67&lpg=RA2-PA67 1881 edition]</ref> The theory was further developed in the 19th and early 20th centuries by [[Mathias Lerch]],<ref>{{citation |first=Mathias |last=Lerch |author-link=Mathias Lerch |title=Sur un point de la th\u00e9orie des fonctions g\u00e9n\u00e9ratrices d'Abel |journal=[[Acta Mathematica]] |volume=27 |date=1903 |pages=339\u2013351 |doi=10.1007/BF02421315 |trans-title=Proof of the inversion formula |language=fr}}</ref> [[Oliver Heaviside]],<ref>{{citation |first=Oliver |last=Heaviside |author-link=Oliver Heaviside |chapter=The solution of definite integrals by differential transformation |title=Electromagnetic Theory |location=London |at=section 526 |volume=III |chapter-url=https://books.google.com/books?id=y9auR0L6ZRcC&pg=PA234&lpg=PA234|isbn=9781605206189 |date=January 2008 }}</ref> and [[Thomas John I'Anson Bromwich|Thomas Bromwich]].<ref>{{citation |first=Thomas J. |last=Bromwich |author-link=Thomas John I'Anson Bromwich |title=Normal coordinates in dynamical systems |journal=[[Proceedings of the London Mathematical Society]] |volume=15 |pages=401\u2013448 |date=1916 |doi=10.1112/plms/s2-15.1.401|url=https://zenodo.org/record/2319588 }}</ref> The current widespread use of the transform (mainly in engineering) came about during and soon after World War II<ref>An influential book was: {{citation |first=Murray F. |last=Gardner |first2=John L. |last2=Barnes |title=Transients in Linear Systems studied by the Laplace Transform |date=1942 |location=New York |publisher=Wiley}}</ref> replacing the earlier Heaviside operational calculus. The advantages of the Laplace transform had been emphasized by [[Gustav Doetsch]]<ref>{{citation |first=Gustav |last=Doetsch |title=Theorie und Anwendung der Laplacesche Transformation |location=Berlin |date=1937 |publisher=Springer |language=de |trans-title=Theory and Application of the Laplace Transform}} translation 1943</ref> to whom the name Laplace Transform is apparently due.  \n\nThe early history of methods having some similarity to Laplace transform is as follows. From 1744, [[Leonhard Euler]] investigated integrals of the form\n: <math> z = \\int X(x) e^{ax}\\, dx \\quad\\text{ and }\\quad z = \\int X(x) x^A \\, dx</math>\nas solutions of [[Laplace transform applied to differential equations|differential equations]] but did not pursue the matter very far.<ref>{{harvnb|Euler|1744}}, {{harvnb|Euler|1753}}, {{harvnb|Euler|1769}}</ref>\n\n[[Joseph Louis Lagrange]] was an admirer of Euler and, in his work on integrating [[probability density function]]s, investigated expressions of the form\n: <math> \\int X(x) e^{- a x } a^x\\, dx,</math>\nwhich some modern historians have interpreted within modern Laplace transform theory.<ref>{{harvnb|Lagrange|1773}}</ref><ref>{{harvnb|Grattan-Guinness| 1997|p=260}}</ref>{{Clarify|date=May 2010}}\n\nThese types of integrals seem first to have attracted Laplace's attention in 1782 where he was following in the spirit of Euler in using the integrals themselves as solutions of equations.<ref>{{harvnb|Grattan-Guinness|1997|p=261}}</ref> However, in 1785, Laplace took the critical step forward when, rather than just looking for a solution in the form of an integral, he started to apply the transforms in the sense that was later to become popular. He used an integral of the form\n: <math> \\int x^s \\varphi (x)\\, dx,</math>\nakin to a [[Mellin transform]], to transform the whole of a [[difference equation]], in order to look for solutions of the transformed equation. He then went on to apply the Laplace transform in the same way and started to derive some of its properties, beginning to appreciate its potential power.<ref>{{harvnb|Grattan-Guinness|1997|pp=261\u2013262}}</ref>\n\nLaplace also recognised that [[Joseph Fourier]]'s method of [[Fourier series]] for solving the [[diffusion equation]] could only apply to a limited region of space because those solutions were periodic. In 1809, Laplace applied his transform to find solutions that diffused indefinitely in space.<ref>{{harvnb|Grattan-Guinness|1997|pp=262&ndash;266}}</ref>\n\n== Formal definition ==\nThe Laplace transform of a [[function (mathematics)|function]] {{math|''f''(''t'')}}, defined for all [[real number]]s {{math|''t'' \u2265 0}}, is the function {{math|''F''(''s'')}}, which is a unilateral transform defined by\n{{Equation box 1\n|indent =\n|title=\n|equation = {{NumBlk||<math>F(s) =\\int_0^\\infty f(t)e^{-st} \\, dt</math>|{{EquationRef|Eq.1}}}}\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nwhere ''s'' is a [[complex number]] frequency parameter\n: <math>s = \\sigma + i \\omega</math>, with real numbers {{math|''\u03c3''}} and {{math|''\u03c9''}}.\n\nAn alternate notation for the Laplace transform is <math>\\mathcal{L}\\{f\\}</math> instead of {{math|''F''}}.\n\nThe meaning of the integral depends on types of functions of interest.  A necessary condition for existence of the integral is that {{math|''f''}} must be [[locally integrable]] on {{closed-open|0, \u221e}}.  For locally integrable functions that decay at infinity or are of [[exponential type]], the integral can be understood to be a (proper) [[Lebesgue integral]]. However, for many applications it is necessary to regard it as a [[conditionally convergent]] [[improper integral]] at {{math|\u221e}}.  Still more generally, the integral can be understood in a [[distribution (mathematics)|weak sense]], and this is dealt with below.\n\nOne can define the Laplace transform of a finite [[Borel measure]] {{math|''\u03bc''}} by the Lebesgue integral<ref>{{harvnb|Feller|1971|loc=\u00a7XIII.1}}</ref>\n: <math>\\mathcal{L}\\{\\mu\\}(s) = \\int_{[0,\\infty)} e^{-st}\\, d\\mu(t).</math>\n\nAn important special case is where {{math|''\u03bc''}} is a [[probability measure]], for example, the [[Dirac delta function]]. In [[operational calculus]], the Laplace transform of a measure is often treated as though the measure came from a probability density function {{math|''f''}}.  In that case, to avoid potential confusion, one often writes\n: <math>\\mathcal{L}\\{f\\}(s) = \\int_{0^-}^\\infty f(t)e^{-st} \\, dt,</math>\nwhere the lower limit of {{math|0<sup>\u2212</sup>}} is shorthand notation for\n: <math>\\lim_{\\varepsilon\\rightarrow 0^+}\\int_{-\\varepsilon}^\\infty.</math>\n\nThis limit emphasizes that any point mass located at {{math|0}} is entirely captured by the Laplace transform. Although with the Lebesgue integral, it is not necessary to take such a limit, it does appear more naturally in connection with the [[Laplace\u2013Stieltjes transform]].\n\n=== Bilateral Laplace transform ===\n{{Main article|Two-sided Laplace transform}}\n\nWhen one says \"the Laplace transform\" without qualification, the unilateral or one-sided transform is normally intended. The Laplace transform can be alternatively defined as the ''bilateral Laplace transform'' or [[two-sided Laplace transform]] by extending the limits of integration to be the entire real axis.  If that is done the common unilateral transform simply becomes a special case of the bilateral transform where the definition of the function being transformed is multiplied by the [[Heaviside step function]].\nThe bilateral Laplace transform is defined as follows:\n{{math|''F''(''s'')}}, which is a bilateral transform defined by\n{{Equation box 1\n|indent =\n|title=\n|equation = {{NumBlk||<math>F(s) = \\int_{-\\infty}^\\infty e^{-st} f(t)\\, dt</math>|{{EquationRef|Eq.2}}}}\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nAn alternate notation for the bilateral Laplace transform is <math>\\mathcal{B}\\{f\\}</math> instead of <math>F</math>.\n\n=== Inverse Laplace transform ===\n{{Main article|Inverse Laplace transform}}\nTwo integrable functions have the same Laplace transform only if they differ on a set of [[Lebesgue measure]] zero. This means that, on the range of the transform, there is an inverse transform. In fact, besides integrable functions, the Laplace transform is a [[one-to-one function|one-to-one]] mapping from one function space into another in many other function spaces as well, although there is usually no easy characterization of the range. Typical function spaces in which this is true include the spaces of bounded continuous functions, the space [[Lp space|{{math|''L''<sup>&infin;</sup>(0, &infin;)}}]], or more generally [[Distribution (mathematics)#Tempered distributions and Fourier transform|tempered distributions]] on {{open-open|0, &infin;}}.  The Laplace transform is also defined and injective for suitable spaces of tempered distributions.\n\nIn these cases, the image of the Laplace transform lives in a space of [[analytic function]]s in the [[#Region of convergence|region of convergence]].  The [[inverse Laplace transform]] is given by the following complex integral, which is known by various names (the '''Bromwich integral''', the '''Fourier\u2013Mellin integral''', and '''Mellin's inverse formula'''):\n{{Equation box 1\n|indent =\n|title=\n|equation = {{NumBlk||<math>f(t) = \\mathcal{L}^{-1}\\{F\\}(t) = \\frac{1}{2 \\pi i} \\lim_{T\\to\\infty}\\oint_{\\gamma - i T}^{\\gamma + i T} e^{st} F(s)\\, ds</math>|{{EquationRef|Eq.3}}}}\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nwhere {{math|''\u03b3''}} is a real number so that the contour path of integration is in the region of convergence of {{math|''F''(''s'')}}. An alternative formula for the inverse Laplace transform is given by [[Post's inversion formula]]. The limit here is interpreted in the [[weak-* topology#Weak-* topology|weak-* topology]].\n\nIn practice, it is typically more convenient to decompose a Laplace transform into known transforms of functions obtained from a table, and construct the inverse by inspection.\n\n=== Probability theory ===\nIn [[probability theory|pure]] and [[applied probability]], the Laplace transform is defined as an [[expected value]]. If {{math|''X''}} is a [[random variable]] with probability density function {{math|''f''}}, then the Laplace transform of {{math|''f''}} is given by the expectation\n: <math>\\mathcal{L}\\{f\\}(s) = \\operatorname{E}\\! \\left[e^{-sX} \\right]\\! .</math>\n\nBy [[abuse of notation|convention]], this is referred to as the Laplace transform of the random variable {{math|''X''}} itself. Replacing {{math|''s''}} by {{math|\u2212''t''}} gives the [[moment generating function]] of {{math|''X''}}. The Laplace transform has applications throughout probability theory, including [[first passage time]]s of [[stochastic processes]] such as [[Markov chain]]s, and [[renewal theory]].\n\nOf particular use is the ability to recover the [[cumulative distribution function]] of a continuous random variable {{math|''X''}} by means of the Laplace transform as follows<ref>The cumulative distribution function is the integral of the probability density function.</ref>\n: <math>F_X(x) = \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s}\\operatorname{E}\\left[e^{-sX}\\right]\\right\\}\\! (x) = \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s}\\mathcal{L}\\{f\\}(s)\\right\\}\\! (x).</math>\n\n== Region of convergence ==\nIf {{math|''f''}} is a locally integrable function (or more generally a Borel measure locally of bounded variation), then the Laplace transform {{math|''F''(''s'')}} of {{math|''f''}} converges provided that the limit\n: <math>\\lim_{R\\to\\infty}\\int_0^R f(t)e^{-st}\\,dt</math>\nexists.\n\nThe Laplace transform converges absolutely if the integral\n: <math>\\int_0^\\infty \\left|f(t)e^{-st}\\right|\\,dt</math>\nexists (as a proper Lebesgue integral).  The Laplace transform is usually understood as conditionally convergent, meaning that it converges in the former instead of the latter sense.\n\nThe set of values for which {{math|''F''(''s'')}} converges absolutely is either of the form {{math|Re(''s'') > ''a''}} or else {{math|Re(''s'') \u2265 ''a''}}, where {{math|''a''}} is an [[extended real number|extended real constant]], {{math|\u2212\u221e \u2264 ''a'' \u2264 \u221e}}.  (This follows from the [[dominated convergence theorem]].) The constant {{math|''a''}} is known as the abscissa of absolute convergence, and depends on the growth behavior of {{math|''f''(''t'')}}.<ref>{{harvnb|Widder|1941|loc=Chapter II, \u00a71}}</ref> Analogously, the two-sided transform converges absolutely in a strip of the form  {{math|''a'' < Re(''s'') < ''b''}}, and possibly including the lines {{math|1=Re(''s'') = ''a''}} or {{math|1=Re(''s'') = ''b''}}.<ref>{{harvnb|Widder|1941|loc=Chapter VI, \u00a72}}</ref>  The subset of values of {{math|''s''}} for which the Laplace transform converges absolutely is called the region of absolute convergence or the domain of absolute convergence.  In the two-sided case, it is sometimes called the strip of absolute convergence. The Laplace transform is analytic in the region of absolute convergence: this is a consequence of [[Fubini's theorem]] and [[Morera's theorem]]. \n\nSimilarly, the set of values for which {{math|''F''(''s'')}} converges (conditionally or absolutely) is known as the region of conditional convergence, or simply the '''region of convergence''' (ROC).  If the Laplace transform converges (conditionally) at {{math|1=''s'' = ''s''<sub>0</sub>}}, then it automatically converges for all {{math|''s''}} with {{math|Re(''s'') > Re(''s''<sub>0</sub>)}}.  Therefore, the region of convergence is a half-plane of the form {{math|Re(''s'') > ''a''}}, possibly including some points of the boundary line {{math|1=Re(''s'') = ''a''}}.\n\nIn the region of convergence {{math|Re(''s'') > Re(''s''<sub>0</sub>)}}, the Laplace transform of {{math|''f''}} can be expressed by [[integration by parts|integrating by parts]] as the integral\n: <math>F(s) = (s-s_0)\\int_0^\\infty e^{-(s-s_0)t}\\beta(t)\\,dt,\\quad \\beta(u) = \\int_0^u e^{-s_0t}f(t)\\,dt.</math>\n\nThat is, in the region of convergence {{math|''F''(''s'')}} can effectively be expressed as the absolutely convergent Laplace transform of some other function.  In particular, it is analytic.\n\nThere are several [[Paley\u2013Wiener theorem]]s concerning the relationship between the decay properties of {{math|''f''}} and the properties of the Laplace transform within the region of convergence.\n\nIn engineering applications, a function corresponding to a [[LTI system|linear time-invariant (LTI) system]] is ''stable'' if every bounded input produces a bounded output.  This is equivalent to the absolute convergence of the Laplace transform of the impulse response function in the region {{math|Re(''s'') \u2265 0}}.  As a result, LTI systems are stable provided the poles of the Laplace transform of the impulse response function have negative real part.\n\nThis ROC is used in knowing about the causality and stability of a system.\n\n== Properties and theorems ==\nThe Laplace transform has a number of properties that make it useful for analyzing linear [[dynamical system]]s. The most significant advantage is that [[derivative|differentiation]] becomes multiplication, and [[integral|integration]] becomes division, by  {{math|''s''}} (similarly to [[logarithm]]s changing multiplication of numbers to addition of their logarithms).\n\nBecause of this property, the Laplace variable {{math|''s''}} is also known as ''operator variable'' in the {{math|''L''}} domain: either ''derivative operator'' or (for {{math|''s''<sup>\u22121</sup>)}} ''integration operator''. The transform turns [[integral equation]]s and [[differential equation]]s to [[polynomial equation]]s, which are much easier to solve.  Once solved, use of the inverse Laplace transform reverts to the original domain.\n\nGiven the functions {{math|''f''(''t'')}} and {{math|''g''(''t'')}}, and their respective Laplace transforms {{math|''F''(''s'')}} and {{math|''G''(''s'')}},\n: <math>\\begin{align}\nf(t) &= \\mathcal{L}^{-1}\\{F(s)\\},\\\\\ng(t) &= \\mathcal{L}^{-1}\\{G(s)\\},\n\\end{align}</math>\n\nThe following '''table''' is a list of properties of unilateral Laplace transform:<ref>{{harvnb|Korn|Korn|1967|pp=226&ndash;227}}</ref>\n\n{| class=\"wikitable\" id=\"291017_tableid\"\n|+ Properties of the unilateral Laplace transform\n|-\n !\n ! Time domain\n ! {{math|''s''}} domain\n ! Comment\n|-\n ! [[Linearity]]\n | <math> a f(t) + b g(t) \\ </math>\n | <math> a F(s) + b G(s) \\ </math>\n | Can be proved using basic rules of integration.\n|-\n ! Frequency-domain derivative\n | <math> t f(t) \\ </math>\n | <math> -F'(s) \\ </math>\n | {{math|''F''\u2032}} is the first derivative of {{math|''F''}} with respect to {{math|''s''}}.\n|-\n ! Frequency-domain general derivative\n | <math> t^{n} f(t) \\ </math>\n | <math> (-1)^{n} F^{(n)}(s) \\ </math>\n | More general form, {{math|''n''}}th derivative of {{math|''F''(''s'')}}.\n|-\n ! [[Derivative]]\n | <math> f'(t) \\ </math>\n | <math> s F(s) - f(0^{+}) \\ </math>\n | {{math|''f''}} is assumed to be a [[differentiable function]], and its derivative is assumed to be of exponential type.  This can then be obtained by integration by parts\n|-\n ! Second derivative\n | <math> f''(t) \\ </math>\n | <math> s^2 F(s) - s f(0^{+}) - f'(0^{+}) \\ </math>\n | {{math|''f''}} is assumed twice differentiable and the second derivative to be of exponential type. Follows by applying the Differentiation property to {{math|''f''\u2032(''t'')}}.\n|-\n ! General derivative\n | <math> f^{(n)}(t)  \\ </math>\n | <math> s^n F(s) - \\sum_{k=1}^{n} s^{n-k} f^{(k-1)}(0^{+}) \\ </math>\n | {{math|''f''}} is assumed to be {{math|''n''}}-times differentiable, with {{math|''n''}}th derivative of exponential type.  Follows by [[mathematical induction]].\n|-\n ! [[Frequency|Frequency-domain integration]]\n | <math> \\frac{1}{t}f(t)  \\ </math>\n | <math> \\int_s^\\infty F(\\sigma)\\, d\\sigma \\ </math>\n | This is deduced using the nature of frequency differentiation and conditional convergence.\n|-\n ! Time-domain [[integral|integration]]\n | <math> \\int_0^t f(\\tau)\\, d\\tau  =  (u * f)(t)</math>\n | <math> {1 \\over s} F(s) </math>\n | {{math|''u''(''t'')}} is the Heaviside step function and {{math|(''u''&nbsp;\u2217&nbsp;''f'')(''t'')}} is the [[convolution]] of {{math|''u''(''t'')}} and {{math|''f''(''t'')}}.\n|-\n ! Frequency shifting\n | <math> e^{at} f(t)  \\ </math>\n | <math> F(s - a) \\ </math>\n |\n|-\n ! Time shifting\n | <math> f(t - a) u(t - a) \\ </math>\n | <math> e^{-as} F(s) \\ </math>\n | {{math|''u''(''t'')}} is the Heaviside step function\n|-\n ! Time scaling\n | <math>f(at)</math>\n | <math> \\frac{1}{a} F \\left ( {s \\over a} \\right )</math>\n | <math> a > 0 \\ </math>\n|-\n ! [[Multiplication]]\n | <math>f(t)g(t)</math>\n | <math> \\frac{1}{2\\pi i}\\lim_{T\\to\\infty}\\int_{c - iT}^{c + iT}F(\\sigma)G(s - \\sigma)\\,d\\sigma \\ </math>\n | The integration is done along the vertical line {{nowrap|1=Re(''\u03c3'') = ''c''}} that lies entirely within the region of convergence of {{math|''F''}}.<ref>{{harvnb|Bracewell|2000|loc=Table 14.1, p. 385}}</ref>\n|-\n ! [[Convolution]]\n | <math> (f * g)(t) = \\int_{0}^{t} f(\\tau)g(t - \\tau)\\,d\\tau</math>\n | <math> F(s) \\cdot G(s) \\ </math>\n | \n|-\n ! [[Complex conjugation]]\n | <math> f^*(t) </math>\n | <math> F^*(s^*) </math>\n |\n|-\n ! [[Cross-correlation]]\n | <math> f(t)\\star g(t) </math>\n | <math> F^*(-s^*)\\cdot G(s) </math>\n |\n|-\n ! [[Periodic function]]\n | <math>f(t)</math>\n | <math>{1 \\over 1 - e^{-Ts}} \\int_0^T e^{-st} f(t)\\,dt </math>\n | {{math|''f''(''t'')}} is a periodic function of period {{math|''T''}} so that {{math|1=''f''(''t'') = ''f''(''t'' + ''T'')}}, for all {{math|''t'' \u2265 0}}. This is the result of the time shifting property and the [[geometric series]].\n|}\n\n* '''[[Initial value theorem]]''':\n: <math>f(0^+)=\\lim_{s\\to \\infty}{sF(s)}.</math>\n* '''[[Final value theorem]]''':\n: <math>f(\\infty)=\\lim_{s\\to 0}{sF(s)}</math>, if all [[Pole (complex analysis)|poles]] of ''sF''(''s'') are in the left half-plane.\n: The final value theorem is useful because it gives the long-term behaviour without having to perform [[partial fraction]] decompositions or other difficult algebra. If {{math|''F''(''s'')}} has a pole in the right-hand plane or poles on the imaginary axis (e.g., if <math>f(t) = e^t</math> or <math>f(t) = \\sin(t)</math>), the behaviour of this formula is undefined.\n\n=== Relation to power series ===\nThe Laplace transform can be viewed as a [[continuous function|continuous]] analogue of a [[power series]].<ref>{{cite web |last1=Mattuck |first1=Arthur |title=Where the Laplace Transform comes from |url=https://www.youtube.com/watch?v=zvbdoSeGAgI}}</ref> If  {{math|''a''(''n'')}} is a discrete function of a positive integer {{math|''n''}}, then the power series associated to  {{math|''a''(''n'')}} is the series\n:<math>\\sum_{n=0}^{\\infty} a(n) x^n</math>\nwhere  {{math|''x''}} is a real variable (see [[Z transform]]). Replacing summation over {{math|''n''}} with integration over  {{math|''t''}}, a continuous version of the power series becomes\n:<math>\\int_{0}^{\\infty} f(t) x^t\\, dt</math>\nwhere the discrete function {{math|''a''(''n'')}} is replaced by the continuous one {{math|''f''(''t'')}}. \n\nChanging the base of the power from {{math|''x''}} to {{math|''e''}} gives\n:<math>\\int_{0}^{\\infty} f(t) \\left(e^{\\ln{x}}\\right)^t\\, dt</math>\n\nFor this to converge for, say, all bounded functions {{math|''f''}}, it is necessary to require that {{math|ln ''x'' < 0}}. Making the substitution {{math|1=&minus;''s'' = ln ''x''}} gives just the Laplace transform:\n:<math>\\int_{0}^{\\infty} f(t) e^{-st}\\, dt</math>\n\nIn other words, the Laplace transform is a continuous analog of a power series in which the discrete parameter {{math|''n''}} is replaced by the continuous parameter {{math|''t''}}, and {{math|''x''}} is replaced by {{math|''e''<sup>&minus;''s''</sup>}}.\n\n=== Relation to moments ===\n{{main article|Moment generating function}}\nThe quantities\n:<math>\\mu_n = \\int_0^\\infty t^nf(t)\\, dt</math>\n\nare the ''moments'' of the function {{math|''f''}}.  If the first {{math|''n''}} moments of {{math|''f''}} converge absolutely, then by repeated [[differentiation under the integral]], \n:<math>(-1)^n(\\mathcal L f)^{(n)}(0) = \\mu_n .</math>\nThis is of special significance in probability theory, where the moments of a random variable {{math|''X''}} are given by the expectation values <math>\\mu_n=\\operatorname{E}[X^n]</math>.  Then, the relation holds\n:<math>\\mu_n = (-1)^n\\frac{d^n}{ds^n}\\operatorname{E}\\left[e^{-sX}\\right](0).</math>\n\n=== Proof of the Laplace transform of a function's derivative ===\nIt is often convenient to use the differentiation property of the Laplace transform to find the transform of a function's derivative.  This can be derived from the basic expression for a Laplace transform as follows:\n\n: <math>\\begin{align}\n  \\mathcal{L} \\left\\{f(t)\\right\\} &= \\int_{0^-}^\\infty e^{-st} f(t)\\, dt \\\\[6pt]\n                                  &= \\left[\\frac{f(t)e^{-st}}{-s} \\right]_{0^-}^\\infty -\n                                       \\int_{0^-}^\\infty \\frac{e^{-st}}{-s} f'(t) \\, dt\\quad \\text{(by parts)} \\\\[6pt]\n                                  &= \\left[-\\frac{f(0^+)}{-s}\\right] + \\frac 1 s \\mathcal{L} \\left\\{f'(t)\\right\\},\n\\end{align}</math>\n\nyielding\n\n: <math>\\mathcal{L} \\{ f'(t) \\} = s\\cdot\\mathcal{L} \\{ f(t) \\}-f(0^+), </math>\n\nand in the bilateral case,\n\n: <math> \\mathcal{L} \\{ f'(t) \\} = s \\int_{-\\infty}^\\infty e^{-st} f(t)\\,dt  = s \\cdot \\mathcal{L} \\{ f(t) \\}. </math>\n\nThe general result\n\n: <math>\\mathcal{L} \\left\\{ f^{(n)}(t) \\right\\} = s^n \\cdot \\mathcal{L} \\{ f(t) \\} - s^{n - 1} f(0^+) - \\cdots - f^{(n - 1)}(0^+),</math>\n\nwhere <math>f^{(n)}</math> denotes the {{math|''n''}}<sup>th</sup> derivative of {{math|''f''}}, can then be established with an inductive argument.\n\n=== Evaluating integrals over the positive real axis ===\nA useful property of the Laplace transform is the following:\n\n: <math>\\int_0^\\infty f(x)g(x)\\,dx = \\int_0^\\infty(\\mathcal{L} f)(s)\\cdot(\\mathcal{L}^{-1}g)(s)\\,ds </math>\n\nunder suitable assumptions on the behaviour of <math>f,g</math> in a right neighbourhood of <math>0</math> and on the decay rate of <math>f,g</math> in a left neighbourhood of <math>\\infty</math>. The above formula is a variation of integration by parts, with the operators \n<math>\\frac{d}{dx}</math> and <math>\\int \\,dx</math> being replaced by <math>\\mathcal{L}</math> and <math>\\mathcal{L}^{-1}</math>. Let us prove the equivalent formulation:\n\n: <math>\\int_0^\\infty(\\mathcal{L} f)(x)g(x)\\,dx = \\int_0^\\infty f(s)(\\mathcal{L}g)(s)\\,ds. </math>\n\nBy plugging in <math>(\\mathcal{L}f)(x)=\\int_0^\\infty f(s)e^{-sx}\\,ds</math> the left-hand side turns into:\n\n: <math>\\int_0^\\infty\\int_0^\\infty f(s)g(x) e^{-sx}\\,ds\\,dx, </math>\n\nbut assuming Fubini's theorem holds, by reversing the order of integration we get the wanted right-hand side.\n\n=== Relationship to other transforms ===\n\n==== Laplace\u2013Stieltjes transform ====\nThe (unilateral) Laplace\u2013Stieltjes transform of a function {{math|''g'' : '''R''' \u2192 '''R'''}} is defined by the [[Lebesgue\u2013Stieltjes integral]]\n\n: <math>\\{\\mathcal{L}^*g\\}(s) = \\int_0^\\infty e^{-st} \\, dg(t).</math>\n\nThe function {{math|''g''}} is assumed to be of [[bounded variation]].  If {{math|''g''}} is the [[antiderivative]] of {{math|''f''}}:\n\n: <math>g(x) = \\int_0^x f(t)\\,dt</math>\n\nthen the Laplace\u2013Stieltjes transform of {{math|''g''}} and the Laplace transform of {{math|''f''}} coincide.  In general, the Laplace\u2013Stieltjes transform is the Laplace transform of the [[Stieltjes measure]] associated to {{math|''g''}}.  So in practice, the only distinction between the two transforms is that the Laplace transform is thought of as operating on the density function of the measure, whereas the Laplace\u2013Stieltjes transform is thought of as operating on its [[cumulative distribution function]].<ref>{{harvnb|Feller|1971|p=432}}</ref>\n\n==== Fourier transform ====\n{{Main|Fourier transform}}\nThe continuous Fourier transform is equivalent to evaluating the bilateral Laplace transform with imaginary argument {{math|1=''s'' = ''i\u03c9''}} or {{math|1=''s'' = 2''\u03c0fi''}}<ref>{{harvnb|Takacs|1953|p=93}}</ref> when the condition explained below is fulfilled, \n:<math>\\begin{align}\n  \\widehat{f}(\\omega) &= \\mathcal{F}\\{f(t)\\} \\\\[4pt]\n                  &= \\mathcal{L}\\{f(t)\\}|_{s = i\\omega}  =  F(s)|_{s = i \\omega} \\\\[4pt]\n                  &= \\int_{-\\infty}^\\infty e^{-i \\omega t} f(t)\\,dt~.\n\\end{align}</math>\n\nThis definition of the Fourier transform requires a prefactor of {{math|1/(2''\u03c0'')}} on the reverse Fourier transform. This relationship between the Laplace and Fourier transforms is often used to determine the [[frequency spectrum]] of a [[signal (information theory)|signal]] or dynamical system.\n\nThe above relation is valid as stated if and only if the region of convergence (ROC) of  {{math|''F''(''s'')}} contains the imaginary axis,  {{math|1=''\u03c3'' = 0}}.\n\nFor example, the function {{math|1=''f''(''t'') = cos(''\u03c9''<sub>0</sub>''t'')}} has a Laplace transform  {{math|1=''F''(''s'') =  ''s''/(''s''<sup>2</sup> + ''\u03c9''<sub>0</sub><sup>2</sup>)}} whose ROC is {{math|Re(''s'') > 0}}. As {{math|1=''s'' = ''i\u03c9''}} is a pole of  {{math|''F''(''s'')}}, substituting  {{math|1=''s'' = ''i\u03c9''}} in {{math|''F''(''s'')}} does not yield the Fourier transform of  {{math|''f''(''t'')''u''(''t'')}}, which is proportional to the [[Dirac delta-function]] {{math|''\u03b4''(''\u03c9'' \u2212 ''\u03c9''<sub>0</sub>)}}.\n\nHowever, a relation of the form\n: <math>\\lim_{\\sigma\\to 0^+} F(\\sigma+i\\omega) = \\widehat{f}(\\omega)</math>\nholds under much weaker conditions.  For instance, this holds for the above example provided that the limit is understood as a [[weak limit]] of measures (see [[vague topology]]).  General conditions relating the limit of the Laplace transform of a function on the boundary to the Fourier transform take the form of [[Paley\u2013Wiener theorem]]s.\n\n==== Mellin transform ====\n{{Main|Mellin transform}}\nThe Mellin transform and its inverse are related to the two-sided Laplace transform by a simple change of variables.\n\nIf in the Mellin transform\n: <math>G(s) = \\mathcal{M}\\{g(\\theta)\\} = \\int_0^\\infty \\theta^s g(\\theta) \\, \\frac{d\\theta} \\theta </math>\nwe set {{math|1=''\u03b8'' = ''e''<sup>\u2212''t''</sup>}} we get a two-sided Laplace transform.\n\n==== Z-transform ====\n{{Main|Z-transform}}\nThe unilateral or one-sided Z-transform is simply the Laplace transform of an ideally sampled signal with the substitution of\n: <math> z \\stackrel{\\mathrm{def}}{{}={}} e^{sT} ,</math>\nwhere {{math|1=''T'' = 1/''f<sub>s</sub>''}} is the [[Sampling theorem|sampling]] period (in units of time e.g., seconds) and  {{math|''f<sub>s</sub>''}} is the [[sampling rate]] (in [[sample (signal)|samples per second]] or [[hertz]]).\n\nLet\n: <math> \\Delta_T(t) \\ \\stackrel{\\mathrm{def}}{=}\\  \\sum_{n=0}^{\\infty}  \\delta(t - n T) </math>\nbe a sampling impulse train (also called a [[Dirac comb]]) and\n:<math>\\begin{align}\n  x_q(t) \\  &\\stackrel{\\mathrm{def}}{=}\\  x(t) \\Delta_T(t) = x(t) \\sum_{n=0}^{\\infty}  \\delta(t - n T) \\\\\n            &= \\sum_{n=0}^{\\infty} x(n T) \\delta(t - n T) = \\sum_{n=0}^{\\infty} x[n] \\delta(t - n T)\n\\end{align}</math>\nbe the sampled representation of the continuous-time {{math|''x''(''t'')}}\n: <math> x[n] \\stackrel{\\mathrm{def}}{{}={}}  x(nT) ~.</math>\n\nThe Laplace transform of the sampled signal {{math|''x''<sub>''q''</sub>(''t'') }} is\n: <math>\\begin{align}\n  X_q(s) &= \\int_{0^-}^\\infty x_q(t) e^{-s t} \\,dt \\\\\n         &= \\int_{0^-}^\\infty \\sum_{n=0}^\\infty x[n] \\delta(t - n T) e^{-s t} \\, dt \\\\\n         &= \\sum_{n=0}^\\infty x[n] \\int_{0^-}^\\infty \\delta(t - n T) e^{-s t} \\, dt \\\\\n         &= \\sum_{n=0}^\\infty x[n] e^{-n s T}~.\n\\end{align}</math>\n\nThis is the precise definition of the unilateral Z-transform of the discrete function {{math|''x''[''n'']}}\n\n: <math> X(z) = \\sum_{n=0}^{\\infty} x[n] z^{-n} </math>\nwith the substitution of {{math|''z'' \u2192 e<sup>''sT''</sup>}}.\n\nComparing the last two equations, we find the relationship between the unilateral Z-transform and the Laplace transform of the sampled signal,\n: <math>X_q(s) =  X(z) \\Big|_{z=e^{sT}}.</math>\n\nThe similarity between the {{math|''Z''}} and Laplace transforms is expanded upon in the theory of [[time scale calculus]].\n\n==== Borel transform ====\nThe integral form of the [[Borel summation|Borel transform]]\n\n: <math>F(s) = \\int_0^\\infty f(z)e^{-sz}\\, dz</math>\n\nis a special case of the Laplace transform for {{math|''f''}} an [[entire function]] of exponential type, meaning that\n\n: <math>|f(z)|\\le Ae^{B|z|}</math>\n\nfor some constants {{math|''A''}} and {{math|''B''}}.  The generalized Borel transform allows a different weighting function to be used, rather than the exponential function, to transform functions not of exponential type. [[Nachbin's theorem]] gives necessary and sufficient conditions for the Borel transform to be well defined.\n\n==== Fundamental relationships ====\nSince an ordinary Laplace transform can be written as a special case of a two-sided transform, and since the two-sided transform can be written as the sum of two one-sided transforms, the theory of the Laplace-, Fourier-, Mellin-, and Z-transforms are at bottom the same subject. However, a different point of view and different characteristic problems are associated with each of these four major integral transforms.\n\n== Table of selected Laplace transforms ==\n{{main article|List of Laplace transforms}}\n\nThe following table provides Laplace transforms for many common functions of a single variable.<ref>{{Citation |edition=3rd |page=455 |first1=K. F. |last1=Riley |first2=M. P. |last2=Hobson |first3=S. J. |last3=Bence |title=Mathematical methods for physics and engineering |publisher=Cambridge University Press |year=2010 |isbn=978-0-521-86153-3}}</ref><ref>{{Citation |first1=J. J. |last1=Distefano |first2=A. R. |last2=Stubberud |first3=I. J. |last3=Williams |page=78 |title=Feedback systems and control |edition=2nd |publisher=McGraw-Hill |series=Schaum's outlines |year=1995 |isbn=978-0-07-017052-0}}</ref> For definitions and explanations, see the ''Explanatory Notes'' at the end of the table.\n\nBecause the Laplace transform is a linear operator,\n\n* The Laplace transform of a sum is the sum of Laplace transforms of each term.\n\n:: <math>\\mathcal{L}\\{f(t) + g(t)\\}  = \\mathcal{L}\\{f(t)\\} + \\mathcal{L}\\{ g(t)\\}  </math>\n\n* The Laplace transform of a multiple of a function is that multiple times the Laplace transformation of that function.\n\n:: <math>\\mathcal{L}\\{a f(t)\\}  = a \\mathcal{L}\\{ f(t)\\}</math>\n\nUsing this linearity, and various [[List of trigonometric identities|trigonometric]], [[Hyperbolic function|hyperbolic]], and complex number (etc.) properties and/or identities, some Laplace transforms can be obtained from others more quickly than by using the definition directly.\n\nThe unilateral Laplace transform takes as input a function whose time domain is the [[non-negative]] reals, which is why all of the time domain functions in the table below are multiples of the Heaviside step function, {{math|''u''(''t'')}}.\n\nThe entries of the table that involve a time delay {{math|''\u03c4''}} are required to be [[causal system|causal]] (meaning that {{math|''\u03c4'' > 0}}).  A causal system is a system where the [[impulse response]] {{math|''h''(''t'')}} is zero for all time {{mvar|t}} prior to {{math|1=''t'' = 0}}. In general, the region of convergence for causal systems is not the same as that of [[anticausal system]]s.\n\n{| class=\"wikitable\"\n|-\n! Function\n! Time domain <br> <math>f(t) = \\mathcal{L}^{-1}\\{F(s)\\}</math> \n! Laplace {{math|s}}-domain <br> <math>F(s) = \\mathcal{L}\\{f(t)\\}</math> \n! Region of convergence \n! Reference\n\n|- style=\"text-align:center;\"\n| unit impulse\n|| <math> \\delta(t) \\ </math> \n|| <math> 1  </math> \n|| all {{math|''s''}}\n|| inspection\n\n|- style=\"text-align:center;\"\n| delayed impulse \n|| <math> \\delta(t - \\tau) \\ </math> \n|| <math> e^{-\\tau s} \\ </math> \n|| \n|| time shift of<br>unit impulse\n\n|- style=\"text-align:center;\"\n| unit step\n|| <math> u(t) \\ </math> \n|| <math> { 1 \\over s } </math> \n|| {{math|Re(''s'') > 0}}\n|| integrate unit impulse\n\n|- style=\"text-align:center;\"\n| delayed unit step \n|| <math> u(t - \\tau) \\ </math> \n|| <math> \\frac 1 s e^{-\\tau s} </math> \n|| {{math|Re(''s'') > 0}} \n|| time shift of<br>unit step\n\n|- style=\"text-align:center;\"\n| [[ramp function|ramp]] \n|| <math> t \\cdot u(t)\\ </math> \n|| <math>\\frac 1 {s^2}</math> \n|| {{math|Re(''s'') > 0}}\n|| integrate unit<br>impulse twice\n\n|- style=\"text-align:center;\"\n| {{math|''n''}}th power <br /> (for integer {{math|''n''}}) \n|| <math> t^n \\cdot u(t) </math> \n|| <math> { n! \\over s^{n + 1} } </math> \n|| {{math|Re(''s'') > 0}}   <br /> ({{math|''n'' > \u22121}})\n|| Integrate unit<br>step {{math|''n''}} times\n\n|- style=\"text-align:center;\"\n| {{math|''q''}}th power <br /> (for complex {{math|''q''}}) \n|| <math> t^q \\cdot u(t) </math> \n|| <math> { \\Gamma(q + 1) \\over s^{q + 1} } </math> \n|| {{math|Re(''s'') > 0}} <br /> {{math|Re(''q'') > \u22121}} \n||<ref>{{citation |title=Mathematical Handbook of Formulas and Tables |edition=3rd |first1=S. |last1=Lipschutz |first2=M. R. |last2=Spiegel |first3=J. |last3=Liu |series=Schaum's Outline Series |publisher=McGraw-Hill |page=183 |year=2009 |isbn=978-0-07-154855-7}} \u2013 provides the case for real {{math|''q''}}.</ref><ref>http://mathworld.wolfram.com/LaplaceTransform.html \u2013 Wolfram Mathword provides case for complex {{math|''q''}}</ref>\n\n|- style=\"text-align:center;\"\n| {{math|''n''}}th root \n|| <math> \\sqrt[n]{t} \\cdot u(t) </math> \n|| <math> { 1 \\over s^{\\frac 1 n + 1} } \\Gamma\\left(\\frac 1 n + 1\\right) </math> \n|| {{math|Re(''s'') > 0}} \n|| Set {{math|1=''q'' = 1/''n''}} above.\n\n|- style=\"text-align:center;\"\n| {{math|''n''}}th power with frequency shift \n|| <math>t^{n} e^{-\\alpha t} \\cdot u(t) </math> \n|| <math>\\frac{n!}{(s+\\alpha)^{n+1}}</math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}}\n|| Integrate unit step,<br>apply frequency shift\n\n|- style=\"text-align:center;\"\n| delayed {{math|''n''}}th power <br /> with frequency shift \n|| <math>(t-\\tau)^n e^{-\\alpha (t-\\tau)} \\cdot u(t-\\tau) </math> \n|| <math> \\frac{n! \\cdot e^{-\\tau s}}{(s+\\alpha)^{n+1}} </math>\n|| {{math|Re(''s'') > \u2212''\u03b1''}} \n|| Integrate unit step,<br>apply frequency shift,<br>apply time shift\n\n|- style=\"text-align:center;\"\n| [[exponential decay]] \n|| <math> e^{-\\alpha t} \\cdot u(t)   </math> \n|| <math> { 1 \\over s+\\alpha } </math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}}\n|| Frequency shift of<br>unit step\n\n|- style=\"text-align:center;\"\n| [[Two-sided Laplace transform|two-sided]] exponential decay <br>(only for bilateral transform)\n|| <math> e^{-\\alpha|t|}  \\ </math> \n|| <math> { 2\\alpha \\over \\alpha^2 - s^2 } </math> \n|| {{math|\u2212''\u03b1'' < Re(''s'') < ''\u03b1''}} \n|| Frequency shift of<br>unit step\n\n|- style=\"text-align:center;\"\n| exponential approach \n|| <math>( 1-e^{-\\alpha t})  \\cdot u(t)  \\ </math> \n|| <math>\\frac{\\alpha}{s(s+\\alpha)} </math> \n|| {{math|Re(''s'') > 0}}\n|| Unit step minus<br>exponential decay\n\n|- style=\"text-align:center;\"\n| [[sine]] \n|| <math> \\sin(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { \\omega \\over s^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > 0}}\n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| [[cosine]] \n|| <math> \\cos(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { s \\over s^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > 0}}\n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| [[hyperbolic sine]] \n|| <math> \\sinh(\\alpha t) \\cdot u(t) \\ </math> \n|| <math> { \\alpha \\over s^2 - \\alpha^2 } </math> \n|| {{math|Re(''s'') > {{abs|''\u03b1''}}}} \n|| {{Harvnb|Williams|1973|p=88}}\n\n|- style=\"text-align:center;\"\n| [[hyperbolic cosine]] \n|| <math> \\cosh(\\alpha t) \\cdot u(t) \\ </math> \n|| <math> { s \\over s^2 - \\alpha^2  } </math> \n|| {{math|Re(''s'') > {{abs|''\u03b1''}}}}\n|| {{Harvnb|Williams|1973|p=88}}\n\n|- style=\"text-align:center;\"\n| exponentially decaying <br /> sine wave \n|| <math>e^{-\\alpha t}  \\sin(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { \\omega \\over (s+\\alpha )^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}} \n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| exponentially decaying <br /> cosine wave \n|| <math>e^{-\\alpha t}  \\cos(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { s+\\alpha \\over (s+\\alpha )^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}}\n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| [[natural logarithm]] \n|| <math> \\ln (t) \\cdot u(t) </math> \n|| <math> - { 1 \\over s}\\, \\left[ \\ln(s)+\\gamma \\right] </math> \n|| {{math|Re(''s'') > 0}} \n|| {{Harvnb|Williams|1973|p=88}}\n\n|- style=\"text-align:center;\"\n| [[Bessel function]] <br> of the first kind, <br /> of order ''n'' \n|| <math> J_n( \\omega t) \\cdot u(t)</math> \n|| <math>\\frac{ \\left(\\sqrt{s^2+ \\omega^2}-s\\right)^n}{\\omega^n \\sqrt{s^2 + \\omega^2}}</math> \n|| {{math|Re(''s'') > 0}}   <br /> ({{math|''n'' > \u22121}}) \n|| {{Harvnb|Williams|1973|p=89}}\n\n|- style=\"text-align:center;\"\n| [[Error function]] \n|| <math> \\operatorname{erf}(t) \\cdot u(t) </math> \n|| <math> \\frac 1 s e^{(1/4)s^2} \\left(1 - \\operatorname{erf} \\frac s 2 \\right)</math> \n|| {{math|Re(''s'') > 0}}\n|| {{Harvnb|Williams|1973|p=89}}\n\n|-\n| colspan=5|'''Explanatory notes:'''\n{{col-begin}}\n{{col-break}}\n\n* {{math|''u''(''t'')}} represents the [[Heaviside step function]].\n* {{math|''\u03b4''}}  represents the [[Dirac delta function]].\n* {{math|\u0393(''z'')}} represents the [[gamma function]].\n* {{math|''\u03b3''}} is the [[Euler&ndash;Mascheroni constant]].\n\n{{col-break}}\n\n*  {{math|''t''}}, a real number, typically represents ''time'', <br />although it can represent ''any'' independent dimension.\n*  {{math|''s''}} is the [[complex number|complex]] frequency domain parameter, and  {{math|Re(''s'')}} is its [[real part]].\n*  {{math|''\u03b1'', ''\u03b2'', ''\u03c4,'' and ''\u03c9''}} are [[real numbers]].\n*  {{math|''n''}} is an [[integer]].\n\n{{col-end}}\n|}\n\n== ''s''-domain equivalent circuits and impedances ==\nThe Laplace transform is often used in circuit analysis, and simple conversions to the {{math|''s''}}-domain of circuit elements can be made. Circuit elements can be transformed into [[Electrical impedance|impedance]]s, very similar to [[Phasor (sine waves)|phasor]] impedances.\n\nHere is a summary of equivalents:\n\n: [[File:S-Domain circuit equivalents.svg|alt={{math|''s''}}-domain equivalent circuits|centre|frameless|400x400px|{{math|''s''}}-domain equivalent circuits]]\n\nNote that the resistor is exactly the same in the time domain and the {{math|''s''}}-domain. The sources are put in if there are initial conditions on the circuit elements. For example, if a capacitor has an initial voltage across it, or if the inductor has an initial current through it, the sources inserted in the {{math|''s''}}-domain account for that.\n\nThe equivalents for current and voltage sources are simply derived from the transformations in the table above.\n\n== Examples and applications ==\n<!--A few worked examples are provided here to enable the reader to assess comprehension of the factual presentation.  Elaboration beyond the role of supporting factual comprehension belongs at [[v:|Wikiversity]] or [[b:|Wikibooks]].-->\n\nThe Laplace transform is used frequently in [[engineering]] and [[physics]]; the output of a [[linear time-invariant]] system can be calculated by convolving its unit impulse response with the input signal. Performing this calculation in Laplace space turns the convolution into a multiplication; the latter being easier to solve because of its algebraic form. For more information, see [[control theory]].\n\nThe Laplace transform can also be used to solve differential equations and is used extensively in [[mechanical engineering]] and [[electrical engineering]].  The Laplace transform reduces a linear differential equation to an algebraic equation, which can then be solved by the formal rules of algebra.  The original differential equation can then be solved by applying the inverse Laplace transform.  The English electrical engineer Oliver Heaviside first proposed a similar scheme, although without using the Laplace transform; and the resulting operational calculus is credited as the Heaviside calculus.\n\n=== Evaluating improper integrals ===\nLet <math>\\mathcal{L}\\left\\{f(t)\\right\\} = F(s)</math>, then (see the table above)\n\n: <math>\\mathcal{L} \\left\\{\\frac{f(t)} t \\right\\} = \\int_s^\\infty F(p)\\, dp,</math>\n\nor\n\n: <math>\\int_0^\\infty \\frac{f(t)}{t}e^{-st}\\, dt = \\int_s^\\infty F(p)\\, dp.</math>\n\nLetting {{math|''s'' \u2192 0}}, gives one the identity\n\n: <math>\\int_0^\\infty \\frac{f(t)} t \\, dt = \\int_0^\\infty F(p)\\, dp.</math>\n\nprovided that the interchange of limits can be justified. Even when the interchange cannot be justified the calculation can be suggestive. For example, with ''a''&nbsp;\u2260&nbsp;0&nbsp;\u2260&nbsp;''b'', proceeding formally one has\n\n: <math>\n\\begin{align}\n& \\int_0^\\infty \\frac 1 t ( \\cos(at) - \\cos(bt) )\\, dt =\n  \\int_0^\\infty \\left(\\frac p {p^2 + a^2} - \\frac{p}{p^2 + b^2}\\right)\\, dp \\\\[6pt]\n= {} & \\frac 1 2 \\left. \\ln\\frac{p^2 + a^2}{p^2 + b^2} \\right|_{p\\,:=\\,0}^\\infty = \\ln|b| - \\ln |a|.\n\\end{align}\n</math>\n\nThe validity of this identity can be proved by other means. It is an example of a [[Frullani integral]].\n\nAnother example is [[Dirichlet integral]].\n\n=== Nuclear physics ===\nIn [[nuclear physics]], the following fundamental relationship governs [[radioactive decay]]: the number of radioactive atoms {{math|''N''}} in a sample of a radioactive [[isotope]] decays at a rate proportional to {{math|''N''}}.  This leads to the first order linear differential equation\n\n: <math>\\frac{dN}{dt} = -\\lambda N,</math>\n\nwhere {{math|''\u03bb''}} is the [[decay constant]]. The Laplace transform can be used to solve this equation.\n\nRearranging the equation to one side, we have\n\n: <math>\\frac{dN}{dt} + \\lambda N = 0.</math>\n\nNext, we take the Laplace transform of both sides of the equation:\n\n: <math>\\left( s \\widetilde{N}(s) - N_0 \\right) + \\lambda \\widetilde{N}(s) = 0,</math>\n\nwhere\n\n: <math>\\widetilde{N}(s) = \\mathcal{L}\\{N(t)\\}</math>\n\nand\n\n: <math>N_0 = N(0).</math>\n\nSolving, we find\n\n: <math>\\widetilde{N}(s) = \\frac{N_0}{s + \\lambda}.</math>\n\nFinally, we take the inverse Laplace transform to find the general solution\n\n: <math>\\begin{align}\n  N(t) &= \\mathcal{L}^{-1} \\{\\widetilde{N}(s)\\} = \\mathcal{L}^{-1}\\! \\left\\{ \\frac{N_0}{s + \\lambda} \\right\\}\\\\\n       &= \\ N_0 e^{-\\lambda t},\n\\end{align}</math>\n\nwhich is indeed the correct form for radioactive decay.\n\n=== Complex impedance of a capacitor ===\nIn the theory of [[electrical circuit]]s, the current flow in a [[capacitor]] is proportional to the capacitance and rate of change in the electrical potential (in [[International System of Units|SI]] units). Symbolically, this is expressed by the differential equation\n\n: <math>i = C { dv \\over dt} ,</math>\n\nwhere {{math|''C''}} is the capacitance (in [[farad]]s) of the capacitor, {{math|1=''i'' = ''i''(''t'')}} is the [[electric current]] (in [[ampere]]s) through the capacitor as a function of time, and {{math|1=''v'' = ''v''(''t'')}} is the [[electrostatic potential|voltage]] (in [[volt]]s) across the terminals of the capacitor, also as a function of time.\n\nTaking the Laplace transform of this equation, we obtain\n\n: <math>I(s) = C(s V(s) - V_0),</math>\n\nwhere\n\n: <math>\\begin{align}\n  I(s) &= \\mathcal{L} \\{ i(t) \\},\\\\\n  V(s) &= \\mathcal{L} \\{ v(t) \\},\n\\end{align}</math>\n\nand\n\n: <math>V_0 = v(t)\\Big|_{t=0}. \\, </math>\n\nSolving for {{math|''V''(''s'')}} we have\n\n: <math>V(s) = { I(s) \\over sC } + { V_0 \\over s }.</math>\n\nThe definition of the complex impedance {{math|''Z''}} (in [[ohm]]s) is the ratio of the complex voltage {{math|''V''}} divided by the complex current {{math|''I''}} while holding the initial state {{math|''V''<sub>0</sub>}} at zero:\n\n: <math>Z(s) = \\left. { V(s) \\over I(s) } \\right|_{V_0 = 0}.</math>\n\nUsing this definition and the previous equation, we find:\n\n: <math>Z(s) = \\frac{1}{sC}, </math>\n\nwhich is the correct expression for the complex impedance of a capacitor. \nIn addition, the Laplace transform has large applications in control theory.\n\n=== Partial fraction expansion ===\n<!-- [[Partial fractions in Laplace transforms]] redirect here -->\nConsider a linear time-invariant system with [[transfer function]]\n: <math>H(s) = \\frac{1}{(s + \\alpha)(s + \\beta)}.</math>\n\nThe [[impulse response]] is simply the inverse Laplace transform of this transfer function:\n: <math>h(t) = \\mathcal{L}^{-1}\\{H(s)\\}.</math>\n\nTo evaluate this inverse transform, we begin by expanding {{math|''H''(''s'')}} using the method of partial fraction expansion,\n\n: <math>\\frac{1}{(s + \\alpha)(s + \\beta)} = { P \\over s + \\alpha } + { R \\over s+\\beta }.</math>\n\nThe unknown constants {{math|''P''}} and {{math|''R''}} are the [[residue (complex analysis)|residue]]s located at the corresponding poles of the transfer function. Each residue represents the relative contribution of that [[mathematical singularity|singularity]] to the transfer function's overall shape.\n\nBy the [[residue theorem]], the inverse Laplace transform depends only upon the poles and their residues. To find the residue {{math|''P''}}, we multiply both sides of the equation by {{math|''s'' + ''\u03b1''}} to get\n: <math>\\frac{1}{s + \\beta} = P  + { R (s + \\alpha) \\over s + \\beta }.</math>\n\nThen by letting {{math|1=''s'' = \u2212''\u03b1''}}, the contribution from {{math|''R''}} vanishes and all that is left is\n: <math>P = \\left.{1 \\over s+\\beta}\\right|_{s=-\\alpha} = {1 \\over \\beta - \\alpha}.</math>\n\nSimilarly, the residue {{math|''R''}} is given by\n: <math>R = \\left.{1 \\over s + \\alpha}\\right|_{s=-\\beta} = {1 \\over \\alpha - \\beta}.</math>\n\nNote that\n: <math>R = {-1 \\over \\beta - \\alpha} = - P</math>\nand so the substitution of {{math|''R''}} and {{math|''P''}} into the expanded expression for {{math|''H''(''s'')}} gives\n: <math>H(s)  = \\left( \\frac{1}{\\beta - \\alpha} \\right) \\cdot \\left(  { 1 \\over s + \\alpha } - { 1  \\over s + \\beta }  \\right).</math>\n\nFinally, using the linearity property and the known transform for exponential decay (see ''Item'' #''3'' in the ''Table of Laplace Transforms'', above), we can take the inverse Laplace transform of {{math|''H''(''s'')}} to obtain\n: <math>h(t) = \\mathcal{L}^{-1}\\{H(s)\\} = \\frac{1}{\\beta - \\alpha}\\left(e^{-\\alpha t} - e^{-\\beta t}\\right),</math>\nwhich is the impulse response of the system.\n\n;Convolution\nThe same result can be achieved using the [[Convolution theorem|convolution property]] as if the system is a series of filters with transfer functions of {{math|1/(''s'' + ''a'')}} and {{math|1/(''s'' + ''b'')}}. That is, the inverse of\n\n: <math>H(s) = \\frac{1}{(s + a)(s + b)} = \\frac{1}{s+a} \\cdot \\frac{1}{s + b}</math>\n\nis\n\n: <math> \\mathcal{L}^{-1}\\! \\left\\{ \\frac{1}{s + a} \\right\\} * \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s + b} \\right\\} = e^{-at} * e^{-bt} = \\int_0^t e^{-ax}e^{-b(t - x)}\\, dx = \\frac{e^{-a t}-e^{-b t}}{b - a}.</math>\n\n=== Phase delay ===\n{| class=\"wikitable\"\n|-\n! Time function\n! Laplace transform\n|-\n| <math>\\sin{(\\omega t + \\varphi)}</math>\n| <math>\\frac{s\\sin(\\varphi) + \\omega \\cos(\\varphi)}{s^2 + \\omega^2}</math>\n|-\n| <math>\\cos{(\\omega t + \\varphi)}</math>\n| <math>\\frac{s\\cos(\\varphi) - \\omega \\sin(\\varphi)}{s^2 + \\omega^2}.</math>\n|}\n\nStarting with the Laplace transform,\n\n: <math>X(s) = \\frac{s\\sin(\\varphi) + \\omega \\cos(\\varphi)}{s^2 + \\omega^2}</math>\n\nwe find the inverse by first rearranging terms in the fraction:\n\n: <math>\\begin{align}\n  X(s) &= \\frac{s \\sin(\\varphi)}{s^2 + \\omega^2} + \\frac{\\omega \\cos(\\varphi)}{s^2 + \\omega^2} \\\\\n       &= \\sin(\\varphi) \\left(\\frac{s}{s^2 + \\omega^2} \\right) + \\cos(\\varphi) \\left(\\frac{\\omega}{s^2 + \\omega^2} \\right).\n\\end{align}</math>\n\nWe are now able to take the inverse Laplace transform of our terms:\n\n: <math>\\begin{align}\n  x(t) &= \\sin(\\varphi) \\mathcal{L}^{-1}\\left\\{\\frac{s}{s^2 + \\omega^2} \\right\\} + \\cos(\\varphi) \\mathcal{L}^{-1}\\left\\{\\frac{\\omega}{s^2 + \\omega^2} \\right\\} \\\\\n       &= \\sin(\\varphi)\\cos(\\omega t) + \\sin(\\omega t)\\cos(\\varphi).\n\\end{align}</math>\n\nThis is just the [[Trigonometric identity#Angle sum and difference identities|sine of the sum]] of the arguments, yielding:\n\n:<math>x(t) = \\sin (\\omega t + \\varphi).</math>\n\nWe can apply similar logic to find that\n\n: <math>\\mathcal{L}^{-1} \\left\\{ \\frac{s\\cos\\varphi - \\omega \\sin\\varphi}{s^2 + \\omega^2} \\right\\} = \\cos{(\\omega t + \\varphi)}.</math>\n\n=== {{Anchor|Inferring spatial structure from spectrum}}Determining structure of astronomical object from spectrum ===\nThe wide and general applicability of the Laplace transform and its inverse is illustrated by an application in astronomy which provides some information on the ''spatial distribution'' of matter of an [[Astronomy|astronomical]] source of [[Radio frequency|radio-frequency]] [[thermal radiation]] too distant to [[Angular resolution|resolve]] as more than a point, given its [[flux density]] [[spectrum]], rather than relating the ''time'' domain with the spectrum (frequency domain).\n\nAssuming certain properties of the object, e.g. spherical shape and constant temperature, calculations based on carrying out an inverse Laplace transformation on the spectrum of the object can produce the only possible [[Mathematical model|model]] of the distribution of matter in it (density as a function of distance from the center) consistent with the spectrum.<ref>{{citation |first1=M. |last1=Salem |first2=M. J. |last2=Seaton |year=1974 |title=I. Continuum spectra and brightness contours |journal=[[Monthly Notices of the Royal Astronomical Society]] |volume=167 |issue=3 |pages=493\u2013510 |doi=10.1093/mnras/167.3.493 |bibcode=1974MNRAS.167..493S}}, and<br/>{{citation |first1=M. |last1=Salem |year=1974 |title=II. Three-dimensional models |journal=Monthly Notices of the Royal Astronomical Society |volume=167 |issue=3 |pages=511\u2013516 |doi=10.1093/mnras/167.3.511 |bibcode=1974MNRAS.167..511S}}</ref> When independent information on the structure of an object is available, the inverse Laplace transform method has been found to be in good agreement.\n\n=== Statistical mechanics ===\nIn [[statistical mechanics]], the Laplace transform of the density of states <math>g(E)dE</math> defines the [[partition function (statistical mechanics)|partition function]].<ref>{{cite book|author1=RK Pathria|author2=Paul Beal|title=Statistical mechanics|edition=2nd|publisher=Butterworth-Heinemann|year=1996|page=56}}</ref> That is, the partition function <math>Z(\\beta)</math> is given by\n:<math> Z(\\beta) = \\int_0^\\infty e^{-\\beta E}g(E)dE</math>\nand the inverse is given by\n:<math> g(E) = \\frac{1}{2\\pi i} \\int_{\\beta_0-i\\infty}^{\\beta_0+i\\infty} e^{\\beta E}Z(\\beta) d\\beta</math>\n\n== See also ==\n{{div col}}\n* [[Analog signal processing]]\n* [[Bernstein's theorem on monotone functions]]\n* [[Continuous-repayment mortgage#Mortgage difference and differential equation|Continuous-repayment mortgage]]\n* [[Hamburger moment problem]]\n* [[Hardy\u2013Littlewood tauberian theorem]]\n* [[Laplace\u2013Carson transform]]\n* [[Moment-generating function]]\n* [[Nonlocal operator]]\n* [[Pierre-Simon Laplace]]\n* [[Post's inversion formula]]\n* [[Signal-flow graph]]\n* [[Symbolic integration]]\n* [[Transfer function]]\n{{div col end}}\n\n== Notes ==\n{{Reflist|30em}}\n\n== References ==\n\n=== Modern ===\n* {{Citation |last=Bracewell |first=Ronald N. |title=The Fourier Transform and its Applications |edition=2nd |year=1978 |publisher=McGraw-Hill Kogakusha |isbn=978-0-07-007013-4 }}<!-- This edition is used for pinpoint citations in the transform table. -->\n* {{citation|first=R. N.|last=Bracewell|title=The Fourier Transform and Its Applications|edition=3rd|location=Boston|publisher=McGraw-Hill|year=2000|isbn=978-0-07-116043-8}}\n* {{Citation | last1=Feller | first1=William | author1-link=William Feller | title=An introduction to probability theory and its applications. Vol. II. | publisher=[[John Wiley & Sons]] | location=New York | series=Second edition | mr=0270403  | year=1971}}\n* {{citation |first1=G. A. |last1=Korn |first2=T. M. |last2=Korn |title=Mathematical Handbook for Scientists and Engineers |publisher=McGraw-Hill Companies |edition=2nd |year=1967 |isbn=978-0-07-035370-1 }}\n* {{Citation | last1=Widder | first1=David Vernon | title=The Laplace Transform | publisher=[[Princeton University Press]] | series=Princeton Mathematical Series, v. 6 | mr=0005923  | year=1941}}\n* {{Citation | last=Williams |first=J. |title=Laplace Transforms |series=Problem Solvers |volume= |publisher=George Allen & Unwin |year=1973 |isbn= 978-0-04-512021-5 }}\n* {{Citation | last=Takacs | first= J.|title=Fourier amplitudok meghatarozasa operatorszamitassal | year=1953 | journal=Magyar Hiradastechnika | volume=IV | issue=7\u20138|pages=93\u201396 |language=Hungarian }}\n\n=== Historical ===\n<!-- Citations to Opera omnia [The Complete Works] are wrong. Opera omnia was published 1911 and after, so the citations should be |origyear=17xx |year=1992... Handling of Euler's volume number and Opera omnia volume is problematic -->\n* {{citation |last=Euler |first=L. |authorlink=Leonhard Euler |year=1744 |title=De constructione aequationum |trans-title=The Construction of Equations |language=la |journal=Opera Omnia |series=1st series |volume=22 |pages=150\u2013161}}\n* {{citation |last=Euler |first=L. |authorlink=Leonhard Euler |year=1753 |title=Methodus aequationes differentiales |trans-title=A Method for Solving Differential Equations |language=la |journal=Opera Omnia |series=1st series |volume=22 |pages=181\u2013213}}\n* {{citation |last=Euler |first=L. |authorlink=Leonhard Euler |origyear=1769 |title=Institutiones calculi integralis, Volume 2 |trans-title=Institutions of Integral Calculus |language=la |journal=Opera Omnia |series=1st series |volume=12 |year=1992 |location=Basel |publisher=Birkh\u00e4user |isbn=978-3764314743 <!-- isbn for the entire first series-->}}, Chapters 3\u20135\n* {{citation |last=Euler |first=Leonhard |authorlink=Leonhard Euler |year=1769 |title=Institutiones calculi integralis |trans-title=Institutions of Integral Calculus |language=la |volume=II <!--Secundum--> |at=ch. 3\u20135, pp. 57\u2013153 |location=Paris |publisher=Petropoli |url=https://books.google.com/books?id=BFqWNwpfqo8C }}\n* {{citation|last=Grattan-Guinness|first=I|authorlink=Ivor Grattan-Guinness|year=1997|contribution=Laplace's integral solutions to partial differential equations|editor=Gillispie, C. C.|title=Pierre Simon Laplace 1749\u20131827: A Life in Exact Science|location=Princeton|publisher=Princeton University Press|isbn=978-0-691-01185-1}}\n* {{citation|last=Lagrange|first=J. L.|authorlink=Joseph Louis Lagrange|year=1773|title=M\u00e9moire sur l'utilit\u00e9 de la m\u00e9thode|series=\u0152uvres de Lagrange|volume=2|pages=171\u2013234}}\n\n==Further reading==\n* {{citation|first1=Wolfgang|last1=Arendt|first2=Charles J.K.|last2=Batty|first3=Matthias|last3=Hieber|first4=Frank|last4=Neubrander|title=Vector-Valued Laplace Transforms and Cauchy Problems|publisher=Birkh\u00e4user Basel|year=2002|isbn=978-3-7643-6549-3 |ref=none}}.\n* {{citation|last=Davies|first=Brian|title=Integral transforms and their applications|edition=Third|publisher=Springer|location=New York|year=2002|isbn= 978-0-387-95314-4 |ref=none}}\n* {{citation | last=Deakin|first= M. A. B. | year=1981 | title=The development of the Laplace transform | journal=Archive for History of Exact Sciences | volume=25 | pages=343\u2013390 | doi=10.1007/BF01395660 | issue=4 |ref=none}}\n* {{citation | last=Deakin|first= M. A. B. | year=1982 | title=The development of the Laplace transform | journal=Archive for History of Exact Sciences | volume=26 | pages=351\u2013381 | doi=10.1007/BF00418754 | issue=4 |ref=none}}\n* {{citation |last=Doetsch |first=Gustav |authorlink=Gustav Doetsch |date=1974 |title=Introduction to the Theory and Application of the Laplace Transformation |publisher=Springer |isbn=978-0-387-06407-9 |ref=none}}\n* Mathews, Jon; Walker, Robert L. (1970), ''Mathematical methods of physics'' (2nd ed.), New York: W. A. Benjamin, {{isbn|0-8053-7002-1}}\n* {{citation|first1=A. D.|last1=Polyanin|first2=A. V.|last2=Manzhirov|title=Handbook of Integral Equations|publisher=CRC Press|location=Boca Raton|year=1998|isbn=978-0-8493-2876-3 |ref=none}}\n* {{Citation | last1=Schwartz | first1=Laurent | author-link=Laurent Schwartz | title=Transformation de Laplace des distributions | mr=0052555  | year=1952 | journal=Comm. S\u00e9m. Math. Univ. Lund [Medd. Lunds Univ. Mat. Sem.] | volume=1952 | pages=196\u2013206 |language=French |ref=none}}\n* {{Citation |last=Schwartz |first=Laurent |author-link=Laurent Schwartz |year=2008 |origyear=1966 |title=Mathematics for the Physical Sciences |publisher=Dover Publications |location=New York |series=Dover Books on Mathematics |pages=215\u2013241 |isbn=978-0-486-46662-0 |url={{Google books|-_AuDQAAQBAJ|Mathematics for the Physical Sciences|page=215|plainurl=yes}} |ref=none}} - See Chapter VI. The Laplace transform.\n* {{citation|first=William McC.|last=Siebert|title=Circuits, Signals, and Systems|publisher=MIT Press|location=Cambridge, Massachusetts|year=1986|isbn=978-0-262-19229-3 |ref=none}}\n* {{Citation | last1=Widder | first1=David Vernon | title=What is the Laplace transform? | mr=0013447  | year=1945 | journal=[[American Mathematical Monthly|The American Mathematical Monthly]] | issn=0002-9890 |volume=52 |issue=8 | pages=419\u2013425 | doi=10.2307/2305640 | jstor=2305640 |ref=none}}\n\n== External links ==\n{{wikiquote}}\n{{commons category|Laplace transformation}}\n* {{springer|title=Laplace transform|id=p/l057540}}\n* [http://wims.unice.fr/wims/wims.cgi?lang=en&+module=tool%2Fanalysis%2Ffourierlaplace Online Computation] of the transform or inverse transform, wims.unice.fr\n* [http://eqworld.ipmnet.ru/en/auxiliary/aux-inttrans.htm Tables of Integral Transforms] at EqWorld: The World of Mathematical Equations.\n* {{MathWorld|title=Laplace Transform|urlname=LaplaceTransform}}\n* [http://fourier.eng.hmc.edu/e102/lectures/Laplace_Transform/ Good explanations of the initial and final value theorems]\n* [http://www.mathpages.com/home/kmath508/kmath508.htm Laplace Transforms] at MathPages\n* [http://www.wolframalpha.com/input/?i=laplace+transform+example Computational Knowledge Engine] allows to easily calculate Laplace Transforms and its inverse Transform.\n* [http://www.laplacetransformcalculator.com/easy-laplace-transform-calculator/ Laplace Calculator] to calculate Laplace Transforms online easily.\n* [https://johnflux.com/2019/02/12/laplace-transform-visualized/ Code to visualize Laplace Transforms] and many example videos.\n\n{{Authority control}}\n\n{{DEFAULTSORT:Laplace Transform}}\n[[Category:Laplace transforms| ]]\n[[Category:Differential equations]]\n[[Category:Fourier analysis]]\n[[Category:Mathematical physics]]\n", "name_user": "Barney Stratford", "label": "safe", "comment": "\u2192\u200eTable of selected Laplace transforms:Another similar typo", "url_page": "//en.wikipedia.org/wiki/Laplace_transform"}
