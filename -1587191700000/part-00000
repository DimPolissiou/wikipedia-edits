{"title_page": "Byzantine fault", "text_new": "{{Redirect|Byzantine generals|military generals of the Byzantine empire|Category:Byzantine generals}}\n\nA '''Byzantine fault''' (also '''interactive consistency''', '''source congruency''', '''error avalanche''', '''Byzantine agreement problem''', '''Byzantine generals problem''', and '''Byzantine failure'''<ref>{{cite web| url= http://lamspeople.epfl.ch/kirrmann/Pubs/FaultTolerance/Fault_Tolerance_Tutorial_HK.pdf#page=94| title= Fault Tolerant Computing in Industrial Automation| last1= Kirrmann| first1= Hubert| date= n.d.| publisher= ABB Research Center| location= Switzerland| page= 94| access-date= 2015-03-02| archive-url= https://web.archive.org/web/20140326192930/http://lamspeople.epfl.ch/kirrmann/Pubs/FaultTolerance/Fault_Tolerance_Tutorial_HK.pdf#page=94#page=94| archive-date= 2014-03-26| url-status=dead| df= }}</ref>) is a condition of a computer system, particularly [[distributed computing]] systems, where components may fail and there is imperfect information on whether a component has failed. The term takes its name from an allegory, the \"[[Byzantine Generals Problem]]\",<ref>{{Cite journal | last1 = Lamport | first1 = L. | authorlink1 = Leslie Lamport| last2 = Shostak | first2 = R. | last3 = Pease | first3 = M. | doi = 10.1145/357172.357176 | title = The Byzantine Generals Problem | journal = ACM Transactions on Programming Languages and Systems | volume = 4 | issue = 3 | pages = 382\u2013401 | year = 1982 | url = https://www.microsoft.com/en-us/research/publication/byzantine-generals-problem/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Flamport%2Fpubs%2Fbyz.pdf | url-status=live | archiveurl = https://web.archive.org/web/20180613015025/https://www.microsoft.com/en-us/research/publication/byzantine-generals-problem/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Flamport%2Fpubs%2Fbyz.pdf | archivedate = 13 June 2018| citeseerx = 10.1.1.64.2312 }}</ref> developed to describe a situation in which, in order to avoid catastrophic failure of the system, the system's actors must agree on a concerted strategy, but some of these actors are unreliable.\n\nIn a Byzantine fault, a component such as a [[Server (computing)|server]] can inconsistently appear both failed and functioning to failure-detection systems, presenting different symptoms to different observers. It is difficult for the other components to declare it failed and shut it out of the network, because they need to first reach a [[Consensus (computer science)|consensus]] regarding which component has failed in the first place.\n\nByzantine fault tolerance (BFT) is the dependability of a [[fault-tolerant computer system]] to such conditions.\n\n== Characteristics ==\n\nA Byzantine fault is any fault presenting different symptoms to different observers.<ref name=\"DriscollHall2004\">{{cite book| last1=Driscoll| first1=K.| title=The 23rd Digital Avionics Systems Conference (IEEE Cat. No.04CH37576)| last2=Hall| first2=B.| last3=Paulitsch| first3=M.| last4=Zumsteg| first4=P. |last5=Sivencrona| first5=H.| chapter=The Real Byzantine Generals| year=2004| pages=6.D.4\u201361\u201311| doi=10.1109/DASC.2004.1390734| isbn=978-0-7803-8539-9}}</ref> A Byzantine failure is the loss of a system service due to a Byzantine fault in systems that require [[Consensus (computer science)|consensus]].<ref name=\"DriscollHall2003\">{{cite book| last1=Driscoll| first1=Kevin| title=Computer Safety, Reliability, and Security| last2=Hall| first2=Brendan| last3=Sivencrona| first3=H\u00e5kan| last4=Zumsteg| first4=Phil | chapter=Byzantine Fault Tolerance, from Theory to Reality| volume=2788| year=2003| pages=235\u2013248| issn=0302-9743| doi=10.1007/978-3-540-39878-3_19| series=Lecture Notes in Computer Science| isbn=978-3-540-20126-7| chapter-url=https://semanticscholar.org/paper/88ae63cd7fc1e5892c8015e70246632bf22f4dd1}}</ref>\n\nThe objective of Byzantine fault tolerance is to be able to defend against failures of system components with or without symptoms that prevent other components of the system from reaching an agreement among themselves, where such an agreement is needed for the correct operation of the system.\n\nRemaining operationally correct components of a Byzantine fault tolerant system will be able to continue providing the system's service as originally intended, assuming there are sufficiently many accurately operating components to maintain the service.\n\nByzantine failures are considered the most general and most difficult class of failures among the [[Failure cause|failure modes]]. The so-called fail-stop failure mode occupies the simplest end of the spectrum. Whereas fail-stop failure mode simply means that the only way to fail is a [[Node (computer science)|node]] crash, detected by other nodes, Byzantine failures imply no restrictions, which means that the failed node can generate arbitrary data, including data that makes it appear like a functioning node. Thus, Byzantine failures can confuse failure detection systems, which makes fault tolerance difficult. Despite the analogy, a Byzantine failure is not necessarily a [[security]] problem involving hostile human interference: it can arise purely from electrical or software faults.\n\nThe terms fault and failure are used here according to the standard definitions<ref name=\"AvizienisLaprie2004\">{{cite journal| last1=Avizienis | first1=A.| last2=Laprie| first2=J.-C.| last3=Randell| first3=Brian| author-link3=Brian Randell| last4=Landwehr| first4=C.| title=Basic concepts and taxonomy of dependable and secure computing| journal=IEEE Transactions on Dependable and Secure Computing| volume=1| issue=1| year=2004| pages=11\u201333| issn=1545-5971 | doi=10.1109/TDSC.2004.2| hdl=1903/6459}}</ref> originally created by a joint committee on \"Fundamental Concepts and Terminology\" formed by the [[IEEE]] Computer Society's Technical Committee on Dependable Computing and Fault-Tolerance and [[IFIP]] Working Group 10.4 on Dependable Computing and Fault Tolerance.<ref>{{cite web| title = Dependable Computing and Fault Tolerance| url = http://www.dependability.org| accessdate = 2015-03-02| archive-url = https://web.archive.org/web/20150402141319/http://www.dependability.org/| archive-date = 2015-04-02| url-status=live| df = }}</ref> A version of these definitions is also described in the [[Dependability]] Wikipedia page.\n\n== Caveat ==\nByzantine fault tolerance is only concerned about broadcast correctness, that is, the property that when one component broadcasts a single consistent value to other components (i.e sends the same value to the other components), they all receive exactly the same value, or in the case that the broadcaster is not consistent, the other components agree on a common value. This kind of fault tolerance does not encompass the correctness of the value itself; for example, an adversarial component that deliberately sends an incorrect value, but sends that same value consistently to all components, will not be caught in the Byzantine fault tolerance scheme.\n\n== Formal definition ==\n'''Setting:''' \n<ref>Generalized Communication and SecurityModelsin Byzantine Agreement, Matthias Fitzi https://www.crypto.ethz.ch/publications/files/Fitzi03.pdf</ref>\nGiven a system of <math>n</math> components, <math>t</math> of which are dishonest, and assuming only point-to-point channel between all the components.\n\nWhenever a component <math>A</math>  tries to broadcast a value <math>x</math>, the other components are allowed to discuss with each other and verify the consistency of  <math>A</math>'s broadcast, and eventually settle on a common value  <math>y</math> .\n\n'''Property:'''\n\nThe system is said to resist Byzantine Faults if when a component  <math>A</math> broadcast a value  <math>x</math>:\n\n# If <math>A</math> is honest, then all honest components agree on  the value  <math>x</math>.\n# In any case, all honest components agree on the same value  <math>y</math>.\n\n<br />'''Variants:'''\n\nThe problem has been studied in the case of both synchronous and asynchronous communications.\n\nThe communication graph above is assumed to be the complete graph (i.e each component can discuss with every other), but the communication graph can be restricted.\n\nIt can also be relaxed in a more \"realistic\" problem where the faulty components do not collude together in an attempt to lure the others into error. It is in this setting that practical algorithms have been devised.\n\n== History ==\n\nThe problem of obtaining Byzantine consensus was conceived and formalized by [[Robert Shostak]], who dubbed it the ''interactive consistency'' problem. This work was done in 1978 in the context of the NASA-sponsored SIFT<ref name=\":0\" /> project in the Computer Science Lab at [[SRI International]]. SIFT (for Software Implemented Fault Tolerance) was the brain child of John Wensley, and was based on the idea of using multiple general-purpose computers that would communicate through pairwise messaging in order to reach a consensus, even if some of the computers were faulty.\n\nAt the beginning of the project, it was not clear how many computers in total are needed to guarantee that a conspiracy of ''n'' faulty computers could not \"thwart\" the efforts of the correctly-operating ones to reach consensus. Shostak showed that a minimum of 3''n+''1 are needed, and devised a two-round 3''n+1'' messaging protocol that would work for ''n''=1. His colleague Marshall Pease generalized the algorithm for any n > 0, proving that 3''n''+1 is both necessary and sufficient. These results, together with a later proof by [[Leslie Lamport]] of the sufficiency of 3''n'' using digital signatures, were published in the seminal paper, ''Reaching Agreement in the Presence of Faults.''<ref>{{Cite journal|last=Pease|first=Marshall|last2=Shostak|first2=Robert|last3=Lamport|first3=Leslie|date=April 1980|title=Reaching Agreement in the Presence of Faults|url=|journal=Journal of the Association for Computing Machinery|volume=27|issue=2|pages=228\u2013234|doi=10.1145/322186.322188|citeseerx=10.1.1.68.4044}}</ref> The authors were awarded the 2005 [[Edsger W. Dijkstra Prize]] for this paper.\n\nTo make the interactive consistency problem easier to understand, Lamport devised a colorful allegory in which a group of army generals formulate a plan for attacking a city. In its original version, the story cast the generals as commanders of the [[Albania]]n army. The name was changed, eventually settling on \"[[Byzantine Empire|Byzantine]]\", at the suggestion of Jack Goldberg to future-proof any potential offense giving.<ref>{{cite journal |last1=Lamport |first1=Leslie |title=The Byzantine Generals Problem |url=https://www.microsoft.com/en-us/research/publication/byzantine-generals-problem/ |journal=ACM Transactions on Programming Languages and Systems |publisher=SRI International |accessdate=18 March 2019|date=2016-12-19 }}</ref> This formulation of the problem, together with some additional results, were presented by the same authors in their 1982 paper, \"The Byzantine Generals Problem\".<ref name=BGP_Paper />\n\nIn its simplest form, the generals must decide only whether to attack or retreat. Some generals may prefer to attack, while others prefer to retreat. The important thing is that every general agrees on a common decision, for a halfhearted attack by a few generals would become a [[rout]], and would be worse than either a coordinated attack or a coordinated retreat.\n\nThe problem is complicated by the presence of treacherous generals who may not only cast a vote for a suboptimal strategy, they may do so selectively. For instance, if nine generals are voting, four of whom support attacking while four others are in favor of retreat, the ninth general may send a vote of retreat to those generals in favor of retreat, and a vote of attack to the rest. Those who received a retreat vote from the ninth general will retreat, while the rest will attack (which may not go well for the attackers). The problem is complicated further by the generals being physically separated and having to send their votes via messengers who may fail to deliver votes or may forge false votes.\n\nByzantine fault tolerance can be achieved if the loyal (non-faulty) generals have a majority agreement on their strategy. There can be a default vote value given to missing messages. For example, missing messages can be given the value &lt;Null&gt;. Further, if the agreement is that the &lt;Null&gt; votes are in the majority, a pre-assigned default strategy can be used (e.g., retreat).<ref name=BGP_Paper>{{Cite journal | last1 = Lamport | first1 = L. | authorlink1 = Leslie Lamport| last2 = Shostak | first2 = R. | last3 = Pease | first3 = M. | doi = 10.1145/357172.357176 | title = The Byzantine Generals Problem | journal = ACM Transactions on Programming Languages and Systems | volume = 4 | issue = 3 | pages = 387\u2013389 | year=1982 | archiveurl = https://web.archive.org/web/20170207104645/http://research.microsoft.com/en-us/um/people/lamport/pubs/byz.pdf | archivedate = 7 February 2017 | url = http://research.microsoft.com/en-us/um/people/lamport/pubs/byz.pdf| citeseerx = 10.1.1.64.2312 }}</ref>\n\nThe typical mapping of this story onto computer systems is that the computers are the generals and their digital communication system links are the messengers. Although the problem is formulated in the analogy as a decision-making and security problem, in electronics, it cannot be solved simply by [[cryptographic]] [[digital signature]]s, because failures such as incorrect voltages can propagate through the encryption process. Thus, a component may appear functioning to one component and faulty to another, which prevents forming a consensus as to whether the component is faulty or not.\n\n== Examples ==\n{{bad linked references|section|date=January 2019}}\n\nSeveral examples of Byzantine failures that have occurred are given in two equivalent journal papers.<ref name=\"DriscollHall2004\" /><ref name=\"DriscollHall2003\" /> These and other examples are described on the [[NASA]] DASHlink web pages.<ref>{{cite web | url = https://c3.nasa.gov/dashlink/resources/624/ | title = Real System Failures | last = Driscoll | first = Kevin | date = 2012-12-11 | publisher = [[NASA]] | access-date = 2015-03-02 | website = DASHlink | archive-url = https://web.archive.org/web/20150402190610/https://c3.nasa.gov/dashlink/resources/624/ | archive-date = 2015-04-02 | url-status=live | df =  }}</ref> These web pages also describe some phenomena that can cause Byzantine faults.\n\nByzantine errors were observed infrequently and at irregular points during endurance testing for the newly constructed [[Virginia-class submarine|''Virginia'' class submarines]], at least through 2005 (when the issues were publicly reported).<ref name=\"WalterEllis2005\">{{cite book|last1=Walter|first1=C.|title=Ninth IEEE International Symposium on High-Assurance Systems Engineering (HASE'05)|last2=Ellis|first2=P.|last3=LaValley|first3=B.|chapter=The Reliable Platform Service: A Property-Based Fault Tolerant Service Architecture|year=2005|pages=34\u201343|doi=10.1109/HASE.2005.23|isbn=978-0-7695-2377-4}}</ref>\n\n== Early solutions ==\n\nSeveral solutions were described by Lamport, Shostak, and Pease in 1982.<ref name=BGP_Paper/> They began by noting that the Generals' Problem can be reduced to solving a \"Commander and Lieutenants\" problem where loyal Lieutenants must all act in unison and that their action must correspond to what the Commander ordered in the case that the Commander is loyal:\n\n* One solution considers scenarios in which messages may be forged, but which will be ''Byzantine-fault-tolerant'' as long as the number of traitorous generals does not equal or exceed one third of the generals. The impossibility of dealing with one-third or more traitors ultimately reduces to proving that the one Commander and two Lieutenants problem cannot be solved, if the Commander is traitorous. To see this, suppose we have a traitorous Commander A, and two Lieutenants, B and C: when A tells B to attack and C to retreat, and B and C send messages to each other, forwarding A's message, neither B nor C can figure out who is the traitor, since it is not necessarily A\u2014another Lieutenant could have forged the message purportedly from A. It can be shown that if ''n'' is the number of generals in total, and ''t'' is the number of traitors in that ''n'', then there are solutions to the problem only when ''n'' &gt; 3''t'' and the communication is synchronous (bounded delay).<ref>{{cite journal | first1 = P. | last1 = Feldman | first2 = S. | last2 = Micali | url = http://people.csail.mit.edu/silvio/Selected%20Scientific%20Papers/Distributed%20Computation/An%20Optimal%20Probabilistic%20Algorithm%20for%20Byzantine%20Agreement.pdf | title = An optimal probabilistic protocol for synchronous Byzantine agreement | journal = SIAM J. Comput. | volume = 26 | issue = 4 | pages = 873\u2013933 | date = 1997 | doi = 10.1137/s0097539790187084 | access-date = 2012-06-14 | archive-url = https://web.archive.org/web/20160305012505/http://people.csail.mit.edu/silvio/Selected%20Scientific%20Papers/Distributed%20Computation/An%20Optimal%20Probabilistic%20Algorithm%20for%20Byzantine%20Agreement.pdf | archive-date = 2016-03-05 | url-status=live | df =  }}</ref>\n* A second solution requires unforgeable message signatures. For [[Critical system#Security critical|security-critical systems]], [[digital signature]]s (in modern computer systems, this may be achieved in practice using [[public-key cryptography]]) can provide Byzantine fault tolerance in the presence of an arbitrary number of traitorous generals. However, for [[safety-critical system]]s (where \"security\" addresses intelligent threats while \"safety\" addresses the inherent dangers of an activity or mission), simple error detecting codes, such as [[Cyclic redundancy check|CRCs]], provide weaker but often sufficient coverage at a much lower cost. This is true for both Byzantine and non-Byzantine faults. Furthermore, sometimes security measures weaken safety and vice versa. Thus, cryptographic digital signature methods are not a good choice for safety-critical systems, unless there is also a specific security threat as well.<ref name=\"PaulitschMorris2005\">{{cite book | last1=Paulitsch | first1=M. | title=2005 International Conference on Dependable Systems and Networks (DSN'05) | last2=Morris | first2=J. | last3=Hall | first3=B. | last4=Driscoll | first4=K. | last5=Latronico | first5=E. | last6=Koopman | first6=P. | chapter=Coverage and the Use of Cyclic Redundancy Codes in Ultra-Dependable Systems | year=2005 | pages=346\u2013355 | doi=10.1109/DSN.2005.31| isbn=978-0-7695-2282-1 }}</ref> While error detecting codes, such as CRCs, are better than cryptographic techniques, neither provide adequate coverage for active electronics in safety-critical systems. This is illustrated by the ''Schr\u00f6dinger CRC'' scenario where a CRC-protected message with a single Byzantine faulty bit presents different data to different observers and each observer sees a valid CRC.<ref name=\"DriscollHall2004\" /><ref name=\"DriscollHall2003\" />\n* Also presented is a variation on the first two solutions allowing Byzantine-fault-tolerant behavior in some situations where not all generals can communicate directly with each other.\n\nSeveral system architectures were designed c. 1980 that implemented Byzantine fault tolerance. These include: Draper's FTMP,<ref name=\"HopkinsLala1987\">{{ Cite book | last1=Hopkins | first1=Albert L. | title=The Evolution of Fault-Tolerant Computing | last2=Lala | first2=Jaynarayan H. | last3=Smith | first3=T. Basil | chapter=The Evolution of Fault Tolerant Computing at the Charles Stark Draper Laboratory, 1955\u201385 | volume=1 | year=1987 | pages=121\u2013140 | issn=0932-5581 | doi=10.1007/978-3-7091-8871-2_6| series=Dependable Computing and Fault-Tolerant Systems | isbn=978-3-7091-8873-6 }}</ref> Honeywell's MMFCS,<ref name=\"MMFCS\">{{ citation | last1 = Driscoll | first1 = Kevin | last2 = Papadopoulos | first2 = Gregory | last3 = Nelson | first3 = Scott | last4 = Hartmann | first4 = Gary | last5 = Ramohalli | first5 = Gautham | title = Multi-Microprocessor Flight Control System | publisher = AFWAL/FIGL U.S. Air Force Systems Command | date = 1984 | type = Technical Report | location = Wright-Patterson Air Force Base, OH 45433, USA | id = AFWAL-TR-84-3076 }}</ref> and SRI's SIFT.<ref name=\":0\">{{cite journal | title=SIFT: design and analysis of a fault-tolerant computer for aircraft control|journal=Microelectronics Reliability|volume=19|issue=3|year=1979|page=190|issn=0026-2714|doi=10.1016/0026-2714(79)90211-7}}</ref>\n\n== Advanced solutions ==\n\nIn 1999, Miguel Castro and [[Barbara Liskov]] introduced the \"Practical Byzantine Fault Tolerance\" (PBFT) algorithm,<ref>{{cite journal | first1 = M. | last1 = Castro | first2 = B. | last2 = Liskov | citeseerx = 10.1.1.127.6130 | title = Practical Byzantine Fault Tolerance and Proactive Recovery | publisher = [[Association for Computing Machinery]] | journal = ACM Transactions on Computer Systems | volume = 20 | issue = 4 | pages = 398\u2013461 | date = 2002 | doi = 10.1145/571637.571640}}</ref> which provides high-performance Byzantine state machine replication, processing thousands of requests per second with sub-millisecond increases in latency.\n\nAfter PBFT, several BFT protocols were introduced to improve its robustness and performance. For instance, Q/U,<ref>{{cite journal | first1 = M. | last1 = Abd-El-Malek | first2 = G. | last2 = Ganger | first3 = G. | last3 = Goodson | first4 = M. | last4 = Reiter | first5 = J. | last5 = Wylie | doi = 10.1145/1095809.1095817 | title = Fault-scalable Byzantine Fault-Tolerant Services | journal = ACM Sigops Operating Systems Review | volume = 39 | issue = 5 | pages = 59 | publisher = [[Association for Computing Machinery]] | conference = Symposium on Operating Systems Principles | date = 2005 }}</ref> HQ,<ref>{{cite conference | first1 = James | last1 = Cowling | first2 = Daniel | last2 = Myers | authorlink3 = Barbara Liskov | first3 = Barbara | last3 = Liskov | first4 = Rodrigo | last4 = Rodrigues | first5 = Liuba | last5 = Shrira | url = http://portal.acm.org/citation.cfm?id=1298455.1298473 | title = HQ Replication: A Hybrid Quorum Protocol for Byzantine Fault Tolerance | conference = Proceedings of the 7th [[USENIX]] Symposium on Operating Systems Design and Implementation | date = 2006 | isbn = 1-931971-47-1 | pages = 177\u2013190}}</ref> Zyzzyva,<ref>{{cite journal | first1 = Ramakrishna | last1 = Kotla | first2 = Lorenzo | last2 = Alvisi | first3 = Mike | last3 = Dahlin | first4 = Allen | last4 = Clement | first5 = Edmund | last5 = Wong | doi = 10.1145/1658357.1658358 | title = Zyzzyva: Speculative Byzantine Fault Tolerance | publisher = [[Association for Computing Machinery]] | journal = ACM Transactions on Computer Systems | volume = 27 | issue = 4 | pages = 1\u201339 | date = December 2009 }}</ref> and ABsTRACTs,<ref>{{cite conference | first1 = Rachid | last1 = Guerraoui | first2 = Nikola | last2 = Kne\u017eevic | first3 = Marko | last3 = Vukolic | first4 = Vivien | last4 = Qu\u00e9ma | url = http://infoscience.epfl.ch/record/144158 | title = The Next 700 BFT Protocols | conference = Proceedings of the 5th European conference on Computer systems | publisher = EuroSys | date = 2010 | access-date = 2011-10-04 | archive-url = https://web.archive.org/web/20111002225957/http://infoscience.epfl.ch/record/144158 | archive-date = 2011-10-02 | url-status=live | df =  }}</ref> addressed the performance and cost issues; whereas other protocols, like Aardvark<ref>{{cite conference|first1=A.|last1=Clement|first2=E.|last2=Wong|first3=L.|last3=Alvisi|first4=M.|last4=Dahlin|first5=M.|last5=Marchetti|url=http://www.usenix.org/events/nsdi09/tech/full_papers/clement/clement.pdf|title=Making Byzantine Fault Tolerant Systems Tolerate Byzantine Faults|publisher=[[USENIX]]|conference=Symposium on Networked Systems Design and Implementation|date=April 22\u201324, 2009|access-date=2010-02-17|archive-url=https://web.archive.org/web/20101225155052/https://www.usenix.org/events/nsdi09/tech/full_papers/clement/clement.pdf|archive-date=2010-12-25|url-status=live|df=}}</ref> and RBFT,<ref>{{cite conference|first1=P.-L.|last1=Aublin|first2=S.|last2=Ben Mokhtar|first3=V.|last3=Qu\u00e9ma|url=http://www.temple.edu/cis/icdcs2013/program.html|title=RBFT: Redundant Byzantine Fault Tolerance|publisher=[[International Conference on Distributed Computing Systems]]|conference=33rd IEEE International Conference on Distributed Computing Systems|date=July 8\u201311, 2013|url-status=dead|archiveurl=https://web.archive.org/web/20130805115252/http://www.temple.edu/cis/icdcs2013/program.html|archivedate=August 5, 2013}}</ref> addressed its robustness issues. Furthermore, Adapt<ref>{{Cite journal|last=Bahsoun|first=J. P.|last2=Guerraoui|first2=R.|last3=Shoker|first3=A.|date=2015-05-01|title=Making BFT Protocols Really Adaptive|journal=Parallel and Distributed Processing Symposium (IPDPS), 2015 IEEE International|pages=904\u2013913|doi=10.1109/IPDPS.2015.21|isbn=978-1-4799-8649-1|url=http://repositorio.inesctec.pt/handle/123456789/4107}}</ref> tried to make use of existing BFT protocols, through switching between them in an adaptive way, to improve system robustness and performance as the underlying conditions change. Furthermore, BFT protocols were introduced that leverage trusted components to reduce the number of replicas, e.g., A2M-PBFT-EA<ref>{{Cite journal|last=Chun|first=Byung-Gon|last2=Maniatis|first2=Petros|last3=Shenker|first3=Scott|last4=Kubiatowicz|first4=John|date=2007-01-01|title=Attested Append-only Memory: Making Adversaries Stick to Their Word|journal=Proceedings of Twenty-first ACM SIGOPS Symposium on Operating Systems Principles|series=SOSP '07|location=New York, NY, USA|publisher=ACM|pages=189\u2013204|doi=10.1145/1294261.1294280|isbn=9781595935915}}</ref> and MinBFT.<ref>{{Cite journal|last=Veronese|first=G. S.|last2=Correia|first2=M.|last3=Bessani|first3=A. N.|last4=Lung|first4=L. C.|last5=Verissimo|first5=P.|date=2013-01-01|title=Efficient Byzantine Fault-Tolerance|journal=IEEE Transactions on Computers|volume=62|issue=1|pages=16\u201330|doi=10.1109/TC.2011.221|issn=0018-9340|citeseerx=10.1.1.408.9972}}</ref>\n\nMotivated by PBFT, Tendermint BFT<ref>{{cite arxiv | first1 = E. | last1 = Buchman | first2 = J. | last2 = Kwon | first3 = Z. | last3 = Milosevic | title = The latest gossip on BFT consensus | eprint = 1807.04938 | date = 2018 | class = cs.DC }}</ref>  was introduced for partial asynchronous networks and it is mainly used for Proof of Stake Proof blockchains. Recently, [[Yongge Wang]]  showed that Tendermint BFT cannot achieve liveness in partial synchronous networks and proposed a more efficient BFT protocol BDLS<ref>{{cite journal | first1 = Yongge | last1 = Wang | title = Byzantine Fault Tolerance in Partially Connected Asynchronous Networks | journal = Cryptology ePrint Archive, Report 2019/1460 | publisher = IACR ePrint | date = 2019 | url=https://eprint.iacr.org/2019/1460/20200211:001341}}</ref> for partial synchronous networks.\n\n== BFT implementations ==\n\nOne example of BFT in use is [[bitcoin]], a peer-to-peer digital cash system.<ref>{{Cite web|url=https://bitcoin.org/en/|title=Bitcoin - Open source P2P money|website=bitcoin.org|language=en|access-date=2019-08-18}}</ref> The [[bitcoin network]] works in parallel to generate a [[blockchain]] with [[proof-of-work]] allowing the system to overcome Byzantine failures and reach a coherent global view of the system's state.\n\nSome aircraft systems, such as the Boeing 777 [[Aircraft Information Management System]] (via its [[ARINC]] 659 [[SAFEbus]] network),<ref name=\"Zurawski2015\">{{cite book | last1=M. | first1=Paulitsch | last2=Driscoll | first2=K. | editor-first=Richard | editor-last=Zurawski | title=Industrial Communication Technology Handbook, Second Edition | chapter-url=https://books.google.com/books?id=ppzNBQAAQBAJ | date=9 January 2015 | chapter=Chapter 48:SAFEbus | pages=48\u20131\u201348\u201326 | publisher=CRC Press | isbn=978-1-4822-0733-0}}</ref><ref name=\"HenzingerKirsch2001\">{{cite book | author1 = Thomas A. Henzinger | author2 = Christoph M. Kirsch | title = Embedded Software: First International Workshop, EMSOFT 2001, Tahoe City, CA, USA, October 8-10, 2001. Proceedings | url = http://www.csl.sri.com/papers/emsoft01/emsoft01.pdf | date = 26 September 2001 | publisher = Springer Science & Business Media | isbn = 978-3-540-42673-8 | pages = 307\u2013 | access-date = 2015-03-05 | archive-url = https://web.archive.org/web/20150922114036/http://www.csl.sri.com/papers/emsoft01/emsoft01.pdf | archive-date = 2015-09-22 | url-status=live | df =  }}</ref>\nthe Boeing 777 flight control system,<ref name=\"Yeh2001\">{{cite book | last1=Yeh | first1=Y.C. | title=20th DASC. 20th Digital Avionics Systems Conference (Cat. No.01CH37219) | chapter=Safety critical avionics for the 777 primary flight controls system | volume=1 | year=2001 | pages=1C2/1\u20131C2/11 | doi=10.1109/DASC.2001.963311| isbn=978-0-7803-7034-0 }}</ref> and the Boeing 787 flight control systems use Byzantine fault tolerance; because these are real-time systems, their Byzantine fault tolerance solutions must have very low latency. For example, SAFEbus can achieve Byzantine fault tolerance within the order of a microsecond of added latency.\n\nSome spacecraft flight systems such as that of the [[SpaceX Dragon]]<ref>{{Cite web |url=https://lwn.net/Articles/540368/ |title=ELC: SpaceX lessons learned [LWN.net]<!-- Bot generated title --> |access-date=2016-07-21 |archive-url=https://web.archive.org/web/20160805064218/http://lwn.net/Articles/540368/ |archive-date=2016-08-05 |url-status=live |df= }}</ref> consider Byzantine fault tolerance in their design.\n\nByzantine fault tolerance mechanisms use components that repeat an incoming message (or just its signature) to other recipients of that incoming message. All these mechanisms make the assumption that the act of repeating a message blocks the propagation of Byzantine symptoms. For systems that have a high degree of safety or security criticality, these assumptions must be proven to be true to an acceptable level of [[fault coverage]]. When providing proof through testing, one difficulty is creating a sufficiently wide range of signals with Byzantine symptoms.<ref name=\"NanyaGoosen1989\">{{cite journal |last1=Nanya|first1=T.|last2=Goosen|first2=H.A.|title=The Byzantine hardware fault model|journal=IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems|volume=8|issue=11|year=1989|pages=1226\u20131231|issn=0278-0070|doi=10.1109/43.41508}}</ref> Such testing likely will require specialized fault injectors.<ref name=\"MartinsGandhi2013\">{{cite book|last1=Martins|first1=Rolando|title=Middleware 2013|last2=Gandhi|first2=Rajeev|last3=Narasimhan|first3=Priya|last4=Pertet|first4=Soila|last5=Casimiro|first5=Ant\u00f3nio|last6=Kreutz|first6=Diego|last7=Ver\u00edssimo|first7=Paulo|chapter=Experiences with Fault-Injection in a Byzantine Fault-Tolerant Protocol|volume=8275|year=2013|pages=41\u201361|issn=0302-9743|doi=10.1007/978-3-642-45065-5_3|series=Lecture Notes in Computer Science|isbn=978-3-642-45064-8}}</ref><ref>{{cite patent | country = US | number = 7475318 | status = patent | title = Method for testing the sensitive input range of Byzantine filters | gdate = 2009-01-06 | fdate = 2006-01-27 | pridate = 2005-01-28 | inventor = Kevin R. Driscoll | assign1 = Honeywell International Inc. | class = G01R31/28 }}</ref>\n\n=== Software ===\n{{primary sources|section|date=January 2019}}\n\n* UpRight is an open source library for constructing services that tolerate both crashes (\"up\") and Byzantine behaviors (\"right\") that incorporates many of these protocols' innovations.<ref>{{ cite web | url = https://code.google.com/p/upright/ | archiveurl = https://web.archive.org/web/20160415055752/https://code.google.com/p/upright/ | archivedate = 2016-04-15 | title = Google Code repository for the UpRight replication library }}</ref>\n* The BFT-SMaRt library is a high-performance Byzantine fault-tolerant state machine replication library developed in Java. This library implements a protocol very similar to PBFT's, plus complementary protocols which offer state transfer and on-the-fly reconfiguration of hosts. BFT-SMaRt is the most recent effort to implement state machine replication, still being actively maintained.<ref>{{ cite web | url = https://bft-smart.github.io/library/ | archiveurl = https://web.archive.org/web/20171029200352/http://bft-smart.github.io/library/ |archivedate = 2017-10-29 | title = Google Code repository for the BFT-SMaRt replication library }}</ref>\n* [[Archistar]] utilizes a slim BFT layer for communication. It prototypes a secure multi-cloud storage system using Java licensed under LGPLv2. Focus lies on simplicity and readability, it aims to be the foundation for further research projects.<ref>{{ cite web | url = https://github.com/Archistar/archistar-core | archiveurl = https://web.archive.org/web/20150204123247/https://github.com/archistar/archistar-core | archivedate = 2015-02-04 | title = github repository for the Archistar project | date = 2019-05-28 }}</ref><ref>{{ cite web | url = https://github.com/Archistar/archistar-bft | archiveurl = https://web.archive.org/web/20170613060325/https://github.com/Archistar/archistar-bft | archivedate = 2017-06-13 | title = github repository for the Archistar project | date = 2019-04-28 }}</ref>\n* Askemos is a concurrent, garbage-collected, persistent programming platform atop of replicated state machines which tolerates Byzantine faults. It prototypes an execution environment facilitating [[Smart contracts]].<ref>{{ cite web | url = http://ball.askemos.org/ | archiveurl = https://web.archive.org/web/20160503082427/http://ball.askemos.org/ | archivedate = 2016-05-03 | title = Askemos home page }}</ref>\n\n== See also ==\n\n* [[Atomic commit]]\n* [[Brooks\u2013Iyengar algorithm]]\n* [[List of mathematical concepts named after places]]\n* [[List of terms relating to algorithms and data structures]]\n* [[Paxos (computer science)#Byzantine Paxos|Byzantine Paxos]]\n* [[Quantum Byzantine agreement]]\n* [[Two Generals Problem]]\n\n== References ==\n\n{{reflist|30em}}\n\n== External links ==\n\n* [https://web.archive.org/web/20080828060019/http://www.rkbexplorer.com/explorer/#display=mechanism%2D{http://resex.rkbexplorer.com/id/resilience-mechanism-65b5cef4} Byzantine Fault Tolerance in the RKBExplorer]\n\n[[Category:Public-key cryptography]]\n[[Category:Distributed computing problems]]\n[[Category:Fault-tolerant computer systems]]\n[[Category:Theory of computation]]\n", "text_old": "{{Redirect|Byzantine generals|military generals of the Byzantine empire|Category:Byzantine generals}}\n\nA '''Byzantine fault''' (also '''interactive consistency''', '''source congruency''', '''error avalanche''', '''Byzantine agreement problem''', '''Byzantine generals problem''', and '''Byzantine failure'''<ref>{{cite web| url= http://lamspeople.epfl.ch/kirrmann/Pubs/FaultTolerance/Fault_Tolerance_Tutorial_HK.pdf#page=94| title= Fault Tolerant Computing in Industrial Automation| last1= Kirrmann| first1= Hubert| date= n.d.| publisher= ABB Research Center| location= Switzerland| page= 94| access-date= 2015-03-02| archive-url= https://web.archive.org/web/20140326192930/http://lamspeople.epfl.ch/kirrmann/Pubs/FaultTolerance/Fault_Tolerance_Tutorial_HK.pdf#page=94#page=94| archive-date= 2014-03-26| url-status=dead| df= }}</ref>) is a condition of a computer system, particularly [[distributed computing]] systems, where components may fail and there is imperfect information on whether a component has failed. The term takes its name from an allegory, the \"Byzantine Generals Problem\",<ref>{{Cite journal | last1 = Lamport | first1 = L. | authorlink1 = Leslie Lamport| last2 = Shostak | first2 = R. | last3 = Pease | first3 = M. | doi = 10.1145/357172.357176 | title = The Byzantine Generals Problem | journal = ACM Transactions on Programming Languages and Systems | volume = 4 | issue = 3 | pages = 382\u2013401 | year = 1982 | url = https://www.microsoft.com/en-us/research/publication/byzantine-generals-problem/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Flamport%2Fpubs%2Fbyz.pdf | url-status=live | archiveurl = https://web.archive.org/web/20180613015025/https://www.microsoft.com/en-us/research/publication/byzantine-generals-problem/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Flamport%2Fpubs%2Fbyz.pdf | archivedate = 13 June 2018| citeseerx = 10.1.1.64.2312 }}</ref> developed to describe a situation in which, in order to avoid catastrophic failure of the system, the system's actors must agree on a concerted strategy, but some of these actors are unreliable.\n\nIn a Byzantine fault, a component such as a [[Server (computing)|server]] can inconsistently appear both failed and functioning to failure-detection systems, presenting different symptoms to different observers. It is difficult for the other components to declare it failed and shut it out of the network, because they need to first reach a [[Consensus (computer science)|consensus]] regarding which component has failed in the first place.\n\nByzantine fault tolerance (BFT) is the dependability of a [[fault-tolerant computer system]] to such conditions.\n\n== Characteristics ==\n\nA Byzantine fault is any fault presenting different symptoms to different observers.<ref name=\"DriscollHall2004\">{{cite book| last1=Driscoll| first1=K.| title=The 23rd Digital Avionics Systems Conference (IEEE Cat. No.04CH37576)| last2=Hall| first2=B.| last3=Paulitsch| first3=M.| last4=Zumsteg| first4=P. |last5=Sivencrona| first5=H.| chapter=The Real Byzantine Generals| year=2004| pages=6.D.4\u201361\u201311| doi=10.1109/DASC.2004.1390734| isbn=978-0-7803-8539-9}}</ref> A Byzantine failure is the loss of a system service due to a Byzantine fault in systems that require [[Consensus (computer science)|consensus]].<ref name=\"DriscollHall2003\">{{cite book| last1=Driscoll| first1=Kevin| title=Computer Safety, Reliability, and Security| last2=Hall| first2=Brendan| last3=Sivencrona| first3=H\u00e5kan| last4=Zumsteg| first4=Phil | chapter=Byzantine Fault Tolerance, from Theory to Reality| volume=2788| year=2003| pages=235\u2013248| issn=0302-9743| doi=10.1007/978-3-540-39878-3_19| series=Lecture Notes in Computer Science| isbn=978-3-540-20126-7| chapter-url=https://semanticscholar.org/paper/88ae63cd7fc1e5892c8015e70246632bf22f4dd1}}</ref>\n\nThe objective of Byzantine fault tolerance is to be able to defend against failures of system components with or without symptoms that prevent other components of the system from reaching an agreement among themselves, where such an agreement is needed for the correct operation of the system.\n\nRemaining operationally correct components of a Byzantine fault tolerant system will be able to continue providing the system's service as originally intended, assuming there are sufficiently many accurately operating components to maintain the service.\n\nByzantine failures are considered the most general and most difficult class of failures among the [[Failure cause|failure modes]]. The so-called fail-stop failure mode occupies the simplest end of the spectrum. Whereas fail-stop failure mode simply means that the only way to fail is a [[Node (computer science)|node]] crash, detected by other nodes, Byzantine failures imply no restrictions, which means that the failed node can generate arbitrary data, including data that makes it appear like a functioning node. Thus, Byzantine failures can confuse failure detection systems, which makes fault tolerance difficult. Despite the analogy, a Byzantine failure is not necessarily a [[security]] problem involving hostile human interference: it can arise purely from electrical or software faults.\n\nThe terms fault and failure are used here according to the standard definitions<ref name=\"AvizienisLaprie2004\">{{cite journal| last1=Avizienis | first1=A.| last2=Laprie| first2=J.-C.| last3=Randell| first3=Brian| author-link3=Brian Randell| last4=Landwehr| first4=C.| title=Basic concepts and taxonomy of dependable and secure computing| journal=IEEE Transactions on Dependable and Secure Computing| volume=1| issue=1| year=2004| pages=11\u201333| issn=1545-5971 | doi=10.1109/TDSC.2004.2| hdl=1903/6459}}</ref> originally created by a joint committee on \"Fundamental Concepts and Terminology\" formed by the [[IEEE]] Computer Society's Technical Committee on Dependable Computing and Fault-Tolerance and [[IFIP]] Working Group 10.4 on Dependable Computing and Fault Tolerance.<ref>{{cite web| title = Dependable Computing and Fault Tolerance| url = http://www.dependability.org| accessdate = 2015-03-02| archive-url = https://web.archive.org/web/20150402141319/http://www.dependability.org/| archive-date = 2015-04-02| url-status=live| df = }}</ref> A version of these definitions is also described in the [[Dependability]] Wikipedia page.\n\n== Caveat ==\nByzantine fault tolerance is only concerned about broadcast correctness, that is, the property that when one component broadcasts a single consistent value to other components (i.e sends the same value to the other components), they all receive exactly the same value, or in the case that the broadcaster is not consistent, the other components agree on a common value. This kind of fault tolerance does not encompass the correctness of the value itself; for example, an adversarial component that deliberately sends an incorrect value, but sends that same value consistently to all components, will not be caught in the Byzantine fault tolerance scheme.\n\n== Formal definition ==\n'''Setting:''' \n<ref>Generalized Communication and SecurityModelsin Byzantine Agreement, Matthias Fitzi https://www.crypto.ethz.ch/publications/files/Fitzi03.pdf</ref>\nGiven a system of <math>n</math> components, <math>t</math> of which are dishonest, and assuming only point-to-point channel between all the components.\n\nWhenever a component <math>A</math>  tries to broadcast a value <math>x</math>, the other components are allowed to discuss with each other and verify the consistency of  <math>A</math>'s broadcast, and eventually settle on a common value  <math>y</math> .\n\n'''Property:'''\n\nThe system is said to resist Byzantine Faults if when a component  <math>A</math> broadcast a value  <math>x</math>:\n\n# If <math>A</math> is honest, then all honest components agree on  the value  <math>x</math>.\n# In any case, all honest components agree on the same value  <math>y</math>.\n\n<br />'''Variants:'''\n\nThe problem has been studied in the case of both synchronous and asynchronous communications.\n\nThe communication graph above is assumed to be the complete graph (i.e each component can discuss with every other), but the communication graph can be restricted.\n\nIt can also be relaxed in a more \"realistic\" problem where the faulty components do not collude together in an attempt to lure the others into error. It is in this setting that practical algorithms have been devised.\n\n== History ==\n\nThe problem of obtaining Byzantine consensus was conceived and formalized by [[Robert Shostak]], who dubbed it the ''interactive consistency'' problem. This work was done in 1978 in the context of the NASA-sponsored SIFT<ref name=\":0\" /> project in the Computer Science Lab at [[SRI International]]. SIFT (for Software Implemented Fault Tolerance) was the brain child of John Wensley, and was based on the idea of using multiple general-purpose computers that would communicate through pairwise messaging in order to reach a consensus, even if some of the computers were faulty.\n\nAt the beginning of the project, it was not clear how many computers in total are needed to guarantee that a conspiracy of ''n'' faulty computers could not \"thwart\" the efforts of the correctly-operating ones to reach consensus. Shostak showed that a minimum of 3''n+''1 are needed, and devised a two-round 3''n+1'' messaging protocol that would work for ''n''=1. His colleague Marshall Pease generalized the algorithm for any n > 0, proving that 3''n''+1 is both necessary and sufficient. These results, together with a later proof by [[Leslie Lamport]] of the sufficiency of 3''n'' using digital signatures, were published in the seminal paper, ''Reaching Agreement in the Presence of Faults.''<ref>{{Cite journal|last=Pease|first=Marshall|last2=Shostak|first2=Robert|last3=Lamport|first3=Leslie|date=April 1980|title=Reaching Agreement in the Presence of Faults|url=|journal=Journal of the Association for Computing Machinery|volume=27|issue=2|pages=228\u2013234|doi=10.1145/322186.322188|citeseerx=10.1.1.68.4044}}</ref> The authors were awarded the 2005 [[Edsger W. Dijkstra Prize]] for this paper.\n\nTo make the interactive consistency problem easier to understand, Lamport devised a colorful allegory in which a group of army generals formulate a plan for attacking a city. In its original version, the story cast the generals as commanders of the [[Albania]]n army. The name was changed, eventually settling on \"[[Byzantine Empire|Byzantine]]\", at the suggestion of Jack Goldberg to future-proof any potential offense giving.<ref>{{cite journal |last1=Lamport |first1=Leslie |title=The Byzantine Generals Problem |url=https://www.microsoft.com/en-us/research/publication/byzantine-generals-problem/ |journal=ACM Transactions on Programming Languages and Systems |publisher=SRI International |accessdate=18 March 2019|date=2016-12-19 }}</ref> This formulation of the problem, together with some additional results, were presented by the same authors in their 1982 paper, \"The Byzantine Generals Problem\".<ref name=BGP_Paper />\n\nIn its simplest form, the generals must decide only whether to attack or retreat. Some generals may prefer to attack, while others prefer to retreat. The important thing is that every general agrees on a common decision, for a halfhearted attack by a few generals would become a [[rout]], and would be worse than either a coordinated attack or a coordinated retreat.\n\nThe problem is complicated by the presence of treacherous generals who may not only cast a vote for a suboptimal strategy, they may do so selectively. For instance, if nine generals are voting, four of whom support attacking while four others are in favor of retreat, the ninth general may send a vote of retreat to those generals in favor of retreat, and a vote of attack to the rest. Those who received a retreat vote from the ninth general will retreat, while the rest will attack (which may not go well for the attackers). The problem is complicated further by the generals being physically separated and having to send their votes via messengers who may fail to deliver votes or may forge false votes.\n\nByzantine fault tolerance can be achieved if the loyal (non-faulty) generals have a majority agreement on their strategy. There can be a default vote value given to missing messages. For example, missing messages can be given the value &lt;Null&gt;. Further, if the agreement is that the &lt;Null&gt; votes are in the majority, a pre-assigned default strategy can be used (e.g., retreat).<ref name=BGP_Paper>{{Cite journal | last1 = Lamport | first1 = L. | authorlink1 = Leslie Lamport| last2 = Shostak | first2 = R. | last3 = Pease | first3 = M. | doi = 10.1145/357172.357176 | title = The Byzantine Generals Problem | journal = ACM Transactions on Programming Languages and Systems | volume = 4 | issue = 3 | pages = 387\u2013389 | year=1982 | archiveurl = https://web.archive.org/web/20170207104645/http://research.microsoft.com/en-us/um/people/lamport/pubs/byz.pdf | archivedate = 7 February 2017 | url = http://research.microsoft.com/en-us/um/people/lamport/pubs/byz.pdf| citeseerx = 10.1.1.64.2312 }}</ref>\n\nThe typical mapping of this story onto computer systems is that the computers are the generals and their digital communication system links are the messengers. Although the problem is formulated in the analogy as a decision-making and security problem, in electronics, it cannot be solved simply by [[cryptographic]] [[digital signature]]s, because failures such as incorrect voltages can propagate through the encryption process. Thus, a component may appear functioning to one component and faulty to another, which prevents forming a consensus as to whether the component is faulty or not.\n\n== Examples ==\n{{bad linked references|section|date=January 2019}}\n\nSeveral examples of Byzantine failures that have occurred are given in two equivalent journal papers.<ref name=\"DriscollHall2004\" /><ref name=\"DriscollHall2003\" /> These and other examples are described on the [[NASA]] DASHlink web pages.<ref>{{cite web | url = https://c3.nasa.gov/dashlink/resources/624/ | title = Real System Failures | last = Driscoll | first = Kevin | date = 2012-12-11 | publisher = [[NASA]] | access-date = 2015-03-02 | website = DASHlink | archive-url = https://web.archive.org/web/20150402190610/https://c3.nasa.gov/dashlink/resources/624/ | archive-date = 2015-04-02 | url-status=live | df =  }}</ref> These web pages also describe some phenomena that can cause Byzantine faults.\n\nByzantine errors were observed infrequently and at irregular points during endurance testing for the newly constructed [[Virginia-class submarine|''Virginia'' class submarines]], at least through 2005 (when the issues were publicly reported).<ref name=\"WalterEllis2005\">{{cite book|last1=Walter|first1=C.|title=Ninth IEEE International Symposium on High-Assurance Systems Engineering (HASE'05)|last2=Ellis|first2=P.|last3=LaValley|first3=B.|chapter=The Reliable Platform Service: A Property-Based Fault Tolerant Service Architecture|year=2005|pages=34\u201343|doi=10.1109/HASE.2005.23|isbn=978-0-7695-2377-4}}</ref>\n\n== Early solutions ==\n\nSeveral solutions were described by Lamport, Shostak, and Pease in 1982.<ref name=BGP_Paper/> They began by noting that the Generals' Problem can be reduced to solving a \"Commander and Lieutenants\" problem where loyal Lieutenants must all act in unison and that their action must correspond to what the Commander ordered in the case that the Commander is loyal:\n\n* One solution considers scenarios in which messages may be forged, but which will be ''Byzantine-fault-tolerant'' as long as the number of traitorous generals does not equal or exceed one third of the generals. The impossibility of dealing with one-third or more traitors ultimately reduces to proving that the one Commander and two Lieutenants problem cannot be solved, if the Commander is traitorous. To see this, suppose we have a traitorous Commander A, and two Lieutenants, B and C: when A tells B to attack and C to retreat, and B and C send messages to each other, forwarding A's message, neither B nor C can figure out who is the traitor, since it is not necessarily A\u2014another Lieutenant could have forged the message purportedly from A. It can be shown that if ''n'' is the number of generals in total, and ''t'' is the number of traitors in that ''n'', then there are solutions to the problem only when ''n'' &gt; 3''t'' and the communication is synchronous (bounded delay).<ref>{{cite journal | first1 = P. | last1 = Feldman | first2 = S. | last2 = Micali | url = http://people.csail.mit.edu/silvio/Selected%20Scientific%20Papers/Distributed%20Computation/An%20Optimal%20Probabilistic%20Algorithm%20for%20Byzantine%20Agreement.pdf | title = An optimal probabilistic protocol for synchronous Byzantine agreement | journal = SIAM J. Comput. | volume = 26 | issue = 4 | pages = 873\u2013933 | date = 1997 | doi = 10.1137/s0097539790187084 | access-date = 2012-06-14 | archive-url = https://web.archive.org/web/20160305012505/http://people.csail.mit.edu/silvio/Selected%20Scientific%20Papers/Distributed%20Computation/An%20Optimal%20Probabilistic%20Algorithm%20for%20Byzantine%20Agreement.pdf | archive-date = 2016-03-05 | url-status=live | df =  }}</ref>\n* A second solution requires unforgeable message signatures. For [[Critical system#Security critical|security-critical systems]], [[digital signature]]s (in modern computer systems, this may be achieved in practice using [[public-key cryptography]]) can provide Byzantine fault tolerance in the presence of an arbitrary number of traitorous generals. However, for [[safety-critical system]]s (where \"security\" addresses intelligent threats while \"safety\" addresses the inherent dangers of an activity or mission), simple error detecting codes, such as [[Cyclic redundancy check|CRCs]], provide weaker but often sufficient coverage at a much lower cost. This is true for both Byzantine and non-Byzantine faults. Furthermore, sometimes security measures weaken safety and vice versa. Thus, cryptographic digital signature methods are not a good choice for safety-critical systems, unless there is also a specific security threat as well.<ref name=\"PaulitschMorris2005\">{{cite book | last1=Paulitsch | first1=M. | title=2005 International Conference on Dependable Systems and Networks (DSN'05) | last2=Morris | first2=J. | last3=Hall | first3=B. | last4=Driscoll | first4=K. | last5=Latronico | first5=E. | last6=Koopman | first6=P. | chapter=Coverage and the Use of Cyclic Redundancy Codes in Ultra-Dependable Systems | year=2005 | pages=346\u2013355 | doi=10.1109/DSN.2005.31| isbn=978-0-7695-2282-1 }}</ref> While error detecting codes, such as CRCs, are better than cryptographic techniques, neither provide adequate coverage for active electronics in safety-critical systems. This is illustrated by the ''Schr\u00f6dinger CRC'' scenario where a CRC-protected message with a single Byzantine faulty bit presents different data to different observers and each observer sees a valid CRC.<ref name=\"DriscollHall2004\" /><ref name=\"DriscollHall2003\" />\n* Also presented is a variation on the first two solutions allowing Byzantine-fault-tolerant behavior in some situations where not all generals can communicate directly with each other.\n\nSeveral system architectures were designed c. 1980 that implemented Byzantine fault tolerance. These include: Draper's FTMP,<ref name=\"HopkinsLala1987\">{{ Cite book | last1=Hopkins | first1=Albert L. | title=The Evolution of Fault-Tolerant Computing | last2=Lala | first2=Jaynarayan H. | last3=Smith | first3=T. Basil | chapter=The Evolution of Fault Tolerant Computing at the Charles Stark Draper Laboratory, 1955\u201385 | volume=1 | year=1987 | pages=121\u2013140 | issn=0932-5581 | doi=10.1007/978-3-7091-8871-2_6| series=Dependable Computing and Fault-Tolerant Systems | isbn=978-3-7091-8873-6 }}</ref> Honeywell's MMFCS,<ref name=\"MMFCS\">{{ citation | last1 = Driscoll | first1 = Kevin | last2 = Papadopoulos | first2 = Gregory | last3 = Nelson | first3 = Scott | last4 = Hartmann | first4 = Gary | last5 = Ramohalli | first5 = Gautham | title = Multi-Microprocessor Flight Control System | publisher = AFWAL/FIGL U.S. Air Force Systems Command | date = 1984 | type = Technical Report | location = Wright-Patterson Air Force Base, OH 45433, USA | id = AFWAL-TR-84-3076 }}</ref> and SRI's SIFT.<ref name=\":0\">{{cite journal | title=SIFT: design and analysis of a fault-tolerant computer for aircraft control|journal=Microelectronics Reliability|volume=19|issue=3|year=1979|page=190|issn=0026-2714|doi=10.1016/0026-2714(79)90211-7}}</ref>\n\n== Advanced solutions ==\n\nIn 1999, Miguel Castro and [[Barbara Liskov]] introduced the \"Practical Byzantine Fault Tolerance\" (PBFT) algorithm,<ref>{{cite journal | first1 = M. | last1 = Castro | first2 = B. | last2 = Liskov | citeseerx = 10.1.1.127.6130 | title = Practical Byzantine Fault Tolerance and Proactive Recovery | publisher = [[Association for Computing Machinery]] | journal = ACM Transactions on Computer Systems | volume = 20 | issue = 4 | pages = 398\u2013461 | date = 2002 | doi = 10.1145/571637.571640}}</ref> which provides high-performance Byzantine state machine replication, processing thousands of requests per second with sub-millisecond increases in latency.\n\nAfter PBFT, several BFT protocols were introduced to improve its robustness and performance. For instance, Q/U,<ref>{{cite journal | first1 = M. | last1 = Abd-El-Malek | first2 = G. | last2 = Ganger | first3 = G. | last3 = Goodson | first4 = M. | last4 = Reiter | first5 = J. | last5 = Wylie | doi = 10.1145/1095809.1095817 | title = Fault-scalable Byzantine Fault-Tolerant Services | journal = ACM Sigops Operating Systems Review | volume = 39 | issue = 5 | pages = 59 | publisher = [[Association for Computing Machinery]] | conference = Symposium on Operating Systems Principles | date = 2005 }}</ref> HQ,<ref>{{cite conference | first1 = James | last1 = Cowling | first2 = Daniel | last2 = Myers | authorlink3 = Barbara Liskov | first3 = Barbara | last3 = Liskov | first4 = Rodrigo | last4 = Rodrigues | first5 = Liuba | last5 = Shrira | url = http://portal.acm.org/citation.cfm?id=1298455.1298473 | title = HQ Replication: A Hybrid Quorum Protocol for Byzantine Fault Tolerance | conference = Proceedings of the 7th [[USENIX]] Symposium on Operating Systems Design and Implementation | date = 2006 | isbn = 1-931971-47-1 | pages = 177\u2013190}}</ref> Zyzzyva,<ref>{{cite journal | first1 = Ramakrishna | last1 = Kotla | first2 = Lorenzo | last2 = Alvisi | first3 = Mike | last3 = Dahlin | first4 = Allen | last4 = Clement | first5 = Edmund | last5 = Wong | doi = 10.1145/1658357.1658358 | title = Zyzzyva: Speculative Byzantine Fault Tolerance | publisher = [[Association for Computing Machinery]] | journal = ACM Transactions on Computer Systems | volume = 27 | issue = 4 | pages = 1\u201339 | date = December 2009 }}</ref> and ABsTRACTs,<ref>{{cite conference | first1 = Rachid | last1 = Guerraoui | first2 = Nikola | last2 = Kne\u017eevic | first3 = Marko | last3 = Vukolic | first4 = Vivien | last4 = Qu\u00e9ma | url = http://infoscience.epfl.ch/record/144158 | title = The Next 700 BFT Protocols | conference = Proceedings of the 5th European conference on Computer systems | publisher = EuroSys | date = 2010 | access-date = 2011-10-04 | archive-url = https://web.archive.org/web/20111002225957/http://infoscience.epfl.ch/record/144158 | archive-date = 2011-10-02 | url-status=live | df =  }}</ref> addressed the performance and cost issues; whereas other protocols, like Aardvark<ref>{{cite conference|first1=A.|last1=Clement|first2=E.|last2=Wong|first3=L.|last3=Alvisi|first4=M.|last4=Dahlin|first5=M.|last5=Marchetti|url=http://www.usenix.org/events/nsdi09/tech/full_papers/clement/clement.pdf|title=Making Byzantine Fault Tolerant Systems Tolerate Byzantine Faults|publisher=[[USENIX]]|conference=Symposium on Networked Systems Design and Implementation|date=April 22\u201324, 2009|access-date=2010-02-17|archive-url=https://web.archive.org/web/20101225155052/https://www.usenix.org/events/nsdi09/tech/full_papers/clement/clement.pdf|archive-date=2010-12-25|url-status=live|df=}}</ref> and RBFT,<ref>{{cite conference|first1=P.-L.|last1=Aublin|first2=S.|last2=Ben Mokhtar|first3=V.|last3=Qu\u00e9ma|url=http://www.temple.edu/cis/icdcs2013/program.html|title=RBFT: Redundant Byzantine Fault Tolerance|publisher=[[International Conference on Distributed Computing Systems]]|conference=33rd IEEE International Conference on Distributed Computing Systems|date=July 8\u201311, 2013|url-status=dead|archiveurl=https://web.archive.org/web/20130805115252/http://www.temple.edu/cis/icdcs2013/program.html|archivedate=August 5, 2013}}</ref> addressed its robustness issues. Furthermore, Adapt<ref>{{Cite journal|last=Bahsoun|first=J. P.|last2=Guerraoui|first2=R.|last3=Shoker|first3=A.|date=2015-05-01|title=Making BFT Protocols Really Adaptive|journal=Parallel and Distributed Processing Symposium (IPDPS), 2015 IEEE International|pages=904\u2013913|doi=10.1109/IPDPS.2015.21|isbn=978-1-4799-8649-1|url=http://repositorio.inesctec.pt/handle/123456789/4107}}</ref> tried to make use of existing BFT protocols, through switching between them in an adaptive way, to improve system robustness and performance as the underlying conditions change. Furthermore, BFT protocols were introduced that leverage trusted components to reduce the number of replicas, e.g., A2M-PBFT-EA<ref>{{Cite journal|last=Chun|first=Byung-Gon|last2=Maniatis|first2=Petros|last3=Shenker|first3=Scott|last4=Kubiatowicz|first4=John|date=2007-01-01|title=Attested Append-only Memory: Making Adversaries Stick to Their Word|journal=Proceedings of Twenty-first ACM SIGOPS Symposium on Operating Systems Principles|series=SOSP '07|location=New York, NY, USA|publisher=ACM|pages=189\u2013204|doi=10.1145/1294261.1294280|isbn=9781595935915}}</ref> and MinBFT.<ref>{{Cite journal|last=Veronese|first=G. S.|last2=Correia|first2=M.|last3=Bessani|first3=A. N.|last4=Lung|first4=L. C.|last5=Verissimo|first5=P.|date=2013-01-01|title=Efficient Byzantine Fault-Tolerance|journal=IEEE Transactions on Computers|volume=62|issue=1|pages=16\u201330|doi=10.1109/TC.2011.221|issn=0018-9340|citeseerx=10.1.1.408.9972}}</ref>\n\nMotivated by PBFT, Tendermint BFT<ref>{{cite arxiv | first1 = E. | last1 = Buchman | first2 = J. | last2 = Kwon | first3 = Z. | last3 = Milosevic | title = The latest gossip on BFT consensus | eprint = 1807.04938 | date = 2018 | class = cs.DC }}</ref>  was introduced for partial asynchronous networks and it is mainly used for Proof of Stake Proof blockchains. Recently, [[Yongge Wang]]  showed that Tendermint BFT cannot achieve liveness in partial synchronous networks and proposed a more efficient BFT protocol BDLS<ref>{{cite journal | first1 = Yongge | last1 = Wang | title = Byzantine Fault Tolerance in Partially Connected Asynchronous Networks | journal = Cryptology ePrint Archive, Report 2019/1460 | publisher = IACR ePrint | date = 2019 | url=https://eprint.iacr.org/2019/1460/20200211:001341}}</ref> for partial synchronous networks.\n\n== BFT implementations ==\n\nOne example of BFT in use is [[bitcoin]], a peer-to-peer digital cash system.<ref>{{Cite web|url=https://bitcoin.org/en/|title=Bitcoin - Open source P2P money|website=bitcoin.org|language=en|access-date=2019-08-18}}</ref> The [[bitcoin network]] works in parallel to generate a [[blockchain]] with [[proof-of-work]] allowing the system to overcome Byzantine failures and reach a coherent global view of the system's state.\n\nSome aircraft systems, such as the Boeing 777 [[Aircraft Information Management System]] (via its [[ARINC]] 659 [[SAFEbus]] network),<ref name=\"Zurawski2015\">{{cite book | last1=M. | first1=Paulitsch | last2=Driscoll | first2=K. | editor-first=Richard | editor-last=Zurawski | title=Industrial Communication Technology Handbook, Second Edition | chapter-url=https://books.google.com/books?id=ppzNBQAAQBAJ | date=9 January 2015 | chapter=Chapter 48:SAFEbus | pages=48\u20131\u201348\u201326 | publisher=CRC Press | isbn=978-1-4822-0733-0}}</ref><ref name=\"HenzingerKirsch2001\">{{cite book | author1 = Thomas A. Henzinger | author2 = Christoph M. Kirsch | title = Embedded Software: First International Workshop, EMSOFT 2001, Tahoe City, CA, USA, October 8-10, 2001. Proceedings | url = http://www.csl.sri.com/papers/emsoft01/emsoft01.pdf | date = 26 September 2001 | publisher = Springer Science & Business Media | isbn = 978-3-540-42673-8 | pages = 307\u2013 | access-date = 2015-03-05 | archive-url = https://web.archive.org/web/20150922114036/http://www.csl.sri.com/papers/emsoft01/emsoft01.pdf | archive-date = 2015-09-22 | url-status=live | df =  }}</ref>\nthe Boeing 777 flight control system,<ref name=\"Yeh2001\">{{cite book | last1=Yeh | first1=Y.C. | title=20th DASC. 20th Digital Avionics Systems Conference (Cat. No.01CH37219) | chapter=Safety critical avionics for the 777 primary flight controls system | volume=1 | year=2001 | pages=1C2/1\u20131C2/11 | doi=10.1109/DASC.2001.963311| isbn=978-0-7803-7034-0 }}</ref> and the Boeing 787 flight control systems use Byzantine fault tolerance; because these are real-time systems, their Byzantine fault tolerance solutions must have very low latency. For example, SAFEbus can achieve Byzantine fault tolerance within the order of a microsecond of added latency.\n\nSome spacecraft flight systems such as that of the [[SpaceX Dragon]]<ref>{{Cite web |url=https://lwn.net/Articles/540368/ |title=ELC: SpaceX lessons learned [LWN.net]<!-- Bot generated title --> |access-date=2016-07-21 |archive-url=https://web.archive.org/web/20160805064218/http://lwn.net/Articles/540368/ |archive-date=2016-08-05 |url-status=live |df= }}</ref> consider Byzantine fault tolerance in their design.\n\nByzantine fault tolerance mechanisms use components that repeat an incoming message (or just its signature) to other recipients of that incoming message. All these mechanisms make the assumption that the act of repeating a message blocks the propagation of Byzantine symptoms. For systems that have a high degree of safety or security criticality, these assumptions must be proven to be true to an acceptable level of [[fault coverage]]. When providing proof through testing, one difficulty is creating a sufficiently wide range of signals with Byzantine symptoms.<ref name=\"NanyaGoosen1989\">{{cite journal |last1=Nanya|first1=T.|last2=Goosen|first2=H.A.|title=The Byzantine hardware fault model|journal=IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems|volume=8|issue=11|year=1989|pages=1226\u20131231|issn=0278-0070|doi=10.1109/43.41508}}</ref> Such testing likely will require specialized fault injectors.<ref name=\"MartinsGandhi2013\">{{cite book|last1=Martins|first1=Rolando|title=Middleware 2013|last2=Gandhi|first2=Rajeev|last3=Narasimhan|first3=Priya|last4=Pertet|first4=Soila|last5=Casimiro|first5=Ant\u00f3nio|last6=Kreutz|first6=Diego|last7=Ver\u00edssimo|first7=Paulo|chapter=Experiences with Fault-Injection in a Byzantine Fault-Tolerant Protocol|volume=8275|year=2013|pages=41\u201361|issn=0302-9743|doi=10.1007/978-3-642-45065-5_3|series=Lecture Notes in Computer Science|isbn=978-3-642-45064-8}}</ref><ref>{{cite patent | country = US | number = 7475318 | status = patent | title = Method for testing the sensitive input range of Byzantine filters | gdate = 2009-01-06 | fdate = 2006-01-27 | pridate = 2005-01-28 | inventor = Kevin R. Driscoll | assign1 = Honeywell International Inc. | class = G01R31/28 }}</ref>\n\n=== Software ===\n{{primary sources|section|date=January 2019}}\n\n* UpRight is an open source library for constructing services that tolerate both crashes (\"up\") and Byzantine behaviors (\"right\") that incorporates many of these protocols' innovations.<ref>{{ cite web | url = https://code.google.com/p/upright/ | archiveurl = https://web.archive.org/web/20160415055752/https://code.google.com/p/upright/ | archivedate = 2016-04-15 | title = Google Code repository for the UpRight replication library }}</ref>\n* The BFT-SMaRt library is a high-performance Byzantine fault-tolerant state machine replication library developed in Java. This library implements a protocol very similar to PBFT's, plus complementary protocols which offer state transfer and on-the-fly reconfiguration of hosts. BFT-SMaRt is the most recent effort to implement state machine replication, still being actively maintained.<ref>{{ cite web | url = https://bft-smart.github.io/library/ | archiveurl = https://web.archive.org/web/20171029200352/http://bft-smart.github.io/library/ |archivedate = 2017-10-29 | title = Google Code repository for the BFT-SMaRt replication library }}</ref>\n* [[Archistar]] utilizes a slim BFT layer for communication. It prototypes a secure multi-cloud storage system using Java licensed under LGPLv2. Focus lies on simplicity and readability, it aims to be the foundation for further research projects.<ref>{{ cite web | url = https://github.com/Archistar/archistar-core | archiveurl = https://web.archive.org/web/20150204123247/https://github.com/archistar/archistar-core | archivedate = 2015-02-04 | title = github repository for the Archistar project | date = 2019-05-28 }}</ref><ref>{{ cite web | url = https://github.com/Archistar/archistar-bft | archiveurl = https://web.archive.org/web/20170613060325/https://github.com/Archistar/archistar-bft | archivedate = 2017-06-13 | title = github repository for the Archistar project | date = 2019-04-28 }}</ref>\n* Askemos is a concurrent, garbage-collected, persistent programming platform atop of replicated state machines which tolerates Byzantine faults. It prototypes an execution environment facilitating [[Smart contracts]].<ref>{{ cite web | url = http://ball.askemos.org/ | archiveurl = https://web.archive.org/web/20160503082427/http://ball.askemos.org/ | archivedate = 2016-05-03 | title = Askemos home page }}</ref>\n\n== See also ==\n\n* [[Atomic commit]]\n* [[Brooks\u2013Iyengar algorithm]]\n* [[List of mathematical concepts named after places]]\n* [[List of terms relating to algorithms and data structures]]\n* [[Paxos (computer science)#Byzantine Paxos|Byzantine Paxos]]\n* [[Quantum Byzantine agreement]]\n* [[Two Generals Problem]]\n\n== References ==\n\n{{reflist|30em}}\n\n== External links ==\n\n* [https://web.archive.org/web/20080828060019/http://www.rkbexplorer.com/explorer/#display=mechanism%2D{http://resex.rkbexplorer.com/id/resilience-mechanism-65b5cef4} Byzantine Fault Tolerance in the RKBExplorer]\n\n[[Category:Public-key cryptography]]\n[[Category:Distributed computing problems]]\n[[Category:Fault-tolerant computer systems]]\n[[Category:Theory of computation]]\n", "name_user": "Aurora mc", "label": "unsafe", "comment": "", "url_page": "//en.wikipedia.org/wiki/Byzantine_fault"}
