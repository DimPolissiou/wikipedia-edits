{"title_page": "Arripis trutta", "text_new": "{{Speciesbox\n| image =Arripis trutta.jpg\n| image_caption = \n| taxonomy = Arripis trutta\n| authority = ([[Johann Reinhold Forster|J. R. Forster]], 1801)\n| synonyms = *''Sciaena trutta'' <small>Forster, 1801</small> \n*''Perca trutta'' <small>[[Louis Augustin Guillaume Bosc|Bosc]], 1802</small> \n*''Perca marginata'' <small>[[Georges Cuvier|Cuvier]], 1828</small> \n*''Arripis salar'' <small>([[John Richardson (naturalist)|Richardson]], 1839)</small> \n*''Centropristes sapidissimus'' <small>Richardson, 1842</small> \n*''Centropristes tasmanicus'' <small>[[Jacques Bernard Hombron|Hombron]] & [[Honor\u00e9 Jacquinot|Jacquinot]], 1853</small>\n| synonyms_ref = <ref name = Fishbase>{{Fishbase|Arripis|trutta|month=December|year=2019}}</ref>\n}}\n\n'''''Arripis trutta''''', known as '''kahawai''' in [[New Zealand]] and as the '''Australian salmon''' in [[Australia]], is one of four species of marine fish within the genus ''[[Arripis]]'', found in cooler waters around the south eastern and south western coasts of [[Australia]] and the New Zealand coastline.  Although it is referred to as a salmon in Australia and its species epithet ''trutta'' is the Latin for ''trout'', it is not related to [[salmon]]s or [[trout]]s of the family [[Salmonidae]]. Other common names for this species include Eastern Australian salmon, bay trout, black back, blackback salmon, buck, buck salmon, cocky salmon, colonial salmon, newfish, and salmon trout. \n\n==Description==\n''Arripis trutta'' is a streamlined fish with a long and slender body. There is a bony ridge edge of bone beneath and in front of each eye which has obvious serrations in smaller individuals. In larger fish the scales feel smooth. The lobes of the [[caudal fin]] are equivalent in length to the head. \nThese fish are dark bluish-green dorsally and silvery white ventrally. The juveniles have golden bars on their upper flanks and these break up into large spots as the fish matures. The [[pectoral fin]] is vivid yellow and the caudal and spiny part of the [[dorsal fin]] both have a blackish margin.<ref name = FofA>{{cite web | author = Bray, D.J. | year = 2018 | title = ''Arripis trutta'' | work = Fishes of Australia | accessdate = 21 April 2020 | url = http://136.154.202.208/home/species/406 | publisher = Museums Victoria}}</ref> There are 9 spines and 15-17 soft rays in the dorsal fin and 3 spinesand 9-10 soft rays in the [[anal fin]].The maximum [[Fish measurement|total length]] recorded is {{convert|89|cm|in}} although they are commonly a total length of around{{convert|47|cm|in}} and the maximum recorded weight is {{convert|9.4|kg|lbs}}.<ref name = Fishbase/> \n\n==Distribution== \n''Arripis trutta'' is found in the south western Pacific Ocean around Australia and New Zealand.>ref name = Fishbase/> In Australia they are found from [[Moreton Bay]] in Queensland to western [[Victoria (Australia)|Victoria]] and northern [[Tasmania]], woth infrequent records at [[Kangaroo Island]] in [[South Australia]]. They are also found around [[Lord Howe Island]] and [[Norfolk Island]] in the [[Tasman Sea]].<ref name = FofA/> In Newe Zealnd they are distributed around the coast but are more common north of [[Kaikoura]] on the [[South Island]].<ref name = OH>{{cite web | url = https://www.oceanhunter.co.nz/NEED+TO+KNOW/Species+Identification/Kahawai.html | title = Kahawai | accessdate = 21 April 2020 | publisher = Ocean Hunter}}</ref> They are also found around the [[Chatham Islands]] and [[Kermadec Islands]].<ref name = Fishbase/>\n\n==Habitat and biology==\n''Arripis trutta'' are migratory fish which may migrate long distances, sometimes thousand of kilometres. The adults congregate in very large schools off oceanic beaches and exposed coasts form vast schools along oceanic beaches and exposed areas coastal areas.<ref name = FofA/> They will enter rivers.<ref name = Fishbase/> The juveniles live in smaller schools in more sheltered areas such as bays and estuaries, and these mostly occur in the more southerly areas in which this species occurs. It is a carnivorous species which feeds mainly on small pelagic fish and pelagic crustaceans such as [[krill]].<ref name = FofA/> They are highly visual predators, preying on a diverse varietywhich eat a variety of crustaceans and [[polychaetes]] during their juvenile phase, however, adults shift their preferred prey to small schooling fish, [[baitfish]] such as [[pilchard]]s, [[sprat]]s and [[anchovy|anchovies]]. There is some evidence that the diet of ''A. trutta'' has undergone a marked shift since the  late 20th Century, studies conducted during 1950s and 1960s found that the adults fed largely on krill and [[squid]], which are animals associated with cooler waters. Studies during the early 21st Century have shown that the main prey taken is small pelagic baitfish. It is though that this shift is a result of long term changes in the [[East Australian Current]] which brings warmer waters from the [[Coral Sea]] and has extended farther south since the 1990s. It is further thought that his \u201cmulti-decadal southward penetration of the EAC\u201d is one of the more obvious indications of [[global warming]] and the recorded change in the diet of ''A trutta'' forms a biological record of global warming.<ref name = Dubbins>{{cite web | url = https://www.fishingworld.com.au/news/fish-facts-australian-salmon | title = Fish Facts: Australian salmon | author = Dr Ben Diggles | date = 14 September 2016 | accessdate = 21 April 2020 | publisher = Fishing World}}</ref>  \n\n''Arripis trutta'' are preyed on by larger apex predators such as seals, dolphins and sharks. The feeding salmon schools push the schools of the fish they prey on towards the surface making them accessible to seabirds, In this way this species has an important ecological role in facilitating transfer of energyamong the upper levels of the pelagic food chain in inshore ecosystems.<ref name = Dubbins/> An example is the [[white-fronted tern]] (''Sterna striata'') which has the colloquial name \"kahawai bird\" because often feeds on shoaling fish in association with kahawai, gulls and shearwaters. Fishermen hunting for schools of kahawai to [[Trolling (fishing)|troll]] look out for the flocks of white-fronted terns feeding in association with the predatory fish.<ref name = NZBirds>{{cite web | url = http://nzbirdsonline.org.nz/species/white-fronted-tern | title = White-fronted tern | accessdate = 21 April 2020 | publisher = NZ Birds Online}}</ref>\n\nThe Australian population of this species [[Spawn (biology)|spawns]] in the surf zone between [[Lakes Entrance]] in Victoria and [[Bermagui, New South Wales|Bermagui]] in [[New South Wales]] in the late spring and summer. The first spawn when they are around four years old and have attained a length of {{convert|39|cm|in}}/<ref name = MV>{{cite web | url = https://collections.museumvictoria.com.au/species/13728 | title = ''Arripis trutta'' (Forster, 1801), Eastern Australian Salmon | accessdate = 21 April 2020 | publisher = Museums Victoria}}</ref> They can live for up to 26 years.<ref name = Fishbase/>\n\n==Fisheries==\n''Arripis trutta'' are caught in coastal waters, frequently in the vicinity of estuaries and off coastal beaches. Most of the commercial landings are caught using [[Seine fishing|purse seines]] and spotter planes may be used to find the large schools They may also be taken as [[bycatch]] of purse seine and trawl fisheries pursuing other schooling species like [[Lutjanidae|snapper]], [[mackerel]] and [[trevally]].  Although they are fished for throughout southern Australia, the main landings are in southern New South Wales and Eastern Victoria. The flesh of this species is not very popular with consumers and a high proportion of the landings have been used as pet-food or bait.<ref name = gfbf>{{cite web | url = https://goodfishbadfish.com.au/?fish=australian-salmon | title = Australian Salmon | accessdate = 21 April 2020 | publisher = goodfishbadfish}}</ref> In New Zealand the principal commercial fishing areas are north of Kaikoura in the South Island, off the coast of [[North Island]] and in the [[Cook Strait]].<ref name = sfnz>{{cite web | url = https://www.seafood.co.nz/show-species/kahawai/ | title = Kahawai | accessdate = 21 April 2020 | publisher = Seafood New Zealand}}</ref> Fisheries New Zealand manages that nation's fishery to maintain the population of ''A trutta'' at roughly 52% of the stock which was present before modern commercial fisheries began and in 2019 the population was well above that target.<ref name = FNZ>{{cite web | url = https://www.mpi.govt.nz/travel-and-recreation/fishing/fish-species/kahawai/ | title = Kahawai | accessdate = 21 April 2020 | publisher = Fisheries New Zealand}}</ref>\n\n===Recreational fisheries===\n''Arripis trutta'' are highly prized by recreational fishermen, especially for anglers fishing from beaches and rocks. Anglers tend to catch this species using light tackle or by [[fly fishing]] and I is said to be a \"sporting catch\".<ref name = sea-ex>{{cite web | url = http://www.sea-ex.com/fishphotos/salmon_australian-catching-fishing.htm | title = Catching & Fishing for Australian Salmon (Arripis trutta) | accessdate = 2 April 2020 | publisher = Sea-Ex}}</ref>\n\n==Species description==\n''Arripis trutta''  was first formally [[Species description|described]] in 1801 as ''Sciaena trutta'' by Marcus Elieser Bloch and Johann Gottlob Theaenus Schneider with the [[Type locality (biology)|type locality]] given as the Cook Strait.<ref name = CofF>{{Cof record|spid=35071|title=''Sciaena trutta''|access-date=21 April 2020}}</ref>\n\n==References==\n{{Reflist}}\n\n==External links==\n* [https://www.youtube.com/watch?v=JRPDaWNmlcQ Juvenile Eastern Australian Salmon video on Youtube]\n{{Non-Endemic Marine Fish of New Zealand}}\n{{Taxonbar|from=Q14245820}}\n\n[[Category:Arripidae]]\n[[Category:Fish of the Pacific Ocean]]\n[[Category:Fish of Australia]]\n[[Category:Marine fauna of Eastern Australia]]\n[[Category:Marine fish of New Zealand]]\n[[Category:Fish described in 1801]]\n[[Category:Taxa named by Johann Reinhold Forster]]\n[[Category:Saltwater Game fish]]\n", "text_old": "{{Speciesbox\n| image =Arripis trutta.jpg\n| image_caption = \n| taxonomy = Arripis trutta\n| authority = ([[Johann Reinhold Forster|J. R. Forster]], 1801)\n| synonyms = *''Sciaena trutta'' <small>Forster, 1801</small> \n*''Perca trutta'' <small>[[Louis Augustin Guillaume Bosc|Bosc]], 1802</small> \n*''Perca marginata'' <small>[[Georges Cuvier|Cuvier]], 1828</small> \n*''Arripis salar'' <small>([[John Richardson (naturalist)|Richardson]], 1839)</small> \n*''Centropristes sapidissimus'' <small>Richardson, 1842</small> \n*''Centropristes tasmanicus'' <small>[[Jacques Bernard Hombron|Hombron]] & [[Honor\u00e9 Jacquinot|Jacquinot]], 1853</small>\n| synonyms_ref = <ref name = Fishbase>{{Fishbase|Arripis|trutta|month=December|year=2019}}</ref>\n}}\n\n'''''Arripis trutta''''', known as '''kahawai''' in [[New Zealand]] and as the '''Australian salmon''' in [[Australia]], is one of four species of marine fish within the genus ''[[Arripis]]'', found in cooler waters around the south eastern and south western coasts of [[Australia]] and the New Zealand coastline.  Although it is referred to as a salmon in Australia and its species epithet ''trutta'' is the Latin for ''trout'', it is not related to [[salmon]]s or [[trout]]s of the family [[Salmonidae]]. Other common names for this species include Eastern Australian salmon, bay trout, black back, blackback salmon, buck, buck salmon, cocky salmon, colonial salmon, newfish, and salmon trout. \n\n==Description==\n''Arripis trutta'' is a streamlined fish with a long and slender body. There is a bony ridge edge of bone beneath and in front of each eye which has obvious serrations in smaller individuals. In larger fish the scales feel smooth. The lobes of the [[caudal fin]] are equivalent in length to the head. \nThese fish are dark bluish-green dorsally and silvery white ventrally. The juveniles have golden bars on their upper flanks and these break up into large spots as the fish matures. The [[pectoral fin]] is vivid yellow and the caudal and spiny part of the [[dorsal fin]] both have a blackish margin.<ref name = FofA>{{cite web | author = Bray, D.J. | year = 2018 | title = ''Arripis trutta'' | work = Fishes of Australia | accessdate = 21 April 2020 | url = http://136.154.202.208/home/species/406 | publisher = Museums Victoria}}</ref> There are 9 spines and 15-17 soft rays in the dorsal fin and 3 spinesand 9-10 soft rays in the [[anal fin]].The maximum [[Fish measurement|total length]] recorded is {{convert|89|cm|in}} although they are commonly a total length of around{{convert|47|cm|in}} and the maximum recorded weight is {{convert|9.4|kg|lbs}}.<ref name = Fishbase/> \n\n==Distribution== \n''Arripis trutta'' is found in the south western Pacific Ocean around Australia and New Zealand.>ref name = Fishbase/> In Australia they are found from [[Moreton Bay]] in Queensland to western [[Victoria (Australia)|Victoria]] and northern [[Tasmania]], woth infrequent records at [[Kangaroo Island]] in [[South Australia]]. They are also found around [[Lord Howe Island]] and [[Norfolk Island]] in the [[Tasman Sea]].<ref name = FofA/> In Newe Zealnd they are distributed around the coast but are more common north of [[Kaikoura]] on the [[South Island]].<ref name = OH>{{cite web | url = https://www.oceanhunter.co.nz/NEED+TO+KNOW/Species+Identification/Kahawai.html | title = Kahawai | accessdate = 21 April 2020 | publisher = Ocean Hunter}}</ref> They are also found around the [[Chatham Islands]] and [[Kermadec Islands]].<ref name = Fishbase/>\n\n==Habitat and biology==\n''Arripis trutta'' are migratory fish which may migrate long distances, sometimes thousand of kilometres. The adults congregate in very large schools off oceanic beaches and exposed coasts form vast schools along oceanic beaches and exposed areas coastal areas.<ref name = FofA/> They will enter rivers.<ref name = Fishbase/> The juveniles live in smaller schools in more sheltered areas such as bays and estuaries, and these mostly occur in the more southerly areas in which this species occurs. It is a carnivorous species which feeds mainly on small pelagic fish and pelagic crustaceans such as [[krill]].<ref name = FofA/> They are highly visual predators, preying on a diverse varietywhich eat a variety of crustaceans and [[polychaetes]] during their juvenile phase, however, adults shift their preferred prey to small schooling fish, [[baitfish]] such as [[pilchard]]s, [[sprat]]s and [[anchovy|anchovies]]. There is some evidence that the diet of ''A. trutta'' has undergone a marked shift since the  late 20th Century, studies conducted during 1950s and 1960s found that the adults fed largely on krill and [[squid]], which are animals associated with cooler waters. Studies during the early 21st Century have shown that the main prey taken is small pelagic baitfish. It is though that this shift is a result of long term changes in the [[East Australian Current]] which brings warmer waters from the [[Coral Sea]] and has extended farther south since the 1990s. It is further thought that his \u201cmulti-decadal southward penetration of the EAC\u201d is one of the more obvious indications of [[global warming]] and the recorded change in the diet of ''A trutta'' forms a biological record of global warming.<ref name = Dubbins>{{cite web | url = https://www.fishingworld.com.au/news/fish-facts-australian-salmon | title = Fish Facts: Australian salmon | author = Dr Ben Diggles | date = 14 September 2016 | accessdate = 21 April 2020 | publisher = Fishing World}}</ref>  \n\n''Arripis trutta'' are preyed on by larger apex predators such as seals, dolphins and sharks. The feeding salmon schools push the schools of the fish they prey on towards the surface making them accessible to seabirds, In this way this species has an important ecological role in facilitating transfer of energyamong the upper levels of the pelagic food chain in inshore ecosystems.<ref name = Dubbins/> An example is the [[white-fronted tern]] (''Sterna striata'') which has the colloquial name \"kahawai bird\" because often feeds on shoaling fish in association with kahawai, gulls and shearwaters. Fishermen hunting for schools of kahawai to [[Trolling (fishing)|troll]] look out for the flocks of white-fronted terns feeding in association with the predatory fish.<ref name = NZBirds>{{cite web | url = http://nzbirdsonline.org.nz/species/white-fronted-tern | title = White-fronted tern | accessdate = 21 April 2020 | publisher = NZ Birds Online}}</ref>\n\nThe Australian population of this species [[Spawn (biology)|spawns]] in the surf zone between [[Lakes Entrance]] in Victoria and [[Bermagui]] in [[New South Wales]] in the late spring and summer. The first spawn when they are around four years old and have attained a length of {{convert|39|cm|in}}/<ref name = MV>{{cite web | url = https://collections.museumvictoria.com.au/species/13728 | title = ''Arripis trutta'' (Forster, 1801), Eastern Australian Salmon | accessdate = 21 April 2020 | publisher = Museums Victoria}}</ref> They can live for up to 26 years.<ref name = Fishbase/>\n\n==Fisheries==\n''Arripis trutta'' are caught in coastal waters, frequently in the vicinity of estuaries and off coastal beaches. Most of the commercial landings are caught using [[Seine fishing|purse seines]] and spotter planes may be used to find the large schools They may also be taken as [[bycatch]] of purse seine and trawl fisheries pursuing other schooling species like [[snapper]], [[mackerel]] and [[trevally]].  Although they are fished for throughout southern Australia, the main landings are in southern New South Wales and Eastern Victoria. The flesh of this species is not very popular with consumers and a high proportion of the landings have been used as pet-food or bait.<ref name = gfbf>{{cite web | url = https://goodfishbadfish.com.au/?fish=australian-salmon | title = Australian Salmon | accessdate = 21 April 2020 | publisher = goodfishbadfish}}</ref> In New Zealand the principal commercial fishing areas are north of Kaikoura in the South Island, off the coast of [[North Island]] and in the [[Cook Strait]].<ref name = sfnz>{{cite web | url = https://www.seafood.co.nz/show-species/kahawai/ | title = Kahawai | accessdate = 21 April 2020 | publisher = Seafood New Zealand}}</ref> Fisheries New Zealand manages that nation's fishery to maintain the population of ''A trutta'' at roughly 52% of the stock which was present before modern commercial fisheries began and in 2019 the population was well above that target.<ref name = FNZ>{{cite web | url = https://www.mpi.govt.nz/travel-and-recreation/fishing/fish-species/kahawai/ | title = Kahawai | accessdate = 21 April 2020 | publisher = Fisheries New Zealand}}</ref>\n\n===Recreational fisheries===\n''Arripis trutta'' are highly prized by recreational fishermen, especially for anglers fishing from beaches and rocks. Anglers tend to catch this species using light tackle or by [[fly fishing]] and I is said to be a \"sporting catch\".<ref name = sea-ex>{{cite web | url = http://www.sea-ex.com/fishphotos/salmon_australian-catching-fishing.htm | title = Catching & Fishing for Australian Salmon (Arripis trutta) | accessdate = 2 April 2020 | publisher = Sea-Ex}}</ref>\n\n==Species description==\n''Arripis trutta''  was first formally [[Species description|described]] in 1801 as ''Sciaena trutta'' by Marcus Elieser Bloch and Johann Gottlob Theaenus Schneider with the [[Type locality (biology)|type locality]] given as the Cook Strait.<ref name = CofF>{{Cof record|spid=35071|title=''Sciaena trutta''|access-date=21 April 2020}}</ref>\n\n==References==\n{{Reflist}}\n\n==External links==\n* [https://www.youtube.com/watch?v=JRPDaWNmlcQ Juvenile Eastern Australian Salmon video on Youtube]\n{{Non-Endemic Marine Fish of New Zealand}}\n{{Taxonbar|from=Q14245820}}\n\n[[Category:Arripidae]]\n[[Category:Fish of the Pacific Ocean]]\n[[Category:Fish of Australia]]\n[[Category:Marine fauna of Eastern Australia]]\n[[Category:Marine fish of New Zealand]]\n[[Category:Fish described in 1801]]\n[[Category:Taxa named by Johann Reinhold Forster]]\n[[Category:Saltwater Game fish]]\n", "name_user": "Rodw", "label": "safe", "comment": "Disambiguated:Bermagui\u2192Bermagui, New South Wales,snapper\u2192Lutjanidae", "url_page": "//en.wikipedia.org/wiki/Arripis_trutta"}
{"title_page": "Ashwani Kumar (police officer)", "text_new": "{{About|the scientist|other people with a similar name|Ashwani Kumar (disambiguation){{!}}Ashwani Kumar}}\n{{Use dmy dates|date=July 2017}}\n{{Use Indian English|date=July 2017}}\n{{Infobox officeholder\n| name = Ashwani Kumar \n| image = The Director, CBI, Shri Ashwani Kumar addressing the passing out Investiture Ceremony of directly recruited Sub-Inspectors of CBI, at CBI Academy Ghaziabad, Uttar Pradesh on November 14, 2009.jpg\n| office = [[List of Governors of Nagaland|Governor of Nagaland]]\n| term_start = 21 March 2013\n| term_end = 27 June 2014 \n| predecessor = [[Nikhil Kumar]]\n| successor = Padmanabha Balakrishna Acharya\n| office1 = [[List of Governors of Manipur|Governor of Manipur]]\n| term_start1 = 29 July 2013\n| term_end1 = 23 December 2013\n| predecessor1 = [[Gurbachan Jagat]]\n| successor1 = [[Vinod Duggal]]\n| office2 = Director, [[Central Bureau of Investigation|CBI]]\n| term_start2 = 2 August 2008 \n| term_end2 = 30 November 2010\n| predecessor2 = Vijay Shankar\n| successor2 = [[A P Singh]]\n| office3 = [[Director General of Police|DGP]], [[Himachal Pradesh]]\n| term_start3 = August 2006 \n| term_end3 = July 2008\n| predecessor3 = \n| successor3 = \n|birth_date     = {{Birth date and age|df=y|1950|11|15}}\n|birth_place    = Nahan, [[Himachal Pradesh]]\n|party          =  \n| residence = \n| religion =\n| spouse = Chandak A.K.\n| children = Abhishek A.K.<ref>{{cite web|url=http://www.realnewslive.org/eng/2012/03/10/life-well-spent-according-to-spiritual-values-former-cbi-director/ |title=Life well-spent, according to spiritual values: Former CBI Director |work=realnewslive.org |year=2012 |quote=my son Abhishek |accessdate=11 June 2013 |url-status=dead |archiveurl=https://web.archive.org/web/20130814050150/http://www.realnewslive.org/eng/2012/03/10/life-well-spent-according-to-spiritual-values-former-cbi-director/ |archivedate=14 August 2013 }}</ref>\n|alma_mater  = [[Himachal Pradesh University]], [[National Defence College, India|National Defence College]], [[Rashtriya Indian Military College]]\n| website = [http://nagaland.nic.in/functionaries/rajbhavan/governor.htm Official Website]\n}}\n\n'''Ashwani Kumar''' is a retired [[Indian Police Service|IPS]] officer and the former [[Governors of states of India|Governor]] of the [[States and territories of India|Indian state]] of [[List of Governors of Nagaland|Nagaland]],<ref>{{cite web |url= http://indiatoday.intoday.in/story/ashwani-kumar-appointed-nagaland-governor-s-c-jamir-odisha-governor/1/257214.html |title=Ex-CBI Director Ashwani Kumar appointed Nagaland Governor, S C Jamir in Odisha : North, News - India Today|work=indiatoday.intoday.in |year=2013 |quote=A 1963-batch IPS officer, 72-year-old Kumar was appointed as Governor of Nagaland |accessdate=11 June 2013}}</ref> having briefly served as [[List of Governors of Manipur|Governor of Manipur]] during 2013.<ref>{{cite web |url= http://www.thehindu.com/news/national/other-states/ashwani-kumar-sworn-in-as-governor-of-manipur/article4966677.ece |title=Ashwani Kumar sworn in as Governor of Manipur|work=thehindu.com |year=2013 |quote=Ashwani Kumar, the Governor of Nagaland was sworn in as the Governor of Manipur on Monday in a simple but impressive function at Raj Bhavan.  |accessdate=2 October 2013}}</ref>\n\nHe was the [[Director General of Police|DGP]] of [[Himachal Pradesh]] from August 2006 to July 2008<ref>{{cite web |url= http://articles.timesofindia.indiatimes.com/2008-07-31/india/27921034_1_ips-officer-cbi-director-officer-of-rajasthan-cadre |title=Himachal DGP Ashwani Kumar is new CBI Director - Times Of India|work=indiatimes.com |year=2008 |quote=Kumar, a 1973 batch IPS officer who is now the DGP of Himachal Pradesh, |accessdate=11 June 2013}}</ref> and was the Director of [[Central Bureau of Investigation|CBI]] between 2 August 2008 and 30 November 2010.<ref>{{cite web |url=http://cbi.nic.in/history.php |title=Central Bureau Of Investigation |work=cbi.nic.in |year=2013 |quote=Shri Ashwani Kumar 02/08/08-30/11/10 |accessdate=11 June 2013 |archive-url=https://web.archive.org/web/20110924144539/http://cbi.nic.in/history.php |archive-date=24 September 2011 |url-status=dead }}</ref><ref>{{cite web |url= http://www.indianexpress.com/news/cbi-chief-ashwani-kumar-gets-4month-extension/654776/ |title=CBI chief Ashwani Kumar gets 4-month extension - Indian Express |first= Neeraj |last=Chauhan |work=indianexpress.com |year=2010 |quote=Kumar had been appointed to the post on August 2, 2008 |accessdate=11 June 2013}}</ref>\n\n==References==\n{{Reflist}}\n\n{{s-start}}\n{{s-gov}}\n{{succession box\n| before= [[Nikhil Kumar]]\n| title=[[List of Governors of Nagaland|Governor of Nagaland]]\n| years= March 2013 \u2013 June 2014\n| after= [[Vakkom Purushothaman]]\n}}\n{{succession box\n| before= [[Gurbachan Jagat]]\n| title=[[List of Governors of Manipur|Governor of Manipur]]\n| years= July \u2013 December 2013\n| after= [[Vinod Duggal]]\n}}\n{{s-end}}\n\n{{Current Indian governors}}\n\n{{DEFAULTSORT:Kumar, Ashwani}}\n[[Category:1950 births]]\n[[Category:Living people]]\n[[Category:Indian police chiefs]]\n[[Category:Governors of Nagaland]]\n[[Category:Governors of Manipur]]\n[[Category:Rashtriya Indian Military College alumni]]\n[[Category:Directors of the Central Bureau of Investigation]]\n", "text_old": "{{About|the scientist|other people with a similar name|Ashwani Kumar (disambiguation){{!}}Ashwani Kumar}}\n{{Use dmy dates|date=July 2017}}\n{{Use Indian English|date=July 2017}}\n{{Infobox officeholder\n| name = Ashwani Kumar \n| image = The Director, CBI, Shri Ashwani Kumar addressing the passing out Investiture Ceremony of directly recruited Sub-Inspectors of CBI, at CBI Academy Ghaziabad, Uttar Pradesh on November 14, 2009.jpg\n| office = [[List of Governors of Nagaland|Governor of Nagaland]]\n| term_start = 21 March 2013\n| term_end = 27 June 2014 \n| predecessor = [[Nikhil Kumar]]\n| successor = Padmanabha Balakrishna Acharya\n| office1 = [[List of Governors of Manipur|Governor of Manipur]]\n| term_start1 = 29 July 2013\n| term_end1 = 23 December 2013\n| predecessor1 = [[Gurbachan Jagat]]\n| successor1 = [[Vinod Duggal]]\n| office2 = Director, [[Central Bureau of Investigation|CBI]]\n| term_start2 = 2 August 2008 \n| term_end2 = 30 November 2010\n| predecessor2 = Vijay Shankar\n| successor2 = [[A P Singh]]\n| office3 = [[Director General of Police|DGP]], [[Himachal Pradesh]]\n| term_start3 = August 2006 \n| term_end3 = July 2008\n| predecessor3 = \n| successor3 = \n|birth_date     = {{Birth date and age|df=y|1950|11|15}}\n|birth_place    = Nahan, [[Himachal Pradesh]]\n|party          =  \n| residence = \n| religion =\n| spouse = Chandak A.K.\n| children = Abhishek A.K.<ref>{{cite web|url=http://www.realnewslive.org/eng/2012/03/10/life-well-spent-according-to-spiritual-values-former-cbi-director/ |title=Life well-spent, according to spiritual values: Former CBI Director |work=realnewslive.org |year=2012 |quote=my son Abhishek |accessdate=11 June 2013 |url-status=dead |archiveurl=https://web.archive.org/web/20130814050150/http://www.realnewslive.org/eng/2012/03/10/life-well-spent-according-to-spiritual-values-former-cbi-director/ |archivedate=14 August 2013 }}</ref>\n|alma_mater  = [[Himachal Pradesh University]], [[National Defence College, India|National Defence College]], [[Rashtriya Indian Military College]]\n| website = [http://nagaland.nic.in/functionaries/rajbhavan/governor.htm Official Website]\n}}\n\n'''Ashwani Kumar''' is a retired [[Indian Police Service|IPS]] officer and the former [[Governors of states of India|Governor]] of the [[States and territories of India|Indian state]] of [[List of Governors of Nagaland|Nagaland]],<ref>{{cite web |url= http://indiatoday.intoday.in/story/ashwani-kumar-appointed-nagaland-governor-s-c-jamir-odisha-governor/1/257214.html |title=Ex-CBI Director Ashwani Kumar appointed Nagaland Governor, S C Jamir in Odisha : North, News - India Today|work=indiatoday.intoday.in |year=2013 |quote=A 1963-batch IPS officer, 72-year-old Kumar was appointed as Governor of Nagaland |accessdate=11 June 2013}}</ref> having briefly served as [[List of Governors of Manipur|Governor of Manipur]] during 2013.<ref>{{cite web |url= http://www.thehindu.com/news/national/other-states/ashwani-kumar-sworn-in-as-governor-of-manipur/article4966677.ece |title=Ashwani Kumar sworn in as Governor of Manipur|work=thehindu.com |year=2013 |quote=Ashwani Kumar, the Governor of Nagaland was sworn in as the Governor of Manipur on Monday in a simple but impressive function at Raj Bhavan.  |accessdate=2 October 2013}}</ref>\n\nHe was the [[Director General of Police|DGP]] of [[Himachal Pradesh]] from August 2006 to July 2008<ref>{{cite web |url= http://articles.timesofindia.indiatimes.com/2008-07-31/india/27921034_1_ips-officer-cbi-director-officer-of-rajasthan-cadre |title=Himachal DGP Ashwani Kumar is new CBI Director - Times Of India|work=indiatimes.com |year=2008 |quote=Kumar, a 1973 batch IPS officer who is now the DGP of Himachal Pradesh, |accessdate=11 June 2013}}</ref> and had worked as the Director of [[Central Bureau of Investigation|CBI]] form 2 August 2008 to 30 November 2010.<ref>{{cite web |url=http://cbi.nic.in/history.php |title=Central Bureau Of Investigation |work=cbi.nic.in |year=2013 |quote=Shri Ashwani Kumar 02/08/08-30/11/10 |accessdate=11 June 2013 |archive-url=https://web.archive.org/web/20110924144539/http://cbi.nic.in/history.php |archive-date=24 September 2011 |url-status=dead }}</ref><ref>{{cite web |url= http://www.indianexpress.com/news/cbi-chief-ashwani-kumar-gets-4month-extension/654776/ |title=CBI chief Ashwani Kumar gets 4-month extension - Indian Express |first= Neeraj |last=Chauhan |work=indianexpress.com |year=2010 |quote=Kumar had been appointed to the post on August 2, 2008 |accessdate=11 June 2013}}</ref>\n\n==References==\n{{Reflist}}\n\n{{s-start}}\n{{s-gov}}\n{{succession box\n| before= [[Nikhil Kumar]]\n| title=[[List of Governors of Nagaland|Governor of Nagaland]]\n| years= March 2013 \u2013 June 2014\n| after= [[Vakkom Purushothaman]]\n}}\n{{succession box\n| before= [[Gurbachan Jagat]]\n| title=[[List of Governors of Manipur|Governor of Manipur]]\n| years= July \u2013 December 2013\n| after= [[Vinod Duggal]]\n}}\n{{s-end}}\n\n{{Current Indian governors}}\n\n{{DEFAULTSORT:Kumar, Ashwani}}\n[[Category:1950 births]]\n[[Category:Living people]]\n[[Category:Indian police chiefs]]\n[[Category:Governors of Nagaland]]\n[[Category:Governors of Manipur]]\n[[Category:Rashtriya Indian Military College alumni]]\n[[Category:Directors of the Central Bureau of Investigation]]\n", "name_user": "CRL956", "label": "safe", "comment": "fixed grammatical / spelling issues", "url_page": "//en.wikipedia.org/wiki/Ashwani_Kumar_(police_officer)"}
{"title_page": "Fourier optics", "text_new": "{{See also|Huygens\u2013Fresnel principle|geometrical optics}}\n\n'''Fourier optics''' is the study of classical [[optics]] using [[Fourier transform]]s (FTs), in which the waveform being considered is regarded as made up of a combination, or ''[[Superposition principle|superposition]]'', of plane waves. It has some parallels to the [[Huygens\u2013Fresnel principle]], in which the wavefront is regarded as being made up of a combination of spherical wavefronts whose sum is the wavefront being studied. A key difference is that Fourier optics considers the plane waves to be natural modes of the propagation medium, as opposed to Huygens\u2013Fresnel, where the spherical waves originate in the physical medium. \n\nA curved phasefront may be synthesized from an infinite number of these \"natural modes\" i.e., from plane wave phasefronts oriented in different directions in space.  Far from its sources, an expanding spherical wave is locally tangent to a planar phase front (a single plane wave out of the infinite spectrum), which is transverse to the radial direction of propagation.  In this case, a [[Fraunhofer diffraction]] pattern is created, which emanates from a single spherical wave phase center.  In the near field, no single well-defined spherical wave phase center exists, so the wavefront isn't locally tangent to a spherical ball.  In this case, a [[Fresnel diffraction]] pattern would be created, which emanates from an ''extended'' source, consisting of a distribution of (physically identifiable) spherical wave sources in space.  In the near field, a full spectrum of plane waves is necessary to represent the Fresnel near-field wave, ''even locally''.  A \"wide\" [[wave]] moving forward (like an expanding ocean wave coming toward the shore) can be regarded as an infinite number of \"[[Wave function|plane wave modes]]\", all of which could (when they collide with something in the way) scatter independently of one other. These mathematical simplifications and calculations are the realm of [[Fourier analysis|Fourier analysis and synthesis]] &ndash; together, they can describe what happens when light passes through various slits, lenses or mirrors curved one way or the other, or is fully or partially reflected.\n\nFourier optics forms much of the theory behind [[image processing|image processing techniques]], as well as finding applications where information needs to be extracted from optical sources such as in [[quantum optics]]. To put it in a slightly more complex way, similar to the concept of ''[[frequency]]'' and ''[[Time in physics|time]]'' used in traditional [[Fourier transform|Fourier transform theory]], Fourier optics makes use of the [[spatial frequency]] domain (''k<sub>x</sub>'', ''k<sub>y</sub>'') as the conjugate of the spatial (''x'', ''y'') domain. Terms and concepts such as transform theory, spectrum, bandwidth, window functions and sampling from one-dimensional [[signal processing]] are commonly used.\n\n== Propagation of light in homogeneous, source-free media ==\n\nLight can be described as a waveform propagating through free space (vacuum) or a material medium (such as air or glass). Mathematically, the (real valued) amplitude of one wave component is represented by a scalar wave function ''u'' that depends on both space and time:\n\n:<math> u = u(\\mathbf{r},t)</math>\n\nwhere\n\n:<math> \\mathbf{r} = (x,y,z) </math>\n\nrepresents position in three dimensional space, and ''t'' represents time.\n\n===The wave equation===\n\nFourier optics begins with the homogeneous, scalar [[wave equation]] (valid in source-free regions):\n\n:<math>\n\\left(\\nabla^2-\\frac{1}{c^2}\\frac{\\partial^2}{\\partial{t}^2}\\right)u(\\mathbf{r},t)=0.\n</math>\n\nwhere ''u''('''r''',''t'') is a [[real number|real valued]] Cartesian component of an electromagnetic wave propagating through free space.\n\n=== Sinusoidal steady state ===\n\nIf light of a fixed [[frequency]]/[[wavelength]]/[[color]] (as from a laser) is assumed, then the time-[[harmonic]] form of the optical field is given as:\n\n:<math>u(\\mathbf{r},t) = \\mathrm{Re} \\left\\{  \\psi(\\mathbf{r}) e^{i\\omega t} \\right\\} </math>.\nwhere <math>i</math> is the [[imaginary unit]],\n:<math>\\omega = 2\\pi f </math>\nis the angular frequency (in radians per unit time) of the light waves, and\n:<math>\\psi(\\mathbf{r}) = a(\\mathbf{r}) e^{i \\phi (\\mathbf{r}) }  </math>\nis, in general, a [[complex number|complex]] quantity, with separate amplitude <math>a</math> and phase <math>\\phi</math>.\n\n=== The Helmholtz equation ===\n\nSubstituting this expression into the wave equation yields the time-independent form of the wave equation, also known as the [[Helmholtz equation]]:\n\n:<math>\\left(\\nabla^2+ k^2 \\right) \\psi (\\mathbf{r})=0</math>\n\nwhere \n:<math>k = { \\omega \\over c} = { 2 \\pi \\over \\lambda }</math>\n\nis the wave number, \u03c8('''r''') is the time-independent, [[complex number|complex-valued]] component of the propagating wave. Note that the propagation constant, k, and the frequency, <math> \\omega </math>, are linearly related to one another, a typical characteristic of transverse electromagnetic (TEM) waves in homogeneous media.\n\n===Solving the Helmholtz equation===\n\nSolutions to the Helmholtz equation may readily be found in [[rectangular coordinates]] via the principle of [[separation of variables]] for [[partial differential equation]]s. This principle says that in separable [[orthogonal coordinates]], an ''elementary product solution'' to this wave equation may be constructed of the following form:\n\n: <math>  \\psi(x, y, z) = f_x(x) \\times f_y(y) \\times f_z(z)</math>\n\ni.e., as the product of a function of ''x'', times a function of ''y'', times a function of ''z''. If this ''elementary product solution'' is substituted into the wave equation (2.0), using the [[Laplace operator|scalar Laplacian]] in rectangular coordinates:\n\n: <math> \\nabla^2 \\psi = \\frac{\\partial^2 \\psi}{\\partial x^2} + \\frac{\\partial^2 \\psi}{\\partial y^2} + \\frac{\\partial^2 \\psi}{\\partial z^2}  </math>\n\nthen the following equation for the 3 individual functions is obtained\n\n: <math>f''_x(x)f_y(y)f_z(z) + f_x(x)f''_y(y)f_z(z) + f_x(x)f_y(y)f''_z(z) + k^2f_x(x)f_y(y)f_z(z)=0  \\,</math>\n\nwhich is readily rearranged into the form:\n\n: <math>   \\frac{f''_x(x)}{f_x(x)}+ \\frac{f''_y(y)}{f_y(y)} + \\frac{f''_z(z)}{f_z(z)} + k^2=0 </math>\n\nIt may now be argued that each of the quotients in the equation above must, of necessity, be constant. For, say the first quotient is not constant, and is a function of ''x''. None of the other terms in the equation has any dependence on the variable x. Therefore, the first term may not have any ''x''-dependence either; it must be constant. The constant is denoted as -''k''<sub>x</sub>\u00b2. Reasoning in a similar way for the ''y'' and ''z'' quotients, three ordinary differential equations are obtained for the ''f''<sub>x</sub>, ''f''<sub>y</sub> and ''f''<sub>z</sub>, along with one ''separation condition'':\n\n: <math>\\frac{d^2}{dx^2}f_x(x) + k_x^2 f_x(x)=0</math>\n\n: <math>\\frac{d^2}{dy^2}f_y(y) + k_y^2 f_y(y)=0</math>\n\n: <math>\\frac{d^2}{dz^2}f_z(z) + k_z^2 f_z(z)=0</math>\n\n: <math>k_x^2+k_y^2+k_z^2= k^2</math>\n\nEach of these 3 differential equations has the same solution: sines, cosines or complex exponentials.  We'll go with the complex exponential for notational simplicity, compatibility with usual FT notation, and the fact that a two-sided integral of complex exponentials picks up both the sine and cosine contributions.  As a result, the elementary product solution for ''E''<sub>u</sub> is:\n\n:<math>\\psi(x,y,z)=e^{i(k_x x + k_y y + k_z z)} </math>\n:::::<math> =e^{i(k_x x + k_y y)} e^{i k_z z}</math>\n:::::<math> =e^{i(k_x x + k_y y)} e^{\\pm i z \\sqrt{k^2-k_x^2-k_y^2} }</math>\n\nwhich represents a propagating or exponentially decaying uniform plane wave solution to the homogeneous wave equation. The - sign is used for a wave propagating/decaying in the +z direction and the + sign is used for a wave propagating/decaying in the -z direction (this follows the engineering time convention, which assumes an e<sup>i\u03c9t</sup> time dependence). This field represents a propagating plane wave when the quantity under the radical is positive, and an exponentially decaying wave when it is negative (in passive media, the root with a non-positive imaginary part must always be chosen, to represent uniform propagation or decay, but not amplification).\n\nProduct solutions to the Helmholtz equation are also readily obtained in [[Cylindrical coordinate system|cylindrical]] and [[Spherical coordinate system|spherical coordinates]], yielding [[Cylindrical harmonics|cylindrical]] and [[spherical harmonics]] (with the remaining separable coordinate systems being used much less frequently).\n\n=== The complete solution: the superposition integral ===\n\nA general solution to the homogeneous electromagnetic wave equation in rectangular coordinates may be formed as a weighted superposition of all possible elementary plane wave solutions as:\n\n:<math>\\psi(x,y,z)=\\int_{-\\infty}^{+\\infty}    \\int_{-\\infty}^{+\\infty}      \\Psi_0(k_x,k_y) ~ e^{i(k_x x + k_y y)} ~ e^{\\pm i z \\sqrt{k^2-k_x^2-k_y^2} } ~ dk_x dk_y ~~~~~~~~~~~~~~~~~~(2.1) </math>\n\nNext, let\n\n:<math>\\psi_0(x,y) = \\psi(x,y,z)|_{z=0}</math>.\n\nThen:\n\n:<math>\\psi_0(x,y)=\\int_{-\\infty}^{+\\infty}      \\int_{-\\infty}^{+\\infty}  \\Psi_0(k_x,k_y) ~ e^{i(k_x x + k_y y)}  ~ dk_x dk_y </math>\n\n'''This plane wave spectrum representation of the electromagnetic field is the basic foundation of Fourier optics''' (this point cannot be emphasized strongly enough), because when ''z''=0, the equation above simply becomes a '''Fourier transform (FT) relationship between the field and its plane wave content'''  (hence the name, \"Fourier optics\").\n\nThus:\n\n:<math>\\Psi_0(k_x,k_y) = \\mathcal{F} \\{ \\psi_0(x,y) \\}</math>\n\nand\n\n:<math>\\psi_0(x,y) = \\mathcal{F}^{-1} \\{  \\Psi_0(k_x,k_y)  \\}</math>\n\nAll spatial dependence of the individual plane wave components is described explicitly via the exponential functions. The coefficients of the exponentials are only functions of spatial wavenumber ''k<sub>x</sub>'', ''k<sub>y</sub>'', just as in ordinary [[Fourier analysis]] and [[Fourier transform]]s.\n\n=== The diffraction limit ===\nWhen\n: <math>   k_x^2+k_y^2 > k^2   </math>\nthe plane waves are [[Evanescent wave|evanescent]] (decaying), so that any spatial frequency content in an object plane transparency which is finer than one wavelength will not be transferred over to the image plane, simply because the plane waves corresponding to that content cannot propagate. In connection with lithography of electronic components, this phenomenon is known as the [[diffraction limit]] and is the reason why light of progressively higher frequency (smaller wavelength, thus larger ''k'') is required for etching progressively finer features in integrated circuits.\n\n== The paraxial approximation ==\n\n===Paraxial plane waves (Optic axis is assumed z-directed)===\n\nAs shown above, an elementary product solution to the Helmholtz equation takes the form:\n\n:<math>\\psi(\\mathbf{r}) = A(\\mathbf{r}) e^{-i \\mathbf{k} \\cdot \\mathbf{r}}</math>\n\nwhere\n\n:<math>\\mathbf{k} \\cdot \\mathbf{r} = k_x \\mathbf{x} + k_y \\mathbf{y} + k_z\\mathbf{z} </math>\n\nis the [[wave vector]], and\n\n:<math> k = \\|\\mathbf{k}\\| = \\sqrt{k_x^2 + k_y^2  + k_z^2} = {\\omega \\over c}</math>\n\nis the wave number. Next, using the [[paraxial approximation]], it is assumed that\n\n:<math>k_x^2 + k_y^2 \\ll k_z^2 </math>\n\nor equivalently,\n\n:<math>\\sin \\theta \\approx \\theta </math>\n\nwhere \u03b8 is the angle between the wave vector '''k''' and the z-axis.\n\nAs a result,\n:<math> k_z = k \\cos \\theta \\approx k ( 1 - \\theta^2 / 2)</math>\nand\n:<math>\\psi(\\mathbf{r}) \\approx A(\\mathbf{r}) e^{-i(k_x x+k_y y)} e^{ikz \\theta^2/2 }  e^{-ik z}</math>\n\n=== The paraxial wave equation ===\n\nSubstituting this expression into the Helmholtz equation, the paraxial wave equation is derived:\n:<math>\\nabla_T^2 A - 2ik { \\partial A \\over \\partial z} = 0</math>\nwhere\n:<math>\\nabla_T^2 = \\nabla^2 - {\\partial^2 \\over \\partial z^2} = {\\partial^2 \\over \\partial x^2} + {\\partial^2 \\over \\partial y^2} </math>\nis the transverse [[Laplace operator]], shown here in Cartesian coordinates.\n\n== The far field approximation ==\n\n{{Main|Fraunhofer diffraction}}\n\nThe equation above may be evaluated asymptotically in the far field (using the [[stationary phase approximation|stationary phase method]]) to show that the field at the distant point (''x'',''y'',''z'') is indeed due solely to the plane wave component (''k<sub>x</sub>'', ''k<sub>y</sub>'', ''k<sub>z</sub>'') which propagates parallel to the vector (''x'',''y'',''z''), and whose plane is tangent to the phasefront at (''x'',''y'',''z''). The mathematical details of this process may be found in Scott [1998] or Scott [1990]. The result of performing a stationary phase integration on the expression above is the following expression,\n\n:<math>E_u(r,\\theta,\\phi)~=~2 \\pi i~ (k~\\cos\\theta)~ \\frac{e^{-ikr}}{r}~ E_u(k~\\sin\\theta~\\cos\\phi,k~\\sin\\theta~\\sin\\phi) ~~~~~~~~~~~~(2.2)</math>\n\nwhich clearly indicates that the field at (x,y,z) is directly proportional to the spectral component in the direction of (x,y,z), where,\n\n: <math> x = r ~ \\sin \\theta ~ \\cos \\phi </math>\n\n: <math> y = r ~ \\sin \\theta ~ \\sin \\phi </math>\n\n: <math> z = r ~ \\cos \\theta ~ </math>\n\nand\n\n: <math> k_x = k ~ \\sin \\theta ~ \\cos \\phi </math>\n\n: <math> k_y = k ~ \\sin \\theta ~ \\sin \\phi </math>\n\n: <math> k_z = k ~ \\cos \\theta ~ </math>\n\nStated another way, the radiation pattern of any planar field distribution is the FT of that source distribution (see [[Huygens\u2013Fresnel principle]], wherein the same equation is developed using a [[Green's function]] approach). Note that this is NOT a plane wave. The <math> \\frac{e^{-ikr}}{r}</math> radial dependence is a spherical wave - both in magnitude and phase - whose local amplitude is the FT of the source plane distribution at that far field angle. The plane wave spectrum has nothing to do with saying that the field behaves something like a plane wave for far distances.\n\n=== Spatial versus angular bandwidth ===\n\nEquation (2.2) above is '''critical''' to making the connection between ''spatial bandwidth'' (on the one hand) and ''angular bandwidth'' (on the other), in the far field. Note that the term \"far field\" usually means we're talking about a converging or diverging spherical wave with a pretty well defined phase center. The connection between spatial and angular bandwidth in the far field is essential in understanding the low pass filtering property of thin lenses. See section 5.1.3 for the condition defining the far field region.\n\nOnce the concept of angular bandwidth is understood, the optical scientist can \"jump back and forth\" between the spatial and spectral domains to quickly gain insights which would ordinarily not be so readily available just through spatial domain or ray optics considerations alone. For example, any source bandwidth which lies past the edge angle to the first lens (this edge angle sets the bandwidth of the optical system) will not be captured by the system to be processed.\n\nAs a side note, electromagnetics scientists have devised an alternative means for calculating the far zone electric field which does not involve stationary phase integration.  They have devised a concept known as \"fictitious magnetic currents\" usually denoted by '''M''', and defined as\n: <math> ~ ~ \\mathbf{M} ~ = ~ 2 \\mathbf{E}^{aper} ~ \\times ~ \\mathbf{\\hat{z}} </math>.\nIn this equation, it is assumed that the unit vector in the z-direction points into the half-space where the far field calculations will be made.  These equivalent magnetic currents are obtained using equivalence principles which, in the case of an infinite planar interface, allow any electric currents, '''J''' to be \"imaged away\" while the fictitious magnetic currents are obtained from twice the aperture electric field (see Scott [1998]).  Then the radiated electric field is calculated from the magnetic currents using an equation similar to the equation for the magnetic field radiated by an electric current.  In this way, a vector equation is obtained for the radiated electric field in terms of the aperture electric field and the derivation requires no use of stationary phase ideas.\n\n==The plane wave spectrum: the foundation of Fourier optics==\n\nFourier optics is somewhat different from ordinary ray optics typically used in the analysis and design of focused imaging systems such as cameras, telescopes and microscopes.  Ray optics is the very first type of optics most of us encounter in our lives; it's simple to conceptualize and understand, and works very well in gaining a baseline understanding of common optical devices.  Unfortunately, ray optics does not explain the operation of Fourier optical systems, which are in general not focused systems.  Ray optics is a subset of wave optics (in the jargon, it is \"the asymptotic zero-wavelength limit\" of wave optics) and therefore has limited applicability.  We have to know when it is valid and when it is not - and this is one of those times when it is not.  For our current task, we must expand our understanding of optical phenomena to encompass wave optics, in which the optical field is seen as a solution to Maxwell's equations.  This more general ''wave optics'' accurately explains the operation of Fourier optics devices.\n\nIn this section, we won't go all the way back to Maxwell's equations, but will start instead with the homogeneous Helmholtz equation (valid in source-free media), which is one level of refinement up from Maxwell's equations (Scott [1998]).  From this equation, we'll show how infinite uniform plane waves comprise one field solution (out of many possible) in free space.  These uniform plane waves form the basis for understanding Fourier optics.\n\nThe [[plane wave]] spectrum concept is the basic foundation of Fourier Optics. The plane wave spectrum is a continuous spectrum of ''uniform'' plane waves, and there is one plane wave component in the spectrum for every tangent point on the far-field phase front. The amplitude of that plane wave component would be the amplitude of the optical field at that tangent point. Again, this is true only in the far field, defined as: Range = 2 D<sup>2</sup> / \u03bb where D is the maximum linear extent of the optical sources and \u03bb is the wavelength (Scott [1998]). The plane wave spectrum is often regarded as being discrete for certain types of periodic gratings, though in reality, the spectra from gratings are continuous as well, since no physical device can have the infinite extent required to produce a true line spectrum.\n\nAs in the case of electrical signals, bandwidth is a measure of how finely detailed an image is; the finer the detail, the greater the bandwidth required to represent it.  A DC electrical signal is constant and has no oscillations; a plane wave propagating parallel to the optic (<math>z</math>) axis has constant value in any ''x''-''y'' plane, and therefore is analogous to the (constant) DC component of an electrical signal.  Bandwidth in electrical signals relates to the difference between the highest and lowest frequencies present in the spectrum of the signal.  For ''optical'' systems, bandwidth also relates to spatial frequency content (spatial bandwidth), but it also has a secondary meaning.  It also measures how far from the optic axis the corresponding plane waves are tilted, and so this type of bandwidth is often referred to also as angular bandwidth. It takes more frequency bandwidth to produce a short pulse in an electrical circuit, and more angular (or, spatial frequency) bandwidth to produce a sharp spot in an optical system (see discussion related to [[Point spread function]]).\n\nThe plane wave spectrum arises naturally as the [[eigenfunction]] or \"natural mode\" solution to the homogeneous [[electromagnetic wave equation]] in rectangular coordinates (see also [[Electromagnetic radiation]], which derives the wave equation from Maxwell's equations in source-free media, or Scott [1998]). In the [[frequency domain]], with an assumed time convention of <math>  e^{i \\omega t} </math>, the homogeneous electromagnetic wave equation is known as the [[Helmholtz equation]] and takes the form:\n\n: <math>  \\nabla^2 E_u + k^2E_u = 0  ~~~~~~~~~~~~~~(2.0) </math>\n\nwhere ''u'' = ''x'', ''y'', ''z'' and ''k'' = 2\u03c0/\u03bb is the [[wavenumber]] of the medium.\n\n===Eigenfunction (natural mode) solutions: background and overview===\n\nIn the case of differential equations, as in the case of matrix equations, whenever the right-hand side of an equation is zero (i.e., the forcing function / forcing vector is zero), the equation may still admit a non-trivial solution, known in applied mathematics as an [[eigenfunction]] solution, in physics as a \"natural mode\" solution and in electrical circuit theory as the \"zero-input response.\"  This is a concept that spans a wide range of physical disciplines.  Common physical examples of ''resonant'' natural modes would include the resonant vibrational modes of stringed instruments (1D), percussion instruments (2D) or the former [[Tacoma Narrows Bridge (1940)|Tacoma Narrows Bridge]] (3D).  Examples of ''propagating'' natural modes would include [[Waveguide (electromagnetism)|waveguide]] modes, [[optical fiber]] modes, [[Soliton (optics)|solitons]] and [[Bloch wave]]s.  Infinite homogeneous media admit the rectangular, circular and spherical harmonic solutions to the Helmholtz equation, depending on the coordinate system under consideration.  The propagating plane waves we'll study in this article are perhaps the simplest type of propagating waves found in any type of media.\n\nThere is a striking similarity between the Helmholtz equation (2.0) above, which may be written\n\n: <math>  (\\nabla^2 + k^2)~f = 0 , </math>\n\nand the usual equation for the [[Eigenvalues and eigenvectors|eigenvalues/eigenvectors]] of a square matrix, '''A''',\n\n: <math>  (\\mathbf A - \\lambda \\mathbf I) ~ \\mathbf x = 0   </math>  ,\n\nparticularly since both the scalar Laplacian,  <math>  \\nabla^2  </math> and the matrix, '''A''' are linear operators on their respective function/vector spaces (the minus sign in the second equation is, for all intents and purposes, immaterial; the plus sign in the first equation however is significant).  It is perhaps worthwhile to note that both the eigenfunction and eigenvector solutions to these two equations respectively, often yield an orthogonal set of functions/vectors which span (i.e., form a basis set for) the function/vector spaces under consideration. The interested reader may investigate other functional linear operators which give rise to different kinds of orthogonal eigenfunctions such as [[Legendre polynomials]], [[Chebyshev polynomials]] and [[Hermite polynomials]].\n\nIn the matrix case, eigenvalues <math>\\lambda</math> may be found by setting the determinant of the matrix equal to zero, i.e. finding where the matrix has no inverse.  Finite matrices have only a finite number of eigenvalues/eigenvectors, whereas linear operators can have a countably infinite number of eigenvalues/eigenfunctions (in confined regions) or uncountably infinite (continuous) spectra of solutions, as in unbounded regions.\n\nIn certain physics applications such as in the [[Bloch wave \u2013 MoM method|computation of bands in a periodic volume]], it is often the case that the elements of a matrix will be very complicated functions of frequency and wavenumber, and the matrix will be non-singular for most combinations of frequency and wavenumber, but will also be singular for certain specific combinations. By finding which combinations of frequency and wavenumber drive the determinant of the matrix to zero, the propagation characteristics of the medium may be determined. Relations of this type, between frequency and wavenumber, are known as dispersion relations and some physical systems may admit many different kinds of dispersion relations. An example from electromagnetics is the ordinary waveguide, which may admit numerous dispersion relations, each associated with a unique mode of the waveguide. Each propagation mode of the waveguide is known as an [[eigenfunction]] solution (or eigenmode solution) to Maxwell's equations in the waveguide. Free space also admits eigenmode (natural mode) solutions (known more commonly as plane waves), but with the distinction that for any given frequency, free space admits a continuous modal spectrum, whereas waveguides have a discrete mode spectrum.  In this case the dispersion relation is linear, as in section 1.2.\n\n=== K-space ===\n\nThe separation condition,\n\n: <math> k_x^2+k_y^2+k_z^2=k^2 </math>\n\nwhich is identical to the equation for the [[Euclidean metric]] in three-dimensional configuration space, suggests the notion of a [[wave vector|k-vector]] in three-dimensional \"k-space\", defined (for propagating plane waves) in rectangular coordinates as:\n\n: <math> \\mathbf{k} ~ = ~ k_x  \\mathbf{\\hat{x}} + k_y \\mathbf{\\hat{y}} + k_z  \\mathbf{\\hat{z}} </math>\n\nand in the [[spherical coordinate system]] as\n\n: <math> k_x = k ~ \\sin \\theta ~ \\cos \\phi </math>\n\n: <math> k_y = k ~ \\sin \\theta ~ \\sin \\phi </math>\n\n: <math> k_z = k ~ \\cos \\theta ~ </math>\n\nUse will be made of these spherical coordinate system relations in the next section.\n\nThe notion of k-space is central to many disciplines in engineering and physics, especially in the study of periodic volumes, such as in crystallography and the band theory of semiconductor materials.\n\n=== The two-dimensional Fourier transform ===\n\nAnalysis Equation (calculating the spectrum of the function):\n:<math>U(k_x,k_y) = \\int_{-\\infty}^{\\infty}  \\int_{-\\infty}^{\\infty} u(x,y) e^{-i(k_x x + k_y y)} dx dy </math>\n\nSynthesis Equation (reconstructing the function from its spectrum):\n:<math> u(x,y) = \\frac{1}{(2\\pi)^2}\\int_{-\\infty}^{\\infty}  \\int_{-\\infty}^{\\infty} U(k_x,k_y) e^{i(k_x x + k_y y)} dk_x dk_y </math>\n\n''Note'': the normalizing factor of:<math>\\frac{1}{(2\\pi)^2} </math> is present whenever angular frequency (radians) is used, but not when ordinary frequency (cycles) is used.\n\n==Optical systems: General overview and analogy with electrical signal processing systems==\n\nAn optical system consists of an input plane, and output plane, and a set of components that transforms the image ''f''   formed at the input into a different image ''g'' formed at the output. The output image is related to the input image by convolving the input image with the optical impulse response, ''h'' (known as the ''point-spread function'', for focused optical systems). The impulse response uniquely defines the input-output behavior of the optical system. By convention, the optical axis of the system is taken as the ''z''-axis. As a result, the two images and the impulse response are all functions of the transverse coordinates, ''x'' and ''y''.\n\n:<math>g(x,y) = h(x,y) * f(x,y)</math>\n\nThe impulse response of an optical imaging system is the output plane field which is produced when an ideal mathematical point source of light is placed in the input plane (usually on-axis). In practice, it is not necessary to have an ideal point source in order to determine an exact impulse response. This is because any source bandwidth which lies outside the bandwidth of the system won't matter anyway (since it cannot even be captured by the optical system), so therefore it's not necessary in determining the impulse response. The source only needs to have at least as much (angular) bandwidth as the optical system.\n\nOptical systems typically fall into one of two different categories. The first is the ordinary focused optical imaging system, wherein the input plane is called the object plane and the output plane is called the image plane. The field in the image plane is desired to be a high-quality reproduction of the field in the object plane. In this case, the impulse response of the optical system is desired to approximate a 2D delta function, at the same location (or a linearly scaled location) in the output plane corresponding to the location of the impulse in the input plane. The ''actual'' impulse response typically resembles an [[Airy disk|Airy function]], whose radius is on the order of the wavelength of the light used. In this case, the impulse response is typically referred to as a [[point spread function]], since the mathematical point of light in the object plane has been spread out into an Airy function in the image plane.\n\nThe second type is the optical image processing system, in which a significant feature in the input plane field is to be located and isolated. In this case, the impulse response of the system is desired to be a close replica (picture) of that feature which is being searched for in the input plane field, so that a convolution of the impulse response (an image of the desired feature) against the input plane field will produce a bright spot at the feature location in the output plane.  It is this latter type of optical ''image processing'' system that is the subject of this section.  Section 5.2 presents one hardware implementation of the optical image processing operations described in this section.\n\n=== Input plane ===\n\nThe input plane is defined as the locus of all points such that ''z'' = 0. The input image ''f'' is therefore\n\n:<math>f(x,y) = U(x,y,z)\\big|_{z=0} </math>\n\n=== Output plane ===\n\nThe output plane is defined as the locus of all points such that ''z'' = ''d''. The output image ''g'' is therefore\n\n:<math>g(x,y) = U(x,y,z)\\big|_{z=d} </math>\n\n=== The 2D convolution of input function against the impulse response function ===\n\n:<math> g(x,y) ~ = ~ h(x,y) * f(x,y) </math>\n\ni.e.,\n\n:<math> g(x,y)= \\int_{-\\infty}^{\\infty}  \\int_{-\\infty}^{\\infty}  h(x-x', y-y') ~ f(x',y') ~ dx' dy'   ~~~~~~(4.1)  ~</math>\n\nThe alert reader will note that the integral above tacitly assumes that the impulse response is NOT a function of the position (x',y') of the impulse of light in the input plane (if this were not the case, this type of convolution would not be possible). This property is known as ''shift invariance'' (Scott [1998]). No optical system is perfectly shift invariant: as the ideal, mathematical point of light is scanned away from the optic axis, aberrations will eventually degrade the impulse response (known as a [[coma (optics)|coma]] in focused imaging systems). However, high quality optical systems are often \"shift invariant enough\" over certain regions of the input plane that we may regard the impulse response as being a function of only the difference between input and output plane coordinates, and thereby use the equation above with impunity.\n\nAlso, this equation assumes unit magnification. If magnification is present, then eqn. (4.1) becomes\n\n:<math> g(x,y)= \\int_{-\\infty}^{\\infty}  \\int_{-\\infty}^{\\infty}  h_M(x-Mx', y-My') ~ f(x',y') ~ dx' dy'   ~~~~~~(4.2)  ~</math>\n\nwhich basically translates the impulse response function, h<sub>M</sub>(), from x' to x=Mx'. In (4.2), h<sub>M</sub>() will be a magnified version of the impulse response function h() of a similar, unmagnified system, so that h<sub>M</sub>(x,y) =h(x/M,y/M).\n\n=== Derivation of the convolution equation ===\nThe extension to two dimensions is trivial, except for the difference that [[causality]] exists in the time domain, but not in the spatial domain. Causality means that the impulse response ''h''(''t'' - t') of an electrical system, due to an impulse applied at time t', must of necessity be zero for all times t such that t - t' < 0.\n\nObtaining the convolution representation of the system response requires representing the input signal as a weighted superposition over a train of impulse functions by using the ''shifting property'' of [[Dirac delta function]]s.\n\n:<math>  f(t) = \\int_{-\\infty}^{\\infty}    \\delta(t-t') f(t') dt'</math>\n\nIt is then presumed that the system under consideration is ''linear'', that is to say that the output of the system due to two different inputs (possibly at two different times) is the sum of the individual outputs of the system to the two inputs, when introduced individually. Thus the optical system may contain no nonlinear materials nor active devices (except possibly, extremely linear active devices). The output of the system, for a single delta function input is defined as the ''impulse response'' of the system, h(t - t').  And, by our linearity assumption (i.e., that the output of system to a pulse train input is the sum of the outputs due to each individual pulse), we can now say that the general input function ''f''(''t'') produces the output:\n\n:<math>  g(t) = \\int_{-\\infty}^{\\infty}    h(t-t') f(t') dt'</math>\n\nwhere ''h''(t - t') is the (impulse) response of the linear system to the delta function input \u03b4(t - t'), applied at time t'. This is where the convolution equation above comes from. The convolution equation is useful because it is often much easier to find the response of a system to a delta function input - and then perform the convolution above to find the response to an arbitrary input - than it is to try to find the response to the arbitrary input directly. Also, the impulse response (in either time or frequency domains) usually yields insight to relevant figures of merit of the system. In the case of most lenses, the point spread function (PSF) is a pretty common figure of merit for evaluation purposes.\n\nThe same logic is used in connection with the [[Huygens\u2013Fresnel principle]], or Stratton-Chu formulation, wherein the \"impulse response\" is referred to as the [[Green's function]] of the system. So the spatial domain operation of a linear optical system is analogous in this way to the Huygens\u2013Fresnel principle.\n\n=== System transfer function ===\nIf the last equation above is Fourier transformed, it becomes:\n\n:<math>  G(\\omega) ~ = ~  H(\\omega) \\cdot  F(\\omega) </math>\n\nwhere\n\n:<math> G(\\omega) ~ </math> is the spectrum of the output signal\n\n:<math> H(\\omega) ~ </math> is the system transfer function\n\n:<math> F(\\omega) ~ </math> is the spectrum of the input signal\n\nIn like fashion, (4.1) may be Fourier transformed to yield:\n\n:<math> G(k_x,k_y) ~ = ~ H(k_x,k_y) \\cdot F(k_x,k_y)</math>\n\nThe system transfer function, <math>H(\\omega)</math>. In optical imaging this function is better known as the [[optical transfer function]] ''(Goodman)''.\n\nOnce again it may be noted from the discussion on the [[Abbe sine condition]], that this equation assumes unit magnification.\n\nThis equation takes on its real meaning when the Fourier transform, <math> ~G(k_x,k_y)</math> is associated with the coefficient of the plane wave whose transverse wavenumbers are <math>~ (k_x,k_y)</math>. Thus, the input-plane plane wave spectrum is transformed into the output-plane plane wave spectrum through the multiplicative action of the system transfer function. It is at this stage of understanding that the previous background on the plane wave spectrum becomes invaluable to the conceptualization of Fourier optical systems.\n\n==Applications of  Fourier optics principles==\nFourier optics is used in the field of optical information processing, the staple of which is the classical 4F processor.\n\nThe [[Fourier transform]] properties of a [[lens (optics)|lens]] provide numerous applications in [[optical signal processing]] such as [[spatial filtering]], [[optical correlation]] and [[computer generated holograms]].\n\nFourier optical theory is used in [[interferometry]], [[optical tweezers]], [[Magnetic trap (atoms)|atom traps]], and [[quantum computing]]. Concepts of Fourier optics are used to reconstruct the [[Phase (waves)|phase]] of light intensity in the spatial frequency plane (see [[adaptive-additive algorithm]]).\n\n===Fourier transforming property of lenses===\n\nIf a transmissive object is placed one focal length in front of a [[lens (optics)|lens]], then its [[Fourier transform]] will be formed one focal length behind the lens. Consider the figure to the right (click to enlarge)\n\n[[File:Lens FT.jpg|On the Fourier transforming property of lenses|right|thumb|500px]]\n\nIn this figure, a plane wave incident from the left is assumed. The transmittance function in the front focal plane (i.e., Plane 1) ''spatially modulates the incident plane wave'' in magnitude and phase, ''like on the left-hand side of eqn. (2.1)'' (specified to ''z''=0), and ''in so doing, produces a spectrum of plane waves'' corresponding to the FT of the transmittance function, ''like on the right-hand side of eqn. (2.1)'' (for ''z''>0). The various plane wave components propagate at different tilt angles with respect to the optic axis of the lens (i.e., the horizontal axis). The finer the features in the transparency, the broader the angular bandwidth of the plane wave spectrum. We'll consider one such plane wave component, propagating at angle \u03b8 with respect to the optic axis. It is assumed that \u03b8 is small ([[paraxial approximation]]), so that\n\n: <math>\\frac{k_x}{k} = \\sin \\theta \\simeq \\theta</math>\n\nand\n\n: <math>\\frac{k_z}{k} = \\cos \\theta \\simeq 1 - \\frac{\\theta^2}{2} </math>\n\nand\n\n: <math> \\frac{1}{\\cos \\theta} \\simeq \\frac{1}{1 - \\frac{\\theta^2}{2}} \\simeq 1 + \\frac{\\theta^2}{2} </math>\n\nIn the figure, the ''plane wave'' phase, moving horizontally from the front focal plane to the lens plane, is\n\n:<math> e^{i k f \\cos \\theta} \\,</math>\n\nand the ''spherical wave'' phase from the lens to the spot in the back focal plane is:\n\n:<math> e^{i k f / \\cos \\theta} \\,</math>\n\nand the sum of the two path lengths is ''f'' (1 + \u03b8<sup>2</sup>/2 + 1 - \u03b8<sup>2</sup>/2) = 2''f''   i.e., it is a constant value, independent of tilt angle, \u03b8, for paraxial plane waves. Each paraxial plane wave component of the field in the front focal plane appears as a [[point spread function]] spot in the back focal plane, with an intensity and phase equal to the intensity and phase of the original plane wave component in the front focal plane. In other words, the field in the back focal plane is the [[Fourier transform]] of the field in the front focal plane.\n\nAll FT components are computed simultaneously - in parallel - at the speed of light. As an example, light travels at a speed of roughly {{convert|1|ft|m|abbr=on}}. / ns, so if a lens has a {{convert|1|ft|m|abbr=on}}. focal length, an entire 2D FT can be computed in about 2 ns (2 x 10<sup>\u22129</sup> seconds). If the focal length is 1 in., then the time is under 200 ps. No electronic computer can compete with these kinds of numbers or perhaps ever hope to, although [[Supercomputer#The_TOP500_list|supercomputers]] may actually prove faster than optics, as improbable as that may seem. However, their speed is obtained by combining numerous computers which, individually, are still slower than optics. The disadvantage of the optical FT is that, as the derivation shows, the FT relationship only holds for paraxial plane waves, so this FT \"computer\" is inherently bandlimited. On the other hand, since the wavelength of visible light is so minute in relation to even the smallest visible feature dimensions in the image i.e.,\n\n: <math> k^2 \\gg  k_x ^2 + k_y ^2 </math>\n\n(for all ''k<sub>x</sub>'', ''k<sub>y</sub>'' within the spatial bandwidth of the image, so that ''k<sub>z</sub>'' is nearly equal to ''k''), the paraxial approximation is not terribly limiting in practice. And, of course, this is an analog - not a digital - computer, so precision is limited. Also, phase can be challenging to extract; often it is inferred interferometrically.\n\nOptical processing is especially useful in real time applications where rapid processing of massive amounts of 2D data is required, particularly in relation to pattern recognition.\n\n====Object truncation and Gibbs phenomenon====\n\nThe spatially modulated electric field, shown on the left-hand side of eqn. (2.1), typically only occupies a finite (usually rectangular) aperture in the x,y plane. The rectangular aperture function acts like a 2D square-top filter, where the field is assumed to be zero outside this 2D rectangle. The spatial domain integrals for calculating the FT coefficients on the right-hand side of eqn. (2.1) are truncated at the boundary of this aperture. This step truncation can introduce inaccuracies in both theoretical calculations and measured values of the plane wave coefficients on the RHS of eqn. (2.1).\n\nWhenever a function is discontinuously truncated in one FT domain, broadening and rippling are introduced in the other FT domain. A perfect example from optics is in connection with the point spread function, which for on-axis plane wave illumination of a quadratic lens (with circular aperture), is an Airy function,  ''J''<sub>1</sub>(''x'')/''x''. Literally, the point source has been \"spread out\" (with ripples added), to form the Airy point spread function (as the result of truncation of the plane wave spectrum by the finite aperture of the lens). This source of error is known as [[Gibbs phenomenon]] and it may be mitigated by simply ensuring that all significant content lies near the center of the transparency, or through the use of [[window function]]s which smoothly taper the field to zero at the frame boundaries. By the convolution theorem, the FT of an arbitrary transparency function - multiplied (or truncated) by an aperture function - is equal to the FT of the non-truncated transparency function convolved against the FT of the aperture function, which in this case becomes a type of \"Greens function\" or \"impulse response function\" in the spectral domain. Therefore, the image of a circular lens is equal to the object plane function convolved against the Airy function (the FT of a circular aperture function is ''J''<sub>1</sub>(''x'')/''x'' and the FT of a rectangular aperture function is a product of sinc functions, sin ''x''/''x'').\n\n==== Fourier analysis and functional decomposition ====\n\nEven though the input transparency only occupies a finite portion of the ''x''-''y'' plane (Plane 1), the uniform plane waves comprising the plane wave spectrum occupy the '''entire''' ''x''-''y'' plane, which is why (for this purpose) only the longitudinal plane wave phase (in the ''z''-direction, from Plane 1 to Plane 2) must be considered, and not the phase transverse to the ''z''-direction. It is of course, very tempting to think that if a plane wave emanating from the finite aperture of the transparency is tilted too far from horizontal, it will somehow \"miss\" the lens altogether but again, since the uniform plane wave extends infinitely far in all directions in the transverse (''x''-''y'') plane, the planar wave components cannot miss the lens.\n\nThis issue brings up perhaps the predominant difficulty with Fourier analysis, namely that the input-plane function, defined over a finite support (i.e., over its own finite aperture), is being approximated with other functions (sinusiods) which have infinite support (''i''.''e''., they are defined over the entire infinite ''x''-''y'' plane). This is unbelievably inefficient computationally, and is the principal reason why [[wavelet]]s were conceived, that is to represent a function (defined on a finite interval or area) in terms of oscillatory functions which are also defined over finite intervals or areas. Thus, instead of getting the frequency content of the entire image all at once (along with the frequency content of the entire rest of the ''x''-''y'' plane, over which the image has zero value), the result is instead the frequency content of different parts of the image, which is usually much simpler. Unfortunately, wavelets in the ''x''-''y'' plane don't correspond to any known type of propagating wave function, in the same way that Fourier's sinusoids (in the ''x''-''y'' plane) correspond to plane wave functions in three dimensions. However, the FTs of most wavelets are well known and could possibly be shown to be equivalent to some useful type of propagating field.\n\nOn the other hand, [[Sinc function]]s and [[Airy function]]s - which are not only the point spread functions of rectangular and circular apertures, respectively, but are also cardinal functions commonly used for functional decomposition in [[Whittaker\u2013Shannon interpolation formula|interpolation/sampling theory]] [Scott 1990] - '''do''' correspond to converging or diverging spherical waves, and therefore could potentially be implemented as a whole new functional decomposition of the object plane function, thereby leading to another point of view similar in nature to Fourier optics. This would basically be the same as conventional ray optics, but with diffraction effects included. In this case, each point spread function would be a type of \"smooth pixel,\" in much the same way that a soliton on a fiber is a \"smooth pulse.\"\n\nPerhaps a lens figure-of-merit in this \"point spread function\" viewpoint would be to ask how well a lens transforms an Airy function in the object plane into an Airy function in the image plane, as a function of radial distance from the optic axis, or as a function of the size of the object plane Airy function. This is somewhat like the point spread function, except now we're really looking at it as a kind of input-to-output plane transfer function (like MTF), and not so much in absolute terms, relative to a perfect point. Similarly, Gaussian wavelets, which would correspond to the waist of a propagating Gaussian beam, could also potentially be used in still another functional decomposition of the object plane field.\n\n==== Far-field range and the 2D<sup>2</sup> / \u03bb criterion ====\n\nIn the figure above, illustrating the Fourier transforming property of lenses, the lens is in the near field of the object plane transparency, therefore the object plane field at the lens may be regarded as a superposition of plane waves, each one of which propagates at some angle with respect to the z-axis. In this regard, the far-field criterion is loosely defined as: Range = 2 ''D''<sup>2</sup> / \u03bb where ''D'' is the maximum linear extent of the optical sources and \u03bb is the wavelength (Scott [1998]).  The ''D'' of the transparency is on the order of cm (10<sup>\u22122</sup> m) and the wavelength of light is on the order of 10<sup>\u22126</sup> m, therefore ''D''/\u03bb  for the whole transparency is on the order of 10<sup>4</sup>. This times ''D'' is on the order of 10<sup>2</sup> m, or hundreds of meters. On the other hand, the far field distance from a PSF spot is on the order of \u03bb. This is because D for the spot is on the order of \u03bb, so that ''D''/\u03bb is on the order of unity; this times ''D'' (i.e., \u03bb) is on the order of \u03bb (10<sup>\u22126</sup> m).\n\nSince the lens is in the far field of any PSF spot, the field incident on the lens from the spot may be regarded as being a spherical wave, as in eqn. (2.2), not as a plane wave spectrum, as in eqn. (2.1). On the other hand, the lens is in the near field of the entire input plane transparency, therefore eqn. (2.1) - the full plane wave spectrum - accurately represents the field incident on the lens from that larger, extended source.\n\n==== Lens as a low-pass filter ====\n\nA lens is basically a low-pass plane wave filter (see [[Low-pass filter]]). Consider a \"small\" light source located on-axis in the object plane of the lens. It is assumed that the source is small enough that, by the far-field criterion, the lens is in the far field of the \"small\" source. Then, the field radiated by the small source is a spherical wave which is modulated by the FT of the source distribution, as in eqn. (2.2), Then, the lens passes - from the object plane over onto the image plane - only that portion of the radiated spherical wave which lies inside the edge angle of the lens. In this far-field case, truncation of the radiated spherical wave is equivalent to truncation of the plane wave spectrum of the small source. So, the plane wave components in this far-field spherical wave, which lie beyond the edge angle of the lens, are not captured by the lens and are not transferred over to the image plane. Note: this logic is valid only for small sources, such that the lens is in the far field region of the source, according to the 2 ''D''<sup>2</sup> / \u03bb criterion mentioned previously. If an object plane transparency is imagined as a summation over small sources (as in the [[Whittaker\u2013Shannon interpolation formula]], Scott [1990]), each of which has its spectrum truncated in this fashion, then every point of the entire object plane transparency suffers the same effects of this low pass filtering.\n\nLoss of the high (spatial) frequency content causes blurring and loss of sharpness (see discussion related to [[point spread function]]). Bandwidth truncation causes a (fictitious, mathematical, ideal) point source in the object plane to be blurred (or, spread out) in the image plane, giving rise to the term, \"point spread function.\"  Whenever bandwidth is expanded or contracted, image size is typically contracted or expanded accordingly, in such a way that the space-bandwidth product remains constant, by Heisenberg's principle (Scott [1998] and [[Abbe sine condition]]).\n\n==== Coherence and Fourier transforming ====\n\nWhile working in the frequency domain, with an assumed e<sup>j\u03c9t</sup> (engineering) time dependence, coherent (laser) light is implicitly assumed, which has a delta function dependence in the frequency domain. Light at different (delta function) frequencies will \"spray\" the plane wave spectrum out at different angles, and as a result these plane wave components will be focused at different places in the output plane. The Fourier transforming property of lenses works best with coherent light, unless there is some special reason to combine light of different frequencies, to achieve some special purpose.\n\n===Hardware implementation of the system transfer function: The 4F correlator {{anchor|4F Correlator}}===\n{{Main|Optical correlator}}\nThe theory on optical transfer functions presented in section 4 is somewhat abstract.  However, there is one very well known device which implements the system transfer function H in hardware using only 2 identical lenses and a transparency plate - the 4F correlator.  Although one important application of this device would certainly be to implement the mathematical operations of [[cross-correlation]] and [[convolution]], this device - 4 focal lengths long - actually serves a wide variety of image processing operations that go well beyond what its name implies.  A diagram of a typical 4F correlator is shown in the figure below (click to enlarge).  This device may be readily understood by combining the plane wave spectrum representation of the electric field (''section 2'') with the Fourier transforming property of quadratic lenses (''section 5.1'') to yield the optical image processing operations described in section 4.\n\n[[File:4F Correlator.svg|4F Correlator|right|thumb|430px]]\n\nThe 4F correlator is based on the [[convolution theorem]] from [[Fourier transform]] theory, which states that [[convolution]] in the spatial (''x'',''y'') domain is equivalent to direct multiplication in the spatial frequency (''k''<sub>x</sub>, ''k''<sub>y</sub>) domain (aka: ''spectral domain''). Once again, a plane wave is assumed incident from the left and a transparency containing one 2D function, ''f''(''x'',''y''), is placed in the input plane of the correlator, located one focal length in front of the first lens. The transparency spatially modulates the incident plane wave in magnitude and phase, like on the left-hand side of eqn. (2.1), and in so doing, produces a spectrum of plane waves corresponding to the FT of the transmittance function, like on the right-hand side of eqn. (2.1). That spectrum is then formed as an \"image\" one focal length behind the first lens, as shown. A transmission mask containing the FT of the second function, ''g''(''x'',''y''), is placed in this same plane, one focal length behind the first lens, causing the transmission through the mask to be equal to the product, ''F''(''k''<sub>x</sub>,''k''<sub>y</sub>) x ''G''(''k''<sub>x</sub>,''k''<sub>y</sub>). This product now lies in the \"input plane\" of the second lens (one focal length in front), so that the FT of this product (i.e., the [[convolution]] of ''f''(''x'',''y'') and ''g''(''x'',''y'')), is formed in the back focal plane of the second lens.\n\nIf an ideal, mathematical point source of light is placed on-axis in the input plane of the first lens, then there will be a uniform, collimated field produced in the output plane of the first lens. When this uniform, collimated field is multiplied by the FT plane mask, and then Fourier transformed by the second lens, the output plane field (which in this case is the ''impulse response'' of the correlator) is just our correlating function, ''g''(''x'',''y''). In practical applications, ''g''(''x'',''y'') will be some type of feature which must be identified and located within the input plane field (see Scott [1998]). In military applications, this feature may be a tank, ship or airplane which must be quickly identified within some more complex scene.\n\nThe 4F correlator is an excellent device for illustrating the \"systems\" aspects of optical instruments, alluded to in ''section 4'' above. The FT plane mask function, ''G''(''k''<sub>x</sub>,''k''<sub>y</sub>) is the system transfer function of the correlator, which we'd in general denote as ''H''(''k''<sub>x</sub>,''k''<sub>y</sub>), and it is the FT of the impulse response function of the correlator, ''h''(''x'',''y'') which is just our correlating function ''g''(''x'',''y''). And, as mentioned above, the impulse response of the correlator is just a picture of the feature we're trying to find in the input image. In the 4F correlator, the system transfer function ''H''(''k''<sub>x</sub>,''k''<sub>y</sub>) is directly multiplied against the spectrum ''F''(''k''<sub>x</sub>,''k''<sub>y</sub>) of the input function, to produce the spectrum of the output function. This is how electrical signal processing systems operate on 1D temporal signals.\n\n==Afterword: Plane wave spectrum within the broader context of functional decomposition==\n\nElectrical fields can be represented mathematically in many different ways. In the [[Huygens\u2013Fresnel principle|Huygens\u2013Fresnel]] or [[Julius Adams Stratton|Stratton]]-Chu viewpoints, the electric field is represented as a superposition of point sources, each one of which gives rise to a [[Green's function]] field. The total field is then the weighted sum of all of the individual Green's function fields. That seems to be the most natural way of viewing the electric field for most people - no doubt because most of us have, at one time or another, drawn out the circles with protractor and paper, much the same way Thomas Young did in his classic paper on the [[double-slit experiment]]. However, it is by no means the only way to represent the electric field, which may also be represented as a spectrum of sinusoidally varying plane waves. In addition, [[Frits Zernike]] proposed still another [[functional decomposition]] based on his [[Zernike polynomials]], defined on the unit disc. The third-order (and lower) Zernike polynomials correspond to the normal lens aberrations. And still another functional decomposition could be made in terms of [[Sinc function]]s and Airy functions, as in the [[Whittaker\u2013Shannon interpolation formula]] and the [[Nyquist\u2013Shannon sampling theorem]]. All of these functional decompositions have utility in different circumstances. The optical scientist having access to these various representational forms has available a richer insight to the nature of these marvelous fields and their properties. These different ways of looking at the field are not conflicting or contradictory, rather, by exploring their connections, one can often gain deeper insight into the nature of wave fields.\n\n=== Functional decomposition and eigenfunctions ===\n\nThe twin subjects of [[eigenfunction]] expansions and [[functional decomposition]], both briefly alluded to here, are not completely independent. The eigenfunction expansions to certain linear operators defined over a given domain, will often yield a countably infinite set of [[orthogonal functions]] which will span that domain. Depending on the operator and the dimensionality (and shape, and boundary conditions) of its domain, many different types of functional decompositions are, in principle, possible.\n\n==See also==\n* [[Abbe sine condition]]\n* [[Huygens\u2013Fresnel principle]]\n* [[Point spread function]]\n* [[Phase contrast microscopy]]\n* [[Fraunhofer diffraction]]\n* [[Fresnel diffraction]]\n* [[Adaptive-additive algorithm]]\n* [[Hilbert space]]\n* [[Optical correlator]]\n* [[Optical Hartley transform]]\n\n==References==\n{{Reflist}}\n* {{cite book |author-first=Pierre-Michel |author-last=Duffieux |author-link=Pierre-Michel Duffieux |date=1983 |title=The Fourier Transform and its Applications to Optics |publisher=[[John Wiley & Sons]] |location=New York, USA}}\n* {{cite book |author-first=Joseph |author-last=Goodman |date=2005 |title=Introduction to Fourier Optics |edition=3 |publisher=Roberts & Company Publishers |isbn=0-9747077-2-4 |url=https://books.google.com/books?id=ow5xs_Rtt9AC |access-date=2017-10-28}}\n* {{cite book |author-first=Eugene |author-last=Hecht |date=1987 |title=Optics |edition=2 |publisher=[[Addison Wesley]] |isbn=0-201-11609-X}}\n* {{cite book |author-first=Raymond |author-last=Wilson |date=1995 |title=Fourier Series and Optical Transform Techniques in Contemporary Optics |publisher=[[John Wiley & Sons]] |isbn=0-471-30357-7}}\n* {{cite book |author-first=Craig |author-last=Scott |date=1998 |title=Introduction to Optics and Optical Imaging |publisher=[[John Wiley & Sons]] |isbn=0-7803-3440-X}}\n* {{cite book |author-first=Craig |author-last=Scott |date=1990 |title=Modern Methods of Reflector Antenna Analysis and Design |publisher=[[Artech House]] |isbn=0-89006-419-9}}\n* {{cite book |author-first=Craig |author-last=Scott |date=1989 |title=The Spectral Domain Method in Electromagnetics |publisher=[[Artech House]] |isbn=0-89006-349-4}}\n* [https://www.youtube.com/watch?v=wcRB3TWIAXE Intro to Fourier Optics and the 4F correlator]\n\n== External links ==\n\n* [http://www.hindawi.com/journals/aot/2010/372652.html Optical Computing: A 60 Year Adventure]\n* [http://server.physics.miami.edu/~curtright/Diffraction/StrattonChu1939.pdf Diffraction Theory of Electromagnetic Waves], ''Phys Rev''\n\n[[Category:Optics]]\n[[Category:Physical optics]]\n[[Category:Fourier analysis]]\n", "text_old": "{{See also|Huygens\u2013Fresnel principle|geometrical optics}}\n\n'''Fourier optics''' is the study of classical [[optics]] using [[Fourier transform]]s (FTs), in which the waveform being considered is regarded as made up of a combination, or ''[[Superposition principle|superposition]]'', of plane waves. It has some parallels to the [[Huygens\u2013Fresnel principle]], in which the wavefront is regarded as being made up of a combination of spherical wavefronts whose sum is the wavefront being studied. A key difference is that Fourier optics considers the plane waves to be natural modes of the propagation medium, as opposed to Huygens\u2013Fresnel, where the spherical waves originate in the physical medium. \n\nA curved phasefront may be synthesized from an infinite number of these \"natural modes\" i.e., from plane wave phasefronts oriented in different directions in space.  Far from its sources, an expanding spherical wave is locally tangent to a planar phase front (a single plane wave out of the infinite spectrum), which is transverse to the radial direction of propagation.  In this case, a [[Fraunhofer diffraction]] pattern is created, which emanates from a single spherical wave phase center.  In the near field, no single well-defined spherical wave phase center exists, so the wavefront isn't locally tangent to a spherical ball.  In this case, a [[Fresnel diffraction]] pattern would be created, which emanates from an ''extended'' source, consisting of a distribution of (physically identifiable) spherical wave sources in space.  In the near field, a full spectrum of plane waves is necessary to represent the Fresnel near-field wave, ''even locally''.  A \"wide\" [[wave]] moving forward (like an expanding ocean wave coming toward the shore) can be regarded as an infinite number of \"[[Wave function|plane wave modes]]\", all of which could (when they collide with something in the way) scatter independently of one other. These mathematical simplifications and calculations are the realm of [[Fourier analysis|Fourier analysis and synthesis]] &ndash; together, they can describe what happens when light passes through various slits, lenses or mirrors curved one way or the other, or is fully or partially reflected.\n\nFourier optics forms much of the theory behind [[image processing|image processing techniques]], as well as finding applications where information needs to be extracted from optical sources such as in [[quantum optics]]. To put it in a slightly more complex way, similar to the concept of ''[[frequency]]'' and ''[[Time in physics|time]]'' used in traditional [[Fourier transform|Fourier transform theory]], Fourier optics makes use of the [[spatial frequency]] domain (''k<sub>x</sub>'', ''k<sub>y</sub>'') as the conjugate of the spatial (''x'', ''y'') domain. Terms and concepts such as transform theory, spectrum, bandwidth, window functions and sampling from one-dimensional [[signal processing]] are commonly used.\n\n== Propagation of light in homogeneous, source-free media ==\n\nLight can be described as a waveform propagating through free space (vacuum) or a material medium (such as air or glass). Mathematically, the (real valued) amplitude of one wave component is represented by a scalar wave function ''u'' that depends on both space and time:\n\n:<math> u = u(\\mathbf{r},t)</math>\n\nwhere\n\n:<math> \\mathbf{r} = (x,y,z) </math>\n\nrepresents position in three dimensional space, and ''t'' represents time.\n\n===The wave equation===\n\nFourier optics begins with the homogeneous, scalar [[wave equation]] (valid in source-free regions):\n\n:<math>\n\\left(\\nabla^2-\\frac{1}{c^2}\\frac{\\partial^2}{\\partial{t}^2}\\right)u(\\mathbf{r},t)=0.\n</math>\n\nwhere ''u''('''r''',''t'') is a [[real number|real valued]] Cartesian component of an electromagnetic wave propagating through free space.\n\n=== Sinusoidal steady state ===\n\nIf light of a fixed [[frequency]]/[[wavelength]]/[[color]] (as from a laser) is assumed, then the time-[[harmonic]] form of the optical field is given as:\n\n:<math>u(\\mathbf{r},t) = \\mathrm{Re} \\left\\{  \\psi(\\mathbf{r}) e^{i\\omega t} \\right\\} </math>.\nwhere <math>i</math> is the [[imaginary unit]],\n:<math>\\omega = 2\\pi f </math>\nis the angular frequency (in radians per unit time) of the light waves, and\n:<math>\\psi(\\mathbf{r}) = a(\\mathbf{r}) e^{i \\phi (\\mathbf{r}) }  </math>\nis, in general, a [[complex number|complex]] quantity, with separate amplitude <math>a</math> and phase <math>\\phi</math>.\n\n=== The Helmholtz equation ===\n\nSubstituting this expression into the wave equation yields the time-independent form of the wave equation, also known as the [[Helmholtz equation]]:\n\n:<math>\\left(\\nabla^2+ k^2 \\right) \\psi (\\mathbf{r})=0</math>\n\nwhere \n:<math>k = { \\omega \\over c} = { 2 \\pi \\over \\lambda }</math>\n\nis the wave number, \u03c8('''r''') is the time-independent, [[complex number|complex-valued]] component of the propagating wave. Note that the propagation constant, k, and the frequency, <math> \\omega </math>, are linearly related to one another, a typical characteristic of transverse electromagnetic (TEM) waves in homogeneous media.\n\n===Solving the Helmholtz equation===\n\nSolutions to the Helmholtz equation may readily be found in [[rectangular coordinates]] via the principle of [[separation of variables]] for [[partial differential equation]]s. This principle says that in separable [[orthogonal coordinates]], an ''elementary product solution'' to this wave equation may be constructed of the following form:\n\n: <math>  \\psi(x, y, z) = f_x(x) \\times f_y(y) \\times f_z(z)</math>\n\ni.e., as the product of a function of ''x'', times a function of ''y'', times a function of ''z''. If this ''elementary product solution'' is substituted into the wave equation (2.0), using the [[Laplace operator|scalar Laplacian]] in rectangular coordinates:\n\n: <math> \\nabla^2 \\psi = \\frac{\\partial^2 \\psi}{\\partial x^2} + \\frac{\\partial^2 \\psi}{\\partial y^2} + \\frac{\\partial^2 \\psi}{\\partial z^2}  </math>\n\nthen the following equation for the 3 individual functions is obtained\n\n: <math>f''_x(x)f_y(y)f_z(z) + f_x(x)f''_y(y)f_z(z) + f_x(x)f_y(y)f''_z(z) + k^2f_x(x)f_y(y)f_z(z)=0  \\,</math>\n\nwhich is readily rearranged into the form:\n\n: <math>   \\frac{f''_x(x)}{f_x(x)}+ \\frac{f''_y(y)}{f_y(y)} + \\frac{f''_z(z)}{f_z(z)} + k^2=0 </math>\n\nIt may now be argued that each of the quotients in the equation above must, of necessity, be constant. For, say the first quotient is not constant, and is a function of ''x''. None of the other terms in the equation has any dependence on the variable x. Therefore, the first term may not have any ''x''-dependence either; it must be constant. The constant is denoted as -''k''<sub>x</sub>\u00b2. Reasoning in a similar way for the ''y'' and ''z'' quotients, three ordinary differential equations are obtained for the ''f''<sub>x</sub>, ''f''<sub>y</sub> and ''f''<sub>z</sub>, along with one ''separation condition'':\n\n: <math>\\frac{d^2}{dx^2}f_x(x) + k_x^2 f_x(x)=0</math>\n\n: <math>\\frac{d^2}{dy^2}f_y(y) + k_y^2 f_y(y)=0</math>\n\n: <math>\\frac{d^2}{dz^2}f_z(z) + k_z^2 f_z(z)=0</math>\n\n: <math>k_x^2+k_y^2+k_z^2= k^2</math>\n\nEach of these 3 differential equations has the same solution: sines, cosines or complex exponentials.  We'll go with the complex exponential for notational simplicity, compatibility with usual FT notation, and the fact that a two-sided integral of complex exponentials picks up both the sine and cosine contributions.  As a result, the elementary product solution for ''E''<sub>u</sub> is:\n\n:<math>\\psi(x,y,z)=e^{i(k_x x + k_y y + k_z z)} </math>\n:::::<math> =e^{i(k_x x + k_y y)} e^{i k_z z}</math>\n:::::<math> =e^{i(k_x x + k_y y)} e^{\\pm i z \\sqrt{k^2-k_x^2-k_y^2} }</math>\n\nwhich represents a propagating or exponentially decaying uniform plane wave solution to the homogeneous wave equation. The - sign is used for a wave propagating/decaying in the +z direction and the + sign is used for a wave propagating/decaying in the -z direction (this follows the engineering time convention, which assumes an e<sup>i\u03c9t</sup> time dependence). This field represents a propagating plane wave when the quantity under the radical is positive, and an exponentially decaying wave when it is negative (in passive media, the root with a non-positive imaginary part must always be chosen, to represent uniform propagation or decay, but not amplification).\n\nProduct solutions to the Helmholtz equation are also readily obtained in [[Cylindrical coordinate system|cylindrical]] and [[Spherical coordinate system|spherical coordinates]], yielding [[Cylindrical harmonics|cylindrical]] and [[spherical harmonics]] (with the remaining separable coordinate systems being used much less frequently).\n\n=== The complete solution: the superposition integral ===\n\nA general solution to the homogeneous electromagnetic wave equation in rectangular coordinates may be formed as a weighted superposition of all possible elementary plane wave solutions as:\n\n:<math>\\psi(x,y,z)=\\int_{-\\infty}^{+\\infty}    \\int_{-\\infty}^{+\\infty}      \\Psi_0(k_x,k_y) ~ e^{i(k_x x + k_y y)} ~ e^{\\pm i z \\sqrt{k^2-k_x^2-k_y^2} } ~ dk_x dk_y ~~~~~~~~~~~~~~~~~~(2.1) </math>\n\nNext, let\n\n:<math>\\psi_0(x,y) = \\psi(x,y,z)|_{z=0}</math>.\n\nThen:\n\n:<math>\\psi_0(x,y)=\\int_{-\\infty}^{+\\infty}      \\int_{-\\infty}^{+\\infty}  \\Psi_0(k_x,k_y) ~ e^{i(k_x x + k_y y)}  ~ dk_x dk_y </math>\n\n'''This plane wave spectrum representation of the electromagnetic field is the basic foundation of Fourier optics''' (this point cannot be emphasized strongly enough), because when ''z''=0, the equation above simply becomes a '''Fourier transform (FT) relationship between the field and its plane wave content'''  (hence the name, \"Fourier optics\").\n\nThus:\n\n:<math>\\Psi_0(k_x,k_y) = \\mathcal{F} \\{ \\psi_0(x,y) \\}</math>\n\nand\n\n:<math>\\psi_0(x,y) = \\mathcal{F}^{-1} \\{  \\Psi_0(k_x,k_y)  \\}</math>\n\nAll spatial dependence of the individual plane wave components is described explicitly via the exponential functions. The coefficients of the exponentials are only functions of spatial wavenumber ''k<sub>x</sub>'', ''k<sub>y</sub>'', just as in ordinary [[Fourier analysis]] and [[Fourier transform]]s.\n\n=== The diffraction limit ===\nWhen\n: <math>   k_x^2+k_y^2 > k^2   </math>\nthe plane waves are [[Evanescent wave|evanescent]] (decaying), so that any spatial frequency content in an object plane transparency which is finer than one wavelength will not be transferred over to the image plane, simply because the plane waves corresponding to that content cannot propagate. In connection with lithography of electronic components, this phenomenon is known as the [[diffraction limit]] and is the reason why light of progressively higher frequency (smaller wavelength, thus larger ''k'') is required for etching progressively finer features in integrated circuits.\n\n== The paraxial approximation ==\n\n===Paraxial plane waves (Optic axis is assumed z-directed)===\n\nAs shown above, an elementary product solution to the Helmholtz equation takes the form:\n\n:<math>\\psi(\\mathbf{r}) = A(\\mathbf{r}) e^{-i \\mathbf{k} \\cdot \\mathbf{r}}</math>\n\nwhere\n\n:<math>\\mathbf{k} \\cdot \\mathbf{r} = k_x \\mathbf{x} + k_y \\mathbf{y} + k_z\\mathbf{z} </math>\n\nis the [[wave vector]], and\n\n:<math> k = \\|\\mathbf{k}\\| = \\sqrt{k_x^2 + k_y^2  + k_z^2} = {\\omega \\over c}</math>\n\nis the wave number. Next, using the [[paraxial approximation]], it is assumed that\n\n:<math>k_x^2 + k_y^2 \\ll k_z^2 </math>\n\nor equivalently,\n\n:<math>\\sin \\theta \\approx \\theta </math>\n\nwhere \u03b8 is the angle between the wave vector '''k''' and the z-axis.\n\nAs a result,\n:<math> k_z = k \\cos \\theta \\approx k ( 1 - \\theta^2 / 2)</math>\nand\n:<math>\\psi(\\mathbf{r}) \\approx A(\\mathbf{r}) e^{-i(k_x x+k_y y)} e^{ikz \\theta^2/2 }  e^{-ik z}</math>\n\n=== The paraxial wave equation ===\n\nSubstituting this expression into the Helmholtz equation, the paraxial wave equation is derived:\n:<math>\\nabla_T^2 A - 2ik { \\partial A \\over \\partial z} = 0</math>\nwhere\n:<math>\\nabla_T^2 = \\nabla^2 - {\\partial^2 \\over \\partial z^2} = {\\partial^2 \\over \\partial x^2} + {\\partial^2 \\over \\partial y^2} </math>\nis the transverse [[Laplace operator]], shown here in Cartesian coordinates.\n\n== The far field approximation ==\n\n{{Main|Fraunhofer diffraction}}\n\nThe equation above may be evaluated asymptotically in the far field (using the [[stationary phase approximation|stationary phase method]]) to show that the field at the distant point (''x'',''y'',''z'') is indeed due solely to the plane wave component (''k<sub>x</sub>'', ''k<sub>y</sub>'', ''k<sub>z</sub>'') which propagates parallel to the vector (''x'',''y'',''z''), and whose plane is tangent to the phasefront at (''x'',''y'',''z''). The mathematical details of this process may be found in Scott [1998] or Scott [1990]. The result of performing a stationary phase integration on the expression above is the following expression,\n\n:<math>E_u(r,\\theta,\\phi)~=~2 \\pi i~ (k~\\cos\\theta)~ \\frac{e^{-ikr}}{r}~ E_u(k~\\sin\\theta~\\cos\\phi,k~\\sin\\theta~\\sin\\phi) ~~~~~~~~~~~~(2.2)</math>\n\nwhich clearly indicates that the field at (x,y,z) is directly proportional to the spectral component in the direction of (x,y,z), where,\n\n: <math> x = r ~ \\sin \\theta ~ \\cos \\phi </math>\n\n: <math> y = r ~ \\sin \\theta ~ \\sin \\phi </math>\n\n: <math> z = r ~ \\cos \\theta ~ </math>\n\nand\n\n: <math> k_x = k ~ \\sin \\theta ~ \\cos \\phi </math>\n\n: <math> k_y = k ~ \\sin \\theta ~ \\sin \\phi </math>\n\n: <math> k_z = k ~ \\cos \\theta ~ </math>\n\nStated another way, the radiation pattern of any planar field distribution is the FT of that source distribution (see [[Huygens\u2013Fresnel principle]], wherein the same equation is developed using a [[Green's function]] approach). Note that this is NOT a plane wave. The <math> \\frac{e^{-ikr}}{r}</math> radial dependence is a spherical wave - both in magnitude and phase - whose local amplitude is the FT of the source plane distribution at that far field angle. The plane wave spectrum has nothing to do with saying that the field behaves something like a plane wave for far distances.\n\n=== Spatial versus angular bandwidth ===\n\nEquation (2.2) above is '''critical''' to making the connection between ''spatial bandwidth'' (on the one hand) and ''angular bandwidth'' (on the other), in the far field. Note that the term \"far field\" usually means we're talking about a converging or diverging spherical wave with a pretty well defined phase center. The connection between spatial and angular bandwidth in the far field is essential in understanding the low pass filtering property of thin lenses. See section 5.1.3 for the condition defining the far field region.\n\nOnce the concept of angular bandwidth is understood, the optical scientist can \"jump back and forth\" between the spatial and spectral domains to quickly gain insights which would ordinarily not be so readily available just through spatial domain or ray optics considerations alone. For example, any source bandwidth which lies past the edge angle to the first lens (this edge angle sets the bandwidth of the optical system) will not be captured by the system to be processed.\n\nAs a side note, electromagnetics scientists have devised an alternative means for calculating the far zone electric field which does not involve stationary phase integration.  They have devised a concept known as \"fictitious magnetic currents\" usually denoted by '''M''', and defined as\n: <math> ~ ~ \\mathbf{M} ~ = ~ 2 \\mathbf{E}^{aper} ~ \\times ~ \\mathbf{\\hat{z}} </math>.\nIn this equation, it is assumed that the unit vector in the z-direction points into the half-space where the far field calculations will be made.  These equivalent magnetic currents are obtained using equivalence principles which, in the case of an infinite planar interface, allow any electric currents, '''J''' to be \"imaged away\" while the fictitious magnetic currents are obtained from twice the aperture electric field (see Scott [1998]).  Then the radiated electric field is calculated from the magnetic currents using an equation similar to the equation for the magnetic field radiated by an electric current.  In this way, a vector equation is obtained for the radiated electric field in terms of the aperture electric field and the derivation requires no use of stationary phase ideas.\n\n==The plane wave spectrum: the foundation of Fourier optics==\n\nFourier optics is somewhat different from ordinary ray optics typically used in the analysis and design of focused imaging systems such as cameras, telescopes and microscopes.  Ray optics is the very first type of optics most of us encounter in our lives; it's simple to conceptualize and understand, and works very well in gaining a baseline understanding of common optical devices.  Unfortunately, ray optics does not explain the operation of Fourier optical systems, which are in general not focused systems.  Ray optics is a subset of wave optics (in the jargon, it is \"the asymptotic zero-wavelength limit\" of wave optics) and therefore has limited applicability.  We have to know when it is valid and when it is not - and this is one of those times when it is not.  For our current task, we must expand our understanding of optical phenomena to encompass wave optics, in which the optical field is seen as a solution to Maxwell's equations.  This more general ''wave optics'' accurately explains the operation of Fourier optics devices.\n\nIn this section, we won't go all the way back to Maxwell's equations, but will start instead with the homogeneous Helmholtz equation (valid in source-free media), which is one level of refinement up from Maxwell's equations (Scott [1998]).  From this equation, we'll show how infinite uniform plane waves comprise one field solution (out of many possible) in free space.  These uniform plane waves form the basis for understanding Fourier optics.\n\nThe [[plane wave]] spectrum concept is the basic foundation of Fourier Optics. The plane wave spectrum is a continuous spectrum of ''uniform'' plane waves, and there is one plane wave component in the spectrum for every tangent point on the far-field phase front. The amplitude of that plane wave component would be the amplitude of the optical field at that tangent point. Again, this is true only in the far field, defined as: Range = 2 D<sup>2</sup> / \u03bb where D is the maximum linear extent of the optical sources and \u03bb is the wavelength (Scott [1998]). The plane wave spectrum is often regarded as being discrete for certain types of periodic gratings, though in reality, the spectra from gratings are continuous as well, since no physical device can have the infinite extent required to produce a true line spectrum.\n\nAs in the case of electrical signals, bandwidth is a measure of how finely detailed an image is; the finer the detail, the greater the bandwidth required to represent it.  A DC electrical signal is constant and has no oscillations; a plane wave propagating parallel to the optic (<math>z</math>) axis has constant value in any ''x''-''y'' plane, and therefore is analogous to the (constant) DC component of an electrical signal.  Bandwidth in electrical signals relates to the difference between the highest and lowest frequencies present in the spectrum of the signal.  For ''optical'' systems, bandwidth also relates to spatial frequency content (spatial bandwidth), but it also has a secondary meaning.  It also measures how far from the optic axis the corresponding plane waves are tilted, and so this type of bandwidth is often referred to also as angular bandwidth. It takes more frequency bandwidth to produce a short pulse in an electrical circuit, and more angular (or, spatial frequency) bandwidth to produce a sharp spot in an optical system (see discussion related to [[Point spread function]]).\n\nThe plane wave spectrum arises naturally as the [[eigenfunction]] or \"natural mode\" solution to the homogeneous [[electromagnetic wave equation]] in rectangular coordinates (see also [[Electromagnetic radiation]], which derives the wave equation from Maxwell's equations in source-free media, or Scott [1998]). In the [[frequency domain]], with an assumed time convention of <math>  e^{i \\omega t} </math>, the homogeneous electromagnetic wave equation is known as the [[Helmholtz equation]] and takes the form:\n\n: <math>  \\nabla^2 E_u + k^2E_u = 0  ~~~~~~~~~~~~~~(2.0) </math>\n\nwhere ''u'' = ''x'', ''y'', ''z'' and ''k'' = 2\u03c0/\u03bb is the [[wavenumber]] of the medium.\n\n===Eigenfunction (natural mode) solutions: background and overview===\n\nIn the case of differential equations, as in the case of matrix equations, whenever the right-hand side of an equation is zero (i.e., the forcing function / forcing vector is zero), the equation may still admit a non-trivial solution, known in applied mathematics as an [[eigenfunction]] solution, in physics as a \"natural mode\" solution and in electrical circuit theory as the \"zero-input response.\"  This is a concept that spans a wide range of physical disciplines.  Common physical examples of ''resonant'' natural modes would include the resonant vibrational modes of stringed instruments (1D), percussion instruments (2D) or the former [[Tacoma Narrows Bridge (1940)|Tacoma Narrows Bridge]] (3D).  Examples of ''propagating'' natural modes would include [[Waveguide (electromagnetism)|waveguide]] modes, [[optical fiber]] modes, [[Soliton (optics)|solitons]] and [[Bloch wave]]s.  Infinite homogeneous media admit the rectangular, circular and spherical harmonic solutions to the Helmholtz equation, depending on the coordinate system under consideration.  The propagating plane waves we'll study in this article are perhaps the simplest type of propagating waves found in any type of media.\n\nThere is a striking similarity between the Helmholtz equation (2.0) above, which may be written\n\n: <math>  (\\nabla^2 + k^2)~f = 0 , </math>\n\nand the usual equation for the [[Eigenvalues and eigenvectors|eigenvalues/eigenvectors]] of a square matrix, '''A''',\n\n: <math>  (\\mathbf A - \\lambda \\mathbf I) ~ \\mathbf x = 0   </math>  ,\n\nparticularly since both the scalar Laplacian,  <math>  \\nabla^2  </math> and the matrix, '''A''' are linear operators on their respective function/vector spaces (the minus sign in the second equation is, for all intents and purposes, immaterial; the plus sign in the first equation however is significant).  It is perhaps worthwhile to note that both the eigenfunction and eigenvector solutions to these two equations respectively, often yield an orthogonal set of functions/vectors which span (i.e., form a basis set for) the function/vector spaces under consideration. The interested reader may investigate other functional linear operators which give rise to different kinds of orthogonal eigenfunctions such as [[Legendre polynomials]], [[Chebyshev polynomials]] and [[Hermite polynomials]].\n\nIn the matrix case, eigenvalues <math>\\lambda</math> may be found by setting the determinant of the matrix equal to zero, i.e. finding where the matrix has no inverse.  Finite matrices have only a finite number of eigenvalues/eigenvectors, whereas linear operators can have a countably infinite number of eigenvalues/eigenfunctions (in confined regions) or uncountably infinite (continuous) spectra of solutions, as in unbounded regions.\n\nIn certain physics applications such as in the [[Bloch wave \u2013 MoM method|computation of bands in a periodic volume]], it is often the case that the elements of a matrix will be very complicated functions of frequency and wavenumber, and the matrix will be non-singular for most combinations of frequency and wavenumber, but will also be singular for certain specific combinations. By finding which combinations of frequency and wavenumber drive the determinant of the matrix to zero, the propagation characteristics of the medium may be determined. Relations of this type, between frequency and wavenumber, are known as dispersion relations and some physical systems may admit many different kinds of dispersion relations. An example from electromagnetics is the ordinary waveguide, which may admit numerous dispersion relations, each associated with a unique mode of the waveguide. Each propagation mode of the waveguide is known as an [[eigenfunction]] solution (or eigenmode solution) to Maxwell's equations in the waveguide. Free space also admits eigenmode (natural mode) solutions (known more commonly as plane waves), but with the distinction that for any given frequency, free space admits a continuous modal spectrum, whereas waveguides have a discrete mode spectrum.  In this case the dispersion relation is linear, as in section 1.2.\n\n=== K-space ===\n\nThe separation condition,\n\n: <math> k_x^2+k_y^2+k_z^2=k^2 </math>\n\nwhich is identical to the equation for the [[Euclidean metric]] in three-dimensional configuration space, suggests the notion of a [[wave vector|k-vector]] in three-dimensional \"k-space\", defined (for propagating plane waves) in rectangular coordinates as:\n\n: <math> \\mathbf{k} ~ = ~ k_x  \\mathbf{\\hat{x}} + k_y \\mathbf{\\hat{y}} + k_z  \\mathbf{\\hat{z}} </math>\n\nand in the [[spherical coordinate system]] as\n\n: <math> k_x = k ~ \\sin \\theta ~ \\cos \\phi </math>\n\n: <math> k_y = k ~ \\sin \\theta ~ \\sin \\phi </math>\n\n: <math> k_z = k ~ \\cos \\theta ~ </math>\n\nUse will be made of these spherical coordinate system relations in the next section.\n\nThe notion of k-space is central to many disciplines in engineering and physics, especially in the study of periodic volumes, such as in crystallography and the band theory of semiconductor materials.\n\n=== The two-dimensional Fourier transform ===\n\nAnalysis Equation (calculating the spectrum of the function):\n:<math>U(k_x,k_y) = \\int_{-\\infty}^{\\infty}  \\int_{-\\infty}^{\\infty} u(x,y) e^{-i(k_x x + k_y y)} dx dy </math>\n\nSynthesis Equation (reconstructing the function from its spectrum):\n:<math> u(x,y) = \\frac{1}{(2\\pi)^2}\\int_{-\\infty}^{\\infty}  \\int_{-\\infty}^{\\infty} U(k_x,k_y) e^{i(k_x x + k_y y)} dk_x dk_y </math>\n\n''Note'': the normalizing factor of:<math>\\frac{1}{(2\\pi)^2} </math> is present whenever angular frequency (radians) is used, but not when ordinary frequency (cycles) is used.\n\n==Optical systems: General overview and analogy with electrical signal processing systems==\n\nAn optical system consists of an input plane, and output plane, and a set of components that transforms the image ''f''  formed at the input into a different image ''g'' formed at the output. The output image is related to the input image by convolving the input image with the optical impulse response, ''h'' (known as the ''point-spread function'', for focused optical systems). The impulse response uniquely defines the input-output behavior of the optical system. By convention, the optical axis of the system is taken as the ''z''-axis. As a result, the two images and the impulse response are all functions of the transverse coordinates, ''x'' and ''y''.\n\n:<math>g(x,y) = h(x,y) * f(x,y)</math>\n\nThe impulse response of an optical imaging system is the output plane field which is produced when an ideal mathematical point source of light is placed in the input plane (usually on-axis). In practice, it is not necessary to have an ideal point source in order to determine an exact impulse response. This is because any source bandwidth which lies outside the bandwidth of the system won't matter anyway (since it cannot even be captured by the optical system), so therefore it's not necessary in determining the impulse response. The source only needs to have at least as much (angular) bandwidth as the optical system.\n\nOptical systems typically fall into one of two different categories. The first is the ordinary focused optical imaging system, wherein the input plane is called the object plane and the output plane is called the image plane. The field in the image plane is desired to be a high-quality reproduction of the field in the object plane. In this case, the impulse response of the optical system is desired to approximate a 2D delta function, at the same location (or a linearly scaled location) in the output plane corresponding to the location of the impulse in the input plane. The ''actual'' impulse response typically resembles an [[Airy disk|Airy function]], whose radius is on the order of the wavelength of the light used. In this case, the impulse response is typically referred to as a [[point spread function]], since the mathematical point of light in the object plane has been spread out into an Airy function in the image plane.\n\nThe second type is the optical image processing system, in which a significant feature in the input plane field is to be located and isolated. In this case, the impulse response of the system is desired to be a close replica (picture) of that feature which is being searched for in the input plane field, so that a convolution of the impulse response (an image of the desired feature) against the input plane field will produce a bright spot at the feature location in the output plane.  It is this latter type of optical ''image processing'' system that is the subject of this section.  Section 5.2 presents one hardware implementation of the optical image processing operations described in this section.\n\n=== Input plane ===\n\nThe input plane is defined as the locus of all points such that ''z'' = 0. The input image ''f'' is therefore\n\n:<math>f(x,y) = U(x,y,z)\\big|_{z=0} </math>\n\n=== Output plane ===\n\nThe output plane is defined as the locus of all points such that ''z'' = ''d''. The output image ''g'' is therefore\n\n:<math>g(x,y) = U(x,y,z)\\big|_{z=d} </math>\n\n=== The 2D convolution of input function against the impulse response function ===\n\n:<math> g(x,y) ~ = ~ h(x,y) * f(x,y) </math>\n\ni.e.,\n\n:<math> g(x,y)= \\int_{-\\infty}^{\\infty}  \\int_{-\\infty}^{\\infty}  h(x-x', y-y') ~ f(x',y') ~ dx' dy'   ~~~~~~(4.1)  ~</math>\n\nThe alert reader will note that the integral above tacitly assumes that the impulse response is NOT a function of the position (x',y') of the impulse of light in the input plane (if this were not the case, this type of convolution would not be possible). This property is known as ''shift invariance'' (Scott [1998]). No optical system is perfectly shift invariant: as the ideal, mathematical point of light is scanned away from the optic axis, aberrations will eventually degrade the impulse response (known as a [[coma (optics)|coma]] in focused imaging systems). However, high quality optical systems are often \"shift invariant enough\" over certain regions of the input plane that we may regard the impulse response as being a function of only the difference between input and output plane coordinates, and thereby use the equation above with impunity.\n\nAlso, this equation assumes unit magnification. If magnification is present, then eqn. (4.1) becomes\n\n:<math> g(x,y)= \\int_{-\\infty}^{\\infty}  \\int_{-\\infty}^{\\infty}  h_M(x-Mx', y-My') ~ f(x',y') ~ dx' dy'   ~~~~~~(4.2)  ~</math>\n\nwhich basically translates the impulse response function, h<sub>M</sub>(), from x' to x=Mx'. In (4.2), h<sub>M</sub>() will be a magnified version of the impulse response function h() of a similar, unmagnified system, so that h<sub>M</sub>(x,y) =h(x/M,y/M).\n\n=== Derivation of the convolution equation ===\nThe extension to two dimensions is trivial, except for the difference that [[causality]] exists in the time domain, but not in the spatial domain. Causality means that the impulse response ''h''(''t'' - t') of an electrical system, due to an impulse applied at time t', must of necessity be zero for all times t such that t - t' < 0.\n\nObtaining the convolution representation of the system response requires representing the input signal as a weighted superposition over a train of impulse functions by using the ''shifting property'' of [[Dirac delta function]]s.\n\n:<math>  f(t) = \\int_{-\\infty}^{\\infty}    \\delta(t-t') f(t') dt'</math>\n\nIt is then presumed that the system under consideration is ''linear'', that is to say that the output of the system due to two different inputs (possibly at two different times) is the sum of the individual outputs of the system to the two inputs, when introduced individually. Thus the optical system may contain no nonlinear materials nor active devices (except possibly, extremely linear active devices). The output of the system, for a single delta function input is defined as the ''impulse response'' of the system, h(t - t').  And, by our linearity assumption (i.e., that the output of system to a pulse train input is the sum of the outputs due to each individual pulse), we can now say that the general input function ''f''(''t'') produces the output:\n\n:<math>  g(t) = \\int_{-\\infty}^{\\infty}    h(t-t') f(t') dt'</math>\n\nwhere ''h''(t - t') is the (impulse) response of the linear system to the delta function input \u03b4(t - t'), applied at time t'. This is where the convolution equation above comes from. The convolution equation is useful because it is often much easier to find the response of a system to a delta function input - and then perform the convolution above to find the response to an arbitrary input - than it is to try to find the response to the arbitrary input directly. Also, the impulse response (in either time or frequency domains) usually yields insight to relevant figures of merit of the system. In the case of most lenses, the point spread function (PSF) is a pretty common figure of merit for evaluation purposes.\n\nThe same logic is used in connection with the [[Huygens\u2013Fresnel principle]], or Stratton-Chu formulation, wherein the \"impulse response\" is referred to as the [[Green's function]] of the system. So the spatial domain operation of a linear optical system is analogous in this way to the Huygens\u2013Fresnel principle.\n\n=== System transfer function ===\nIf the last equation above is Fourier transformed, it becomes:\n\n:<math>  G(\\omega) ~ = ~  H(\\omega) \\cdot  F(\\omega) </math>\n\nwhere\n\n:<math> G(\\omega) ~ </math> is the spectrum of the output signal\n\n:<math> H(\\omega) ~ </math> is the system transfer function\n\n:<math> F(\\omega) ~ </math> is the spectrum of the input signal\n\nIn like fashion, (4.1) may be Fourier transformed to yield:\n\n:<math> G(k_x,k_y) ~ = ~ H(k_x,k_y) \\cdot F(k_x,k_y)</math>\n\nThe system transfer function, <math>H(\\omega)</math>. In optical imaging this function is better known as the [[optical transfer function]] ''(Goodman)''.\n\nOnce again it may be noted from the discussion on the [[Abbe sine condition]], that this equation assumes unit magnification.\n\nThis equation takes on its real meaning when the Fourier transform, <math> ~G(k_x,k_y)</math> is associated with the coefficient of the plane wave whose transverse wavenumbers are <math>~ (k_x,k_y)</math>. Thus, the input-plane plane wave spectrum is transformed into the output-plane plane wave spectrum through the multiplicative action of the system transfer function. It is at this stage of understanding that the previous background on the plane wave spectrum becomes invaluable to the conceptualization of Fourier optical systems.\n\n==Applications of  Fourier optics principles==\nFourier optics is used in the field of optical information processing, the staple of which is the classical 4F processor.\n\nThe [[Fourier transform]] properties of a [[lens (optics)|lens]] provide numerous applications in [[optical signal processing]] such as [[spatial filtering]], [[optical correlation]] and [[computer generated holograms]].\n\nFourier optical theory is used in [[interferometry]], [[optical tweezers]], [[Magnetic trap (atoms)|atom traps]], and [[quantum computing]]. Concepts of Fourier optics are used to reconstruct the [[Phase (waves)|phase]] of light intensity in the spatial frequency plane (see [[adaptive-additive algorithm]]).\n\n===Fourier transforming property of lenses===\n\nIf a transmissive object is placed one focal length in front of a [[lens (optics)|lens]], then its [[Fourier transform]] will be formed one focal length behind the lens. Consider the figure to the right (click to enlarge)\n\n[[File:Lens FT.jpg|On the Fourier transforming property of lenses|right|thumb|500px]]\n\nIn this figure, a plane wave incident from the left is assumed. The transmittance function in the front focal plane (i.e., Plane 1) ''spatially modulates the incident plane wave'' in magnitude and phase, ''like on the left-hand side of eqn. (2.1)'' (specified to ''z''=0), and ''in so doing, produces a spectrum of plane waves'' corresponding to the FT of the transmittance function, ''like on the right-hand side of eqn. (2.1)'' (for ''z''>0). The various plane wave components propagate at different tilt angles with respect to the optic axis of the lens (i.e., the horizontal axis). The finer the features in the transparency, the broader the angular bandwidth of the plane wave spectrum. We'll consider one such plane wave component, propagating at angle \u03b8 with respect to the optic axis. It is assumed that \u03b8 is small ([[paraxial approximation]]), so that\n\n: <math>\\frac{k_x}{k} = \\sin \\theta \\simeq \\theta</math>\n\nand\n\n: <math>\\frac{k_z}{k} = \\cos \\theta \\simeq 1 - \\frac{\\theta^2}{2} </math>\n\nand\n\n: <math> \\frac{1}{\\cos \\theta} \\simeq \\frac{1}{1 - \\frac{\\theta^2}{2}} \\simeq 1 + \\frac{\\theta^2}{2} </math>\n\nIn the figure, the ''plane wave'' phase, moving horizontally from the front focal plane to the lens plane, is\n\n:<math> e^{i k f \\cos \\theta} \\,</math>\n\nand the ''spherical wave'' phase from the lens to the spot in the back focal plane is:\n\n:<math> e^{i k f / \\cos \\theta} \\,</math>\n\nand the sum of the two path lengths is ''f'' (1 + \u03b8<sup>2</sup>/2 + 1 - \u03b8<sup>2</sup>/2) = 2''f''   i.e., it is a constant value, independent of tilt angle, \u03b8, for paraxial plane waves. Each paraxial plane wave component of the field in the front focal plane appears as a [[point spread function]] spot in the back focal plane, with an intensity and phase equal to the intensity and phase of the original plane wave component in the front focal plane. In other words, the field in the back focal plane is the [[Fourier transform]] of the field in the front focal plane.\n\nAll FT components are computed simultaneously - in parallel - at the speed of light. As an example, light travels at a speed of roughly {{convert|1|ft|m|abbr=on}}. / ns, so if a lens has a {{convert|1|ft|m|abbr=on}}. focal length, an entire 2D FT can be computed in about 2 ns (2 x 10<sup>\u22129</sup> seconds). If the focal length is 1 in., then the time is under 200 ps. No electronic computer can compete with these kinds of numbers or perhaps ever hope to, although [[Supercomputer#The_TOP500_list|supercomputers]] may actually prove faster than optics, as improbable as that may seem. However, their speed is obtained by combining numerous computers which, individually, are still slower than optics. The disadvantage of the optical FT is that, as the derivation shows, the FT relationship only holds for paraxial plane waves, so this FT \"computer\" is inherently bandlimited. On the other hand, since the wavelength of visible light is so minute in relation to even the smallest visible feature dimensions in the image i.e.,\n\n: <math> k^2 \\gg  k_x ^2 + k_y ^2 </math>\n\n(for all ''k<sub>x</sub>'', ''k<sub>y</sub>'' within the spatial bandwidth of the image, so that ''k<sub>z</sub>'' is nearly equal to ''k''), the paraxial approximation is not terribly limiting in practice. And, of course, this is an analog - not a digital - computer, so precision is limited. Also, phase can be challenging to extract; often it is inferred interferometrically.\n\nOptical processing is especially useful in real time applications where rapid processing of massive amounts of 2D data is required, particularly in relation to pattern recognition.\n\n====Object truncation and Gibbs phenomenon====\n\nThe spatially modulated electric field, shown on the left-hand side of eqn. (2.1), typically only occupies a finite (usually rectangular) aperture in the x,y plane. The rectangular aperture function acts like a 2D square-top filter, where the field is assumed to be zero outside this 2D rectangle. The spatial domain integrals for calculating the FT coefficients on the right-hand side of eqn. (2.1) are truncated at the boundary of this aperture. This step truncation can introduce inaccuracies in both theoretical calculations and measured values of the plane wave coefficients on the RHS of eqn. (2.1).\n\nWhenever a function is discontinuously truncated in one FT domain, broadening and rippling are introduced in the other FT domain. A perfect example from optics is in connection with the point spread function, which for on-axis plane wave illumination of a quadratic lens (with circular aperture), is an Airy function,  ''J''<sub>1</sub>(''x'')/''x''. Literally, the point source has been \"spread out\" (with ripples added), to form the Airy point spread function (as the result of truncation of the plane wave spectrum by the finite aperture of the lens). This source of error is known as [[Gibbs phenomenon]] and it may be mitigated by simply ensuring that all significant content lies near the center of the transparency, or through the use of [[window function]]s which smoothly taper the field to zero at the frame boundaries. By the convolution theorem, the FT of an arbitrary transparency function - multiplied (or truncated) by an aperture function - is equal to the FT of the non-truncated transparency function convolved against the FT of the aperture function, which in this case becomes a type of \"Greens function\" or \"impulse response function\" in the spectral domain. Therefore, the image of a circular lens is equal to the object plane function convolved against the Airy function (the FT of a circular aperture function is ''J''<sub>1</sub>(''x'')/''x'' and the FT of a rectangular aperture function is a product of sinc functions, sin ''x''/''x'').\n\n==== Fourier analysis and functional decomposition ====\n\nEven though the input transparency only occupies a finite portion of the ''x''-''y'' plane (Plane 1), the uniform plane waves comprising the plane wave spectrum occupy the '''entire''' ''x''-''y'' plane, which is why (for this purpose) only the longitudinal plane wave phase (in the ''z''-direction, from Plane 1 to Plane 2) must be considered, and not the phase transverse to the ''z''-direction. It is of course, very tempting to think that if a plane wave emanating from the finite aperture of the transparency is tilted too far from horizontal, it will somehow \"miss\" the lens altogether but again, since the uniform plane wave extends infinitely far in all directions in the transverse (''x''-''y'') plane, the planar wave components cannot miss the lens.\n\nThis issue brings up perhaps the predominant difficulty with Fourier analysis, namely that the input-plane function, defined over a finite support (i.e., over its own finite aperture), is being approximated with other functions (sinusiods) which have infinite support (''i''.''e''., they are defined over the entire infinite ''x''-''y'' plane). This is unbelievably inefficient computationally, and is the principal reason why [[wavelet]]s were conceived, that is to represent a function (defined on a finite interval or area) in terms of oscillatory functions which are also defined over finite intervals or areas. Thus, instead of getting the frequency content of the entire image all at once (along with the frequency content of the entire rest of the ''x''-''y'' plane, over which the image has zero value), the result is instead the frequency content of different parts of the image, which is usually much simpler. Unfortunately, wavelets in the ''x''-''y'' plane don't correspond to any known type of propagating wave function, in the same way that Fourier's sinusoids (in the ''x''-''y'' plane) correspond to plane wave functions in three dimensions. However, the FTs of most wavelets are well known and could possibly be shown to be equivalent to some useful type of propagating field.\n\nOn the other hand, [[Sinc function]]s and [[Airy function]]s - which are not only the point spread functions of rectangular and circular apertures, respectively, but are also cardinal functions commonly used for functional decomposition in [[Whittaker\u2013Shannon interpolation formula|interpolation/sampling theory]] [Scott 1990] - '''do''' correspond to converging or diverging spherical waves, and therefore could potentially be implemented as a whole new functional decomposition of the object plane function, thereby leading to another point of view similar in nature to Fourier optics. This would basically be the same as conventional ray optics, but with diffraction effects included. In this case, each point spread function would be a type of \"smooth pixel,\" in much the same way that a soliton on a fiber is a \"smooth pulse.\"\n\nPerhaps a lens figure-of-merit in this \"point spread function\" viewpoint would be to ask how well a lens transforms an Airy function in the object plane into an Airy function in the image plane, as a function of radial distance from the optic axis, or as a function of the size of the object plane Airy function. This is somewhat like the point spread function, except now we're really looking at it as a kind of input-to-output plane transfer function (like MTF), and not so much in absolute terms, relative to a perfect point. Similarly, Gaussian wavelets, which would correspond to the waist of a propagating Gaussian beam, could also potentially be used in still another functional decomposition of the object plane field.\n\n==== Far-field range and the 2D<sup>2</sup> / \u03bb criterion ====\n\nIn the figure above, illustrating the Fourier transforming property of lenses, the lens is in the near field of the object plane transparency, therefore the object plane field at the lens may be regarded as a superposition of plane waves, each one of which propagates at some angle with respect to the z-axis. In this regard, the far-field criterion is loosely defined as: Range = 2 ''D''<sup>2</sup> / \u03bb where ''D'' is the maximum linear extent of the optical sources and \u03bb is the wavelength (Scott [1998]).  The ''D'' of the transparency is on the order of cm (10<sup>\u22122</sup> m) and the wavelength of light is on the order of 10<sup>\u22126</sup> m, therefore ''D''/\u03bb  for the whole transparency is on the order of 10<sup>4</sup>. This times ''D'' is on the order of 10<sup>2</sup> m, or hundreds of meters. On the other hand, the far field distance from a PSF spot is on the order of \u03bb. This is because D for the spot is on the order of \u03bb, so that ''D''/\u03bb is on the order of unity; this times ''D'' (i.e., \u03bb) is on the order of \u03bb (10<sup>\u22126</sup> m).\n\nSince the lens is in the far field of any PSF spot, the field incident on the lens from the spot may be regarded as being a spherical wave, as in eqn. (2.2), not as a plane wave spectrum, as in eqn. (2.1). On the other hand, the lens is in the near field of the entire input plane transparency, therefore eqn. (2.1) - the full plane wave spectrum - accurately represents the field incident on the lens from that larger, extended source.\n\n==== Lens as a low-pass filter ====\n\nA lens is basically a low-pass plane wave filter (see [[Low-pass filter]]). Consider a \"small\" light source located on-axis in the object plane of the lens. It is assumed that the source is small enough that, by the far-field criterion, the lens is in the far field of the \"small\" source. Then, the field radiated by the small source is a spherical wave which is modulated by the FT of the source distribution, as in eqn. (2.2), Then, the lens passes - from the object plane over onto the image plane - only that portion of the radiated spherical wave which lies inside the edge angle of the lens. In this far-field case, truncation of the radiated spherical wave is equivalent to truncation of the plane wave spectrum of the small source. So, the plane wave components in this far-field spherical wave, which lie beyond the edge angle of the lens, are not captured by the lens and are not transferred over to the image plane. Note: this logic is valid only for small sources, such that the lens is in the far field region of the source, according to the 2 ''D''<sup>2</sup> / \u03bb criterion mentioned previously. If an object plane transparency is imagined as a summation over small sources (as in the [[Whittaker\u2013Shannon interpolation formula]], Scott [1990]), each of which has its spectrum truncated in this fashion, then every point of the entire object plane transparency suffers the same effects of this low pass filtering.\n\nLoss of the high (spatial) frequency content causes blurring and loss of sharpness (see discussion related to [[point spread function]]). Bandwidth truncation causes a (fictitious, mathematical, ideal) point source in the object plane to be blurred (or, spread out) in the image plane, giving rise to the term, \"point spread function.\"  Whenever bandwidth is expanded or contracted, image size is typically contracted or expanded accordingly, in such a way that the space-bandwidth product remains constant, by Heisenberg's principle (Scott [1998] and [[Abbe sine condition]]).\n\n==== Coherence and Fourier transforming ====\n\nWhile working in the frequency domain, with an assumed e<sup>j\u03c9t</sup> (engineering) time dependence, coherent (laser) light is implicitly assumed, which has a delta function dependence in the frequency domain. Light at different (delta function) frequencies will \"spray\" the plane wave spectrum out at different angles, and as a result these plane wave components will be focused at different places in the output plane. The Fourier transforming property of lenses works best with coherent light, unless there is some special reason to combine light of different frequencies, to achieve some special purpose.\n\n===Hardware implementation of the system transfer function: The 4F correlator {{anchor|4F Correlator}}===\n{{Main|Optical correlator}}\nThe theory on optical transfer functions presented in section 4 is somewhat abstract.  However, there is one very well known device which implements the system transfer function H in hardware using only 2 identical lenses and a transparency plate - the 4F correlator.  Although one important application of this device would certainly be to implement the mathematical operations of [[cross-correlation]] and [[convolution]], this device - 4 focal lengths long - actually serves a wide variety of image processing operations that go well beyond what its name implies.  A diagram of a typical 4F correlator is shown in the figure below (click to enlarge).  This device may be readily understood by combining the plane wave spectrum representation of the electric field (''section 2'') with the Fourier transforming property of quadratic lenses (''section 5.1'') to yield the optical image processing operations described in section 4.\n\n[[File:4F Correlator.svg|4F Correlator|right|thumb|430px]]\n\nThe 4F correlator is based on the [[convolution theorem]] from [[Fourier transform]] theory, which states that [[convolution]] in the spatial (''x'',''y'') domain is equivalent to direct multiplication in the spatial frequency (''k''<sub>x</sub>, ''k''<sub>y</sub>) domain (aka: ''spectral domain''). Once again, a plane wave is assumed incident from the left and a transparency containing one 2D function, ''f''(''x'',''y''), is placed in the input plane of the correlator, located one focal length in front of the first lens. The transparency spatially modulates the incident plane wave in magnitude and phase, like on the left-hand side of eqn. (2.1), and in so doing, produces a spectrum of plane waves corresponding to the FT of the transmittance function, like on the right-hand side of eqn. (2.1). That spectrum is then formed as an \"image\" one focal length behind the first lens, as shown. A transmission mask containing the FT of the second function, ''g''(''x'',''y''), is placed in this same plane, one focal length behind the first lens, causing the transmission through the mask to be equal to the product, ''F''(''k''<sub>x</sub>,''k''<sub>y</sub>) x ''G''(''k''<sub>x</sub>,''k''<sub>y</sub>). This product now lies in the \"input plane\" of the second lens (one focal length in front), so that the FT of this product (i.e., the [[convolution]] of ''f''(''x'',''y'') and ''g''(''x'',''y'')), is formed in the back focal plane of the second lens.\n\nIf an ideal, mathematical point source of light is placed on-axis in the input plane of the first lens, then there will be a uniform, collimated field produced in the output plane of the first lens. When this uniform, collimated field is multiplied by the FT plane mask, and then Fourier transformed by the second lens, the output plane field (which in this case is the ''impulse response'' of the correlator) is just our correlating function, ''g''(''x'',''y''). In practical applications, ''g''(''x'',''y'') will be some type of feature which must be identified and located within the input plane field (see Scott [1998]). In military applications, this feature may be a tank, ship or airplane which must be quickly identified within some more complex scene.\n\nThe 4F correlator is an excellent device for illustrating the \"systems\" aspects of optical instruments, alluded to in ''section 4'' above. The FT plane mask function, ''G''(''k''<sub>x</sub>,''k''<sub>y</sub>) is the system transfer function of the correlator, which we'd in general denote as ''H''(''k''<sub>x</sub>,''k''<sub>y</sub>), and it is the FT of the impulse response function of the correlator, ''h''(''x'',''y'') which is just our correlating function ''g''(''x'',''y''). And, as mentioned above, the impulse response of the correlator is just a picture of the feature we're trying to find in the input image. In the 4F correlator, the system transfer function ''H''(''k''<sub>x</sub>,''k''<sub>y</sub>) is directly multiplied against the spectrum ''F''(''k''<sub>x</sub>,''k''<sub>y</sub>) of the input function, to produce the spectrum of the output function. This is how electrical signal processing systems operate on 1D temporal signals.\n\n==Afterword: Plane wave spectrum within the broader context of functional decomposition==\n\nElectrical fields can be represented mathematically in many different ways. In the [[Huygens\u2013Fresnel principle|Huygens\u2013Fresnel]] or [[Julius Adams Stratton|Stratton]]-Chu viewpoints, the electric field is represented as a superposition of point sources, each one of which gives rise to a [[Green's function]] field. The total field is then the weighted sum of all of the individual Green's function fields. That seems to be the most natural way of viewing the electric field for most people - no doubt because most of us have, at one time or another, drawn out the circles with protractor and paper, much the same way Thomas Young did in his classic paper on the [[double-slit experiment]]. However, it is by no means the only way to represent the electric field, which may also be represented as a spectrum of sinusoidally varying plane waves. In addition, [[Frits Zernike]] proposed still another [[functional decomposition]] based on his [[Zernike polynomials]], defined on the unit disc. The third-order (and lower) Zernike polynomials correspond to the normal lens aberrations. And still another functional decomposition could be made in terms of [[Sinc function]]s and Airy functions, as in the [[Whittaker\u2013Shannon interpolation formula]] and the [[Nyquist\u2013Shannon sampling theorem]]. All of these functional decompositions have utility in different circumstances. The optical scientist having access to these various representational forms has available a richer insight to the nature of these marvelous fields and their properties. These different ways of looking at the field are not conflicting or contradictory, rather, by exploring their connections, one can often gain deeper insight into the nature of wave fields.\n\n=== Functional decomposition and eigenfunctions ===\n\nThe twin subjects of [[eigenfunction]] expansions and [[functional decomposition]], both briefly alluded to here, are not completely independent. The eigenfunction expansions to certain linear operators defined over a given domain, will often yield a countably infinite set of [[orthogonal functions]] which will span that domain. Depending on the operator and the dimensionality (and shape, and boundary conditions) of its domain, many different types of functional decompositions are, in principle, possible.\n\n==See also==\n* [[Abbe sine condition]]\n* [[Huygens\u2013Fresnel principle]]\n* [[Point spread function]]\n* [[Phase contrast microscopy]]\n* [[Fraunhofer diffraction]]\n* [[Fresnel diffraction]]\n* [[Adaptive-additive algorithm]]\n* [[Hilbert space]]\n* [[Optical correlator]]\n* [[Optical Hartley transform]]\n\n==References==\n{{Reflist}}\n* {{cite book |author-first=Pierre-Michel |author-last=Duffieux |author-link=Pierre-Michel Duffieux |date=1983 |title=The Fourier Transform and its Applications to Optics |publisher=[[John Wiley & Sons]] |location=New York, USA}}\n* {{cite book |author-first=Joseph |author-last=Goodman |date=2005 |title=Introduction to Fourier Optics |edition=3 |publisher=Roberts & Company Publishers |isbn=0-9747077-2-4 |url=https://books.google.com/books?id=ow5xs_Rtt9AC |access-date=2017-10-28}}\n* {{cite book |author-first=Eugene |author-last=Hecht |date=1987 |title=Optics |edition=2 |publisher=[[Addison Wesley]] |isbn=0-201-11609-X}}\n* {{cite book |author-first=Raymond |author-last=Wilson |date=1995 |title=Fourier Series and Optical Transform Techniques in Contemporary Optics |publisher=[[John Wiley & Sons]] |isbn=0-471-30357-7}}\n* {{cite book |author-first=Craig |author-last=Scott |date=1998 |title=Introduction to Optics and Optical Imaging |publisher=[[John Wiley & Sons]] |isbn=0-7803-3440-X}}\n* {{cite book |author-first=Craig |author-last=Scott |date=1990 |title=Modern Methods of Reflector Antenna Analysis and Design |publisher=[[Artech House]] |isbn=0-89006-419-9}}\n* {{cite book |author-first=Craig |author-last=Scott |date=1989 |title=The Spectral Domain Method in Electromagnetics |publisher=[[Artech House]] |isbn=0-89006-349-4}}\n* [https://www.youtube.com/watch?v=wcRB3TWIAXE Intro to Fourier Optics and the 4F correlator]\n\n== External links ==\n\n* [http://www.hindawi.com/journals/aot/2010/372652.html Optical Computing: A 60 Year Adventure]\n* [http://server.physics.miami.edu/~curtright/Diffraction/StrattonChu1939.pdf Diffraction Theory of Electromagnetic Waves], ''Phys Rev''\n\n[[Category:Optics]]\n[[Category:Physical optics]]\n[[Category:Fourier analysis]]\n", "name_user": "Hueipei", "label": "safe", "comment": "\u2192\u200eOptical systems: General overview and analogy with electrical signal processing systems", "url_page": "//en.wikipedia.org/wiki/Fourier_optics"}
{"title_page": "Theatre Area of Pompeii", "text_new": "{{short description|Buildings in Pompeii}}\n{{distinguish|Theatre of Pompey}}\n[[File:S03 06 01 024 image 3121.jpg|thumb|right|Bird's eye view of the large and small theatres, Pompeii]]\nThe '''theatre area of [[Pompeii]]''' is located in the southwest region of the city. There are three main buildings that make up this area: the Large Theatre, the Odeon (small theatre), and the Quadriporticum. This served as an entertainment and meeting center of the city.<ref>[Saleri, Renato, Marc Pierrot-Deseilligny, Emmanuel Barbiere, Valeria Cappellini, Nicolas Nony, Livio De Luca, and Massimiliano Campi. \"UAV Photogrammetry for Archaeological Survey: The Theaters Area of Pompeii.\" ''2013 Digital Heritage International Congress (DigitalHeritage)''. Vol. 2. Ieee, 2013. 497-502. Web. 5 Nov. 2015.]</ref> Pompeii had two stone theatres of its own nearly two decades before the first permanent stone theatre was erected in Rome in the 50s BCE. Most of the theatres were adapted for gladiatorial performances during the reign of the Roman empire.\n\n==The Large Theatre==\n[[File:Pompeii theatre 3.jpg|thumbnail|Large Theatre, Pompeii]]\nThe Large Theatre was built into a natural hill in the second century BC. This theatre sat roughly 5,000 spectators and is one of the original permanent stone theatres to stand in Rome.{{clarify|date=June 2018}} In the [[Ancient Greek architecture|Greek style]], the tiered seating extends from the orchestra carved out of the hillside. The Roman influence is seen above this gallery where four tiers rested upon an arched corridor.<ref>[Monnier, Marc, 1827-1885. ''The Wonders of Pompeii''. United States: n.p., 1870. Web. 6 Nov. 2015.]</ref> The cavae, audience seating area, was divided into three sections. The lowermost section, the ''ima'', was reserved for [[Roman Senate|senators]], [[Roman magistrate|magistrates]], and other noble people. The middle section, the ''media'', sat the middle class and the top, the ''summa'', was reserved for the [[plebeians]]. The tiers on the \"ima\" were wider and not as steep as the \"media\" or the \"summa\" to make it more spacious and comfortable for the higher class. The upper class was also separated from the other seating by a short wall, this was to show the class system, and the divide within the social standings of the classes in Rome.\n\nFollowing the [[62 Pompeii earthquake|earthquake of 62 CE]], renovations were made to the theatre. The [[colonnade]] leading to the theatre was converted into barracks for [[gladiator]] residence.<ref>[Beard, Mary. ''Pompeii: The Life of a Roman Town''. London: Profile, 2008;2010;2009;. Web. 6 Nov. 2015.]</ref>\n\n===Modern usage===\nThe theatre has been used for concerts, operas, and theatre in modern times. In the 1950s, in an effort to preserve the original steps, iron frames were installed that allowed for wooden boards to be rested upon them to provide seating. In 2008 a restoration effort began to allow for further theatrical and musical performances. Upon reopening, productions of [[Puccini]]'s ''La Boheme'' and [[Bizet]]'s ''Carmen'' took place in 2014.<ref>[Donati, Silvia. \"Pompeii Hosts Opera Concerts.\" ''ITALY Magazine''. N.p., 17 Sept. 2014. Web. 06 Nov. 2015.]</ref>\n\n==Odeon==\n[[File:Pompeii Odeon.png|thumb|Odeon of Pompeii]]\n[[File:Pompeii Odeion plan.jpg|thumbnail|Odeon plan]]\nThe Odeon was a smaller roofed theatre, ''theatrum tectum'',  that sat 1500 spectators built in 80 BC. The theatre follows the plan of other Roman theatres and [[odeon (building)|odeon]] structures. Where the Large Theatre was used primarily for staging drama, the Odeon was intended for a more educated audience, as well as a musical concert performance. The thin walls and rectangular plan lead to the conclusion that the roof would have been wood rather than vaulted stone. There are two raised ''tribunalia'', platforms, above the seating that were reserved for important visitors. These platforms are cut off from the general seating completely with entrances from narrow staircases near the stage.\n\n===The stage===\nThe stage featured five entrances on the back wall. A large palatial double door was center with two smaller double doors on either side. Two small single doors were located at either end. There is a large doorway that opens to a colonnade leading to the Large Theatre at the west end of the stage. Opposite this is a similar doorway opening up to the street. Behind the stage is a long dressing room or ''postscaenium''. Following ancient theatre tradition, a machine used for suspending the gods and heroes was located at the left side of the stage.<ref>[Kelsey, Francis W. \"The Stage Entrances of the Small Theatre at Pompeii.\" ''American Journal of Archaeology'' 6.4 (1902): 387-97. Web. 5 Nov. 2015.]</ref>\n\n==Quadriporticum==\nThe Quadriporticum served as a passage, ''porticos post scans'', behind the scene of the theatre. It was a covered walkway used by spectators to either travel between events, or just gain cover from the rain. The Quadriporticus was a classic feature of most Hellenic Theaters codified by [[Vitruvius]] in [[De architectura]].<ref>Division, N. (n.d.). Quadriporticus of the Theatres (VIII,7,16-17). Retrieved November 28, 2017, from http://www.pompeiisites.org/Sezione.jsp?titolo=Quadriporticus%2Bof%2Bthe%2BTheatres%2B%28VIII%2C7%2C16-17%29&idSezione=673</ref>\nThe interior area of this courtyard was transformed into gladiatorial housing wdddgyms.\n\n==See also==\n* [[Amphitheatre of Pompei]]\n* [[Theatre of ancient Rome]]\n* [[Roman theatre (structure)]]\n* [[Theatre of ancient Greece]]\n\n==References==\n{{reflist}}\n\n[[Category:Pompeii (ancient city)]]\n[[Category:Ancient Roman theatre lollll| ]]\n", "text_old": "{{short description|Buildings in Pompeii}}\n{{distinguish|Theatre of Pompey}}\n[[File:S03 06 01 024 image 3121.jpg|thumb|right|Bird's eye view of the large and small theatres, Pompeii]]\nThe '''theatre area of [[Pompeii]]''' is located in the southwest region of the city. There are three main buildings that make up this area: the Large Theatre, the Odeon (small theatre), and the Quadriporticum. This served as an entertainment and meeting center of the city.<ref>[Saleri, Renato, Marc Pierrot-Deseilligny, Emmanuel Barbiere, Valeria Cappellini, Nicolas Nony, Livio De Luca, and Massimiliano Campi. \"UAV Photogrammetry for Archaeological Survey: The Theaters Area of Pompeii.\" ''2013 Digital Heritage International Congress (DigitalHeritage)''. Vol. 2. Ieee, 2013. 497-502. Web. 5 Nov. 2015.]</ref> Pompeii had two stone theatres of its own nearly two decades before the first permanent stone theatre was erected in Rome in the 50s BCE. Most of the theatres were adapted for gladiatorial performances during the reign of the Roman empire.\n\n==The Large Theatre==\n[[File:Pompeii theatre 3.jpg|thumbnail|Large Theatre, Pompeii]]\nThe Large Theatre was built into a natural hill in the second century BC. This theatre sat roughly 5,000 spectators and is one of the original permanent stone theatres to stand in Rome.{{clarify|date=June 2018}} In the [[Ancient Greek architecture|Greek style]], the tiered seating extends from the orchestra carved out of the hillside. The Roman influence is seen above this gallery where four tiers rested upon an arched corridor.<ref>[Monnier, Marc, 1827-1885. ''The Wonders of Pompeii''. United States: n.p., 1870. Web. 6 Nov. 2015.]</ref> The cavae, audience seating area, was divided into three sections. The lowermost section, the ''ima'', was reserved for [[Roman Senate|senators]], [[Roman magistrate|magistrates]], and other noble people. The middle section, the ''media'', sat the middle class and the top, the ''summa'', was reserved for the [[plebeians]]. The tiers on the \"ima\" were wider and not as steep as the \"media\" or the \"summa\" to make it more spacious and comfortable for the higher class. The upper class was also separated from the other seating by a short wall, this was to show the class system, and the divide within the social standings of the classes in Rome.\n\nFollowing the [[62 Pompeii earthquake|earthquake of 62 CE]], renovations were made to the theatre. The [[colonnade]] leading to the theatre was converted into barracks for [[gladiator]] residence.<ref>[Beard, Mary. ''Pompeii: The Life of a Roman Town''. London: Profile, 2008;2010;2009;. Web. 6 Nov. 2015.]</ref>\n\n===Modern usage===\nThe theatre has been used for concerts, operas, and theatre in modern times. In the 1950s, in an effort to preserve the original steps, iron frames were installed that allowed for wooden boards to be rested upon them to provide seating. In 2008 a restoration effort began to allow for further theatrical and musical performances. Upon reopening, productions of [[Puccini]]'s ''La Boheme'' and [[Bizet]]'s ''Carmen'' took place in 2014.<ref>[Donati, Silvia. \"Pompeii Hosts Opera Concerts.\" ''ITALY Magazine''. N.p., 17 Sept. 2014. Web. 06 Nov. 2015.]</ref>\n\n==Odeon==\n[[File:Pompeii Odeon.png|thumb|Odeon of Pompeii]]\n[[File:Pompeii Odeion plan.jpg|thumbnail|Odeon plan]]\nThe Odeon was a smaller roofed theatre, ''theatrum tectum'',  that sat 1500 spectators built in 80 BC. The theatre follows the plan of other Roman theatres and [[odeon (building)|odeon]] structures. Where the Large Theatre was used primarily for staging drama, the Odeon was intended for a more educated audience, as well as a musical concert performance. The thin walls and rectangular plan lead to the conclusion that the roof would have been wood rather than vaulted stone. There are two raised ''tribunalia'', platforms, above the seating that were reserved for important visitors. These platforms are cut off from the general seating completely with entrances from narrow staircases near the stage.\n\n===The stage===\nThe stage featured five entrances on the back wall. A large palatial double door was center with two smaller double doors on either side. Two small single doors were located at either end. There is a large doorway that opens to a colonnade leading to the Large Theatre at the west end of the stage. Opposite this is a similar doorway opening up to the street. Behind the stage is a long dressing room or ''postscaenium''. Following ancient theatre tradition, a machine used for suspending the gods and heroes was located at the left side of the stage.<ref>[Kelsey, Francis W. \"The Stage Entrances of the Small Theatre at Pompeii.\" ''American Journal of Archaeology'' 6.4 (1902): 387-97. Web. 5 Nov. 2015.]</ref>\n\n==Quadriporticum==\nThe Quadriporticum served as a passage, ''porticos post scans'', behind the scene of the theatre. It was a covered walkway used by spectators to either travel between events, or just gain cover from the rain. The Quadriporticus was a classic feature of most Hellenic Theaters codified by [[Vitruvius]] in [[De architectura]].<ref>Division, N. (n.d.). Quadriporticus of the Theatres (VIII,7,16-17). Retrieved November 28, 2017, from http://www.pompeiisites.org/Sezione.jsp?titolo=Quadriporticus%2Bof%2Bthe%2BTheatres%2B%28VIII%2C7%2C16-17%29&idSezione=673</ref>\nThe interior area of this courtyard was transformed into gladiatorial housing wdddgyms.\n\n==See also==\n* [[Amphitheatre of Pompei]]\n* [[Theatre of ancient Rome]]\n* [[Roman theatre (structure)]]\n* [[Theatre of ancient Greece]]\n\n==References==\n{{reflist}}\n\n[[Category:Pompeii (ancient city)]]\n[[Category:Ancient Roman theatre| ]]\n", "name_user": "2a02:c7f:14d7:1400:a42e:50be:225d:2e3d", "label": "unsafe", "comment": "(\u2192\u200eReferences)", "url_page": "//en.wikipedia.org/wiki/Theatre_Area_of_Pompeii"}
